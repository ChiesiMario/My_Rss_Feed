<?xml version="1.0" encoding="UTF-8"?>
<rss
    xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"


>
    <channel>
        <title>
            <![CDATA[開源中國-綜合資訊]]>
        </title>
        <link>https://www.oschina.net/news/industry</link>
        <atom:link href="https://rsshub.app/oschina/news/industry" rel="self" type="application/rss+xml" />
        <description>
            <![CDATA[開源中國-綜合資訊 - Made with love by RSSHub(https://github.com/DIYgod/RSSHub)]]>
        </description>
        <generator>RSSHub</generator>
        <webMaster>i@diygod.me (DIYgod)</webMaster>
        <language>zh-cn</language>
        <lastBuildDate>Mon, 27 Nov 2023 23:13:51 GMT</lastBuildDate>
        <ttl>120</ttl>
        <item>
            <title>
                <![CDATA[Dromara 社區新晉開源項目 dbswitch，異構數據庫遷移同步工具！]]>
            </title>
            <description>
                <![CDATA[<div class="content"><h1>一個適用於異構數據庫遷移同步的簡單工具 dbswitch</h1><h2>作者介紹</h2><ul><li>網名：三胖 (inrgihc)</li><li>dromara 開源組織成員，項目 dromara/dbswitch 作者</li><li>項目地址：<a href="https://gitee.com/dromara/dbswitch">https://gitee.com/dromara/dbswitch</a></li></ul><p>&nbsp;</p><p><img height="400" src="https://oscimg.oschina.net/oscnet/up-6c79b909dbfad7a428286eebe6fd1c2f82b.png" width="400" referrerpolicy="no-referrer"></p><h2>dbswitch 的誕生</h2><p>你需要<strong>將 Oracle 等老牌數據庫中的數據一鍵搞到 MySQL 或 PostgreSQL 中</strong>麼？你需要<strong>將 MySQL 等關係型數據庫中的數據一鍵搞到 Greenplum/ClickHouse 等 OLAP 數據庫中進行分析</strong>麼？</p><p>如果你在工作中遇到與我同樣的需求，那麼不妨體驗下 dbswitch 工具。</p><p>dbswitch 是在<strong>數據庫間數據搬遷</strong>和<strong>數據入倉入湖</strong>這兩大背景環境下誕生的，雖然目標路程還很長，但是<strong>dbswitch 作為一款開源工具</strong>會一直再努力堅持着（也許各個數據庫廠商都有自己的專業遷移工具）。</p><h2>dbswitch 的功能</h2><p>簡言之，dbswitch 提供源端數據庫向目的端數據庫的批量遷移同步功能：</p><ul><li>結構遷移：</li></ul><p>(1) 支持字段類型、主鍵信息、建表語句等的轉換，並生成建表 SQL 語句。</p><p>(2) 支持基於正則表達式轉換的表名與字段名映射轉換。</p><ul><li>數據同步：</li></ul><p>(1) 基於 JDBC 的分批次讀取源端數據庫數據，並基於 jdbc(insert/copy 方式) 將數據分批次寫入目的數據庫。</p><p>(2) 支持有主鍵表（基於數據比對變化計算原理的）增量變更 (insert/update/delete) 同步功能</p><h2>dbswitch 支持的數據庫</h2><p>當前基於<strong>驅動隔離</strong>已經集成支持<strong>多版本的數據庫</strong>產品如下：</p><ul><li>甲骨文的 Oracle</li><li>微軟的 Microsoft SQLServer</li><li>MySQL/MariaDB</li><li>PostgreSQL</li><li>Greenplum(需使用 PostgreSQL 類型)</li><li>IBM 的 DB2</li><li>Sybase 數據庫</li><li>國產達夢數據庫 DMDB</li><li>國產人大金倉數據庫 Kingbase8</li><li>國產翰高數據庫 HighGo</li><li>國產神通數據庫 Oscar</li><li>國產南大通用數據庫 GBase8a</li><li>Apache Hive(基於 JdbcStorageHandler)</li><li>SQLite3</li><li>OpenGuass</li><li>ClickHouse</li><li>MongoDB</li></ul><h2>dbswitch 的部署體驗</h2><h3>1.一鍵部署</h3><ul><li>基於 docker-compose 的一鍵安裝 (或升級):</li></ul><pre><code>curl -sSL https://gitee.com/inrgihc/dbswitch/attach_files/1551962/download | sh
</code></pre><ul><li>基於 docker 的一鍵安裝：</li></ul><p>假設已經部署好的 MySQL 數據庫地址為 192.168.31.57，端口為 3306，賬號為 test，密碼為 123456</p><pre><code>docker run -d --name dbswitch \\
 -e MYSQLDB_HOST=192.168.31.57 \\
 -e MYSQLDB_PORT=3306 \\
 -e MYSQLDB_USERNAME=test \\
 -e MYSQLDB_PASSWORD='123456' \\
 -v /tmp:/tmp \\
 -p 9088:9088 \\
 registry.cn-hangzhou.aliyuncs.com/inrgihc/dbswitch:1.8.2
</code></pre><h2>2.部分截圖</h2><p><img height="992" src="https://oscimg.oschina.net/oscnet/up-248a80912f903336faae60ac7147a23fbde.png" width="1842" referrerpolicy="no-referrer"></p><p>&nbsp;</p><p><img height="991" src="https://oscimg.oschina.net/oscnet/up-23ac44c99d40214512e2fe4506c63c69c32.png" width="1827" referrerpolicy="no-referrer"></p><ul><li>二次集成開發</li></ul><p>dbswitch 也支持 java 下二次集成開發，具體可查看 dbswitch 項目中的文檔説明。</p><h2>關注 dbswitch</h2><p>歡迎體驗使用 dbswitch 工具，同時項目中也提供了 dbswitch 相關的實現原理。</p><h2>友情項目</h2><p>[1] <a href="https://gitee.com/inrgihc/greenplum_installer">Greenplum 一鍵安裝</a></p><p>[2] <a href="https://gitee.com/inrgihc/libnpce">新聞文章正文抽取正文抽取組件</a></p></div>
                                    ]]>
            </description>
            <pubDate>Mon, 27 Nov 2023 02:39:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/268303</guid>
            <link>https://www.oschina.net/news/268303</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Firefox 在 2023 變得更快了]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>Mozilla 官方博客最近<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhacks.mozilla.org%2F2023%2F10%2Fdown-and-to-the-right-firefox-got-faster-for-real-users-in-2023%2F">發表文章</a>，稱 2023 年 Firefox 在提升用戶體驗方面取得了顯著的進展，真實用戶使用 Firefox 能感受到速度更快。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-48c6863ad3edd6c093cc619549ed7f30c35.png" referrerpolicy="no-referrer"></p><p>據介紹，Firefox 通過收集與<strong>頁面加載、響應速度、啓動</strong>等瀏覽器性能相關的匿名化時間度量指標來衡量用戶體驗。文章分享了一些對用戶瀏覽器體驗至關重要的指標在一年中是如何改進的。</p><ul><li><h4><strong>優化頁面加載速度</strong></h4></li></ul><p>Firefox 使用 "First Contentful Paint (FCP)" 這個指標來衡量用戶感知的性能。FCP 指的是從網絡接收到第一個字節到頁面顯示內容的時間。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-16ba708b843784921085bfebb7aede81380.png" referrerpolicy="no-referrer"></p><p>數據顯示，從年初的大約 250 毫秒，到十月份的 215 毫秒，<strong>頁面加載速度提高了約 15%</strong>。這意味着用戶能夠更快地收到頁面加載的反饋信息。</p><ul><li><h4><strong>優化 JavaScript 執行時間</strong></h4></li></ul><p>Firefox 還關注頁面加載過程中 JavaScript 代碼的執行時間。</p><p>數據顯示，95% 的頁面中 JavaScript 執行時間從年初的約 1560 毫秒，到十月份的約 1260 毫秒，速度提升了約 20%。這對於減少頁面加載時間起到了重要作用。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-180320b8057907172e172bf066f77cc7c79.png" referrerpolicy="no-referrer"></p><ul><li><h4><strong>優化鍵盤響應速度</strong></h4></li></ul><p>Firefox 還關注頁面加載後的響應速度。更具體來説，它關注鍵盤按下後到屏幕上顯示結果的時間。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-19618b78169525abf4262e888f93daec3dc.png" referrerpolicy="no-referrer"></p><p>數據顯示，95% 的頁面中鍵盤響應速度從年初的約 65 毫秒，到八月份的約 59 毫秒，速度提升了約 10%。這意味着用戶在鍵入時能夠更快地得到反饋，減少了打字時的延遲。</p><p>Firefox 團隊表示，通過這些數據可以看出 Firefox 在 2023 年取得了用戶體驗方面的顯著改善。這些改進是通過優化瀏覽器的性能和 JavaScript 引擎實現的。Firefox 團隊還表示他們將繼續努力進行更多的優化，並在未來的文章中分享更多細節和進展。</p></div>
                                    ]]>
            </description>
            <pubDate>Sun, 26 Nov 2023 12:16:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/268242/firefox-got-faster-for-real-users-in-2023</guid>
            <link>https://www.oschina.net/news/268242/firefox-got-faster-for-real-users-in-2023</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[浪潮發佈基礎大模型「源 2.0」，千億參數全面開源]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><strong>浪潮信息<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FrjnsUS83TT7aEN3r2i0IPQ" target="_blank">發佈</a></u>「源 2.0」基礎大模型，並宣佈全面開源</strong>。</p><p>據介紹，源 2.0 基礎大模型包括 1026 億、518 億、21 億等三種參數規模的模型，在編程、推理、邏輯等方面展示出了先進的能力。</p><p><strong>算法方面</strong>，源 2.0 提出並採用了一種新型的注意力算法結構：局部注意力過濾增強機制 (LFA：Localized Filtering-based Attention)。LFA 通過先學習相鄰詞之間的關聯性，然後再計算全局關聯性的方法，能夠更好地學習到自然語言的局部和全局的語言特徵，對於自然語言的關聯語義理解更準確、更人性，提升了模型的自然語言表達能力，進而提升了模型精度。</p><p><img src="https://static.oschina.net/uploads/space/2023/1127/184848_muAm_2720166.png" referrerpolicy="no-referrer"></p><p><strong>數據方面</strong>，源 2.0 通過使用中英文書籍、百科、論文等高質量中英文資料，降低了互聯網語料內容佔比，結合高效的數據清洗流程，為大模型訓練提供了高質量的專業數據集和邏輯推理數據集。</p><p>據稱，為了更高效地獲得相對匱乏的高質量中文數學及代碼數據集，源 2.0 採用了基於大模型的數據生產及過濾方法，在保證數據的多樣性的同時也在每一個類別上提升數據質量，獲取了一批高質量的數學與代碼預訓練數據。</p><p><img src="https://static.oschina.net/uploads/space/2023/1127/184918_iLAq_2720166.png" referrerpolicy="no-referrer"></p><p><strong>算力方面</strong>，源 2.0 採用了非均勻流水並行的方法，綜合運用流水線並行+優化器參數並行+數據並行的策略，讓模型在流水並行各階段的顯存佔用量分佈更均衡，避免出現顯存瓶頸導致的訓練效率降低的問題，該方法顯著降低了大模型對芯片間 P2P 帶寬的需求，為硬件差異較大訓練環境提供了一種高性能的訓練方法。</p><p><img src="https://static.oschina.net/uploads/space/2023/1127/184932_0UiQ_2720166.png" referrerpolicy="no-referrer"></p><p>源 2.0 在業界公開的評測上進行了代碼生成、數學問題求解、事實問答方面的能力測試，下面是測試結果：</p><p><img src="https://static.oschina.net/uploads/space/2023/1127/184945_PzyP_2720166.png" referrerpolicy="no-referrer"></p><p><strong>源 2.0 採用全面開源策略，全系列模型參數和代碼均可免費下載使用</strong>。</p><ul><li>代碼開源鏈接：<u><em><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FIEIT-Yuan%2FYuan-2.0" target="_blank">https://github.com/IEIT-Yuan/Yuan-2.0</a></em></u></li><li>論文鏈接：<u><em><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FIEIT-Yuan%2FYuan-2.0%2Fblob%2Fmain%2Fdocs%2FYuan2.0_paper.pdf" target="_blank">https://github.com/IEIT-Yuan/Yuan-2.0/blob/main/docs/Yuan2.0_paper.pdf</a></em></u></li></ul></div>
                                    ]]>
            </description>
            <pubDate>Sun, 26 Nov 2023 10:50:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/268384</guid>
            <link>https://www.oschina.net/news/268384</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[字節跳動成立新部門 Flow，發力 AI 應用層]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="background-color:#ffffff; color:#333333">36 氪報道稱，</span><span style="background-color:#ffffff; color:#222222">字節跳動近期成立了一個新 AI 部門 Flow，技術負責人為字節跳動技術副總裁洪定坤。</span></p><p><span style="background-color:#ffffff; color:#222222">一位知情人士表示，這一新部門的業務帶頭人，為字節大模型團隊的負責人朱文佳。Flow 主要聚焦在 AI 應用層。在字節圈內，Flow 近期發佈了活水招聘帖，社會招聘也已經開始一段時間。</span></p><p><span style="background-color:#ffffff; color:#222222">在帖中，其表示是字節跳動旗下 AI 創新業務團隊，「目前已經在國內和海外分別上線豆包和 Cici 兩款產品，有多個 AI 相關創新產品孵化中」。截止發稿前，字節跳動尚無迴應。</span></p><p style="color:#262626; margin-left:0; margin-right:0; text-align:justify">在 11 月初，字節各個事業部都進行了不少業務和架構調整，這些調整仍在進行中，當前 Flow 的架構和彙報線未完全確定。且多位知情人士透露，在此次調整中，字節也從飛書、抖音等各個 BU 抽調人選，到這一部門做一款新的 C 端產品。</p></div>
                                    ]]>
            </description>
            <pubDate>Sun, 26 Nov 2023 10:50:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/268383</guid>
            <link>https://www.oschina.net/news/268383</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[雲原生週刊：Kubernetes 1.29 中的刪除、棄用和主要更改]]>
            </title>
            <description>
                <![CDATA[<div class="content"><h2>開源項目推薦</h2><h3><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fyonahd%2Forphaned-configmaps" target="_blank">Orphaned ConfigMaps</a></h3><p>該版本庫包含一個腳本，用於識別 Kubernetes 命名空間中的孤立的配置映射。孤立的配置映射是指那些未被命名空間中的任何活動 Pod 或容器引用的配置映射。</p><h3><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fmarvasgit%2Fkubernetes-multicooker" target="_blank">Kubernetes Multi Cooker</a></h3><p>該項目包含一個小型 Kubernetes 控制器，用於監視每個節點的 CPU 壓力；當超過某個閾值時，節點將被污染（這樣就不會在已經超載的節點上調度額外的工作負載），最後控制器將開始從該節點驅逐 Pod。</p><h3><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Femberstack%2Fkubernetes-reflector" target="_blank">Reflector</a></h3><p>Reflector 是一個 Kubernetes 插件，旨在監視資源（祕密和配置映射）的更改並反映相同或其他命名空間中鏡像資源的更改。</p><h2>文章推薦</h2><h3><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fkubernetes.io%2Fblog%2F2023%2F11%2F16%2Fkubernetes-1-29-upcoming-changes%2F" target="_blank">Kubernetes 1.29 中的刪除、棄用和主要更改</a></h3><p>和其他每次發佈一樣，Kubernetes v1.29 將棄用和移除一些特性。一貫以來生成高質量發佈版本的能力是開發週期穩健和社區健康的證明。本文列舉即將發佈的 Kubernetes 1.29 中的一些棄用和移除事項。</p><h3><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcollabnix.com%2Ftop-5-storage-provider-tools-for-kubernetes%2F" target="_blank">Kubernetes 的 5 大存儲提供商工具</a></h3><p>這篇文章介紹了 Kubernetes 的五個存儲提供者工具：SeaweedFS、Vitess、TiKV、Rook 和 OpenEBS。這些工具幫助管理 Kubernetes 上的數據工作負載，包括卷供應、複製、備份、加密、壓縮和性能調優等功能。它們與 Kubernetes API 和概念無縫集成，並支持持久卷（PV）、持久卷聲明（PVC）和存儲類（Storage Class）。這篇文章詳細介紹了每個工具的工作機制、優勢以及在實際使用中的案例和成功故事。通過閲讀這篇文章，讀者可以瞭解 Kubernetes 上可用的存儲提供者選項，並根據自己的需求選擇最合適的工具。</p><h3><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.atatus.com%2Fblog%2Ftroubleshooting-kubernetes-deployment%2F" target="_blank">對各個級別的 Kubernetes 部署進行故障排除</a></h3><p>這篇文章是關於在各個層面上解決 Kubernetes 部署問題的指南。文章首先介紹了 Kubernetes 作為容器編排的事實標準，並提到了它自動化部署、擴展和管理容器化應用程序的能力。然而，即使遵循最佳實踐並具備專業知識，Kubernetes 部署有時也是一個複雜而具有挑戰性的過程。文章探討了從應用代碼到基礎設施和 Kubernetes 組件的各個層面上的部署故障排除過程，並介紹了一些常見問題和挑戰，如容器鏡像拉取錯誤、Pod 調度問題、網絡連接問題和存儲問題。文章還討論了一些診斷和解決這些問題的最佳實踐和工具。通過閲讀這篇文章，讀者將更好地瞭解如何在 Kubernetes 部署的每個層面上進行故障排除，並更好地管理其應用程序。</p><h2>雲原生動態</h2><h3><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.cncf.io%2Fblog%2F2023%2F11%2F20%2Fannouncing-the-platform-engineering-maturity-model%2F" target="_blank">CNCF 平台工程成熟度模型出爐</a></h3><p>CNCF（Cloud Native Computing Foundation）的平台工程成熟度模型首次發佈。該模型提供了對平台工程成熟度的具體應用，是今年 4 月份發佈的備受歡迎的白皮書的延伸。該模型將平台工程定義為通過在構建平台和其能力的各個方面（包括人員、流程、策略和技術）進行投資，提供內部平台作為產品的實踐，從而推動業務結果。</p><h3><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcloudnativenow.com%2Ftopics%2Fcloudnativedevelopment%2Fmicrosoft-expands-scope-of-azure-kubernetes-services%2F" target="_blank">微軟擴大 Azure Kubernetes 服務範圍</a></h3><p>Microsoft 已普遍推出 Azure Kubernetes Fleet Manager，以便更輕鬆地集中管理多個集羣，並可與一組用於優化成本的工具一起分階段進行。</p><p>與此同時，除了預覽 Azure 容器應用程序平台的擴展以增加對事件的支持之外，微軟還使用 Kubernetes AI 工具鏈運算符簡化在 Azure Kubernetes 服務 (AKS) 上部署大型語言模型 (LLM) 的過程用於訓練 AI 模型的驅動框架，同時支持開源 Qdrant、Milvus 和 Weaviate 矢量數據庫。</p><blockquote><p>本文由博客一文多發平台 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopenwrite.cn%3Ffrom%3Darticle_bottom" target="_blank">OpenWrite</a> 發佈！</p></blockquote></div>
                                    ]]>
            </description>
            <pubDate>Sun, 26 Nov 2023 09:22:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/4197945/blog/10293895</guid>
            <link>https://my.oschina.net/u/4197945/blog/10293895</link>
            <author>
                <![CDATA[原創]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[What's new in dubbo-go-pixiu v1.0.0]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>dubbo 原生網關 dubbo-go-pixiu v1.0 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fdubbo-go-pixiu%2Freleases%2Ftag%2Fv1.0.0-rc2" target="_blank">https://github.com/apache/dubbo-go-pixiu/releases/tag/v1.0.0-rc2</a> 正式發版了，項目從 2019 年一路走來，四年磨劍，感謝從，鐵城、張天，到 呂夢超，三位負責人。</p><p>目前，dubbo-go-pixiu 可作為 dubbo/dubbogo 服務網關，也可作為 dubbo/dubbogo 服務的 sidecar，還額外基於 Istio v1.14.3 實現了 dubbo 的控制面。</p><p>dubbo-go 和 dubbo-go-pixiu 在 2023 年初被螞蟻集團採用內部容器 PAAS HCS(Hyper Container Service) 超級容器平台的微服務技術底座， v1.0.0 集成了螞蟻集團使用過程中的提交的很多改進和優化。感謝本次版本的主要貢獻者，胡瀟晗、樊凡、龔娜、張國強、【阿里】遠雲、【螞蟻】多航、王虓雄、望哥、於雨，等社區同學。</p><h1>1 New Features In v1.0.0</h1><h2>1.1 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fdubbo-go-pixiu%2Fpull%2F548" target="_blank">Triple 支持傳遞 Header 和引入 PB 定義</a></h2><p>Triple 代理現在可以正確傳遞 header 到 Triple 服務，且支持通過引入 protoset 文件來支持未開啓 Proto 反射或不支持反射的特定 proto，例如使用舊版本編譯的或 gogoproto 編譯的服務。</p><p>samples： <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fdubbo-go-pixiu-samples%2Ftree%2Fmain%2Fdubbogo%2Fsimple%2Ftriple" target="_blank">https://github.com/apache/dubbo-go-pixiu-samples/tree/main/dubbogo/simple/triple</a></p><h2>1.2 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fdubbo-go-pixiu%2Fpull%2F554" target="_blank">負載均衡 Maglev hashing</a></h2><p>負載均衡支持新算法：Maglev hashing。Maglev 是 Google 開發的基於 kernal bypass 技術實現的 4 層負載均衡，它具有非常強大的負載性能，承載了 Google 絕大部分接入流量。Maglev 在負載均衡算法上採用自行開發的一致性哈希算法被稱為 Maglev Hashing，該哈希算法在節點變化時能夠儘量少的影響其他幾點，且儘可能的保證負載的均衡，是一個非常優秀的一致性哈希算法。</p><p>samples： <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fshawnh2%2Fdubbo-go-pixiu-samples%2Ftree%2Fmain%2Fdubbogo%2Fsimple%2Ftraffic" target="_blank">https://github.com/shawnh2/dubbo-go-pixiu-samples/tree/main/dubbogo/simple/traffic</a></p><h2>1.3 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fdubbo-go-pixiu%2Fpull%2F565" target="_blank">Router 支持 Header 路由</a></h2><p>Router 支持通過 header 路由，可以更方便的管理流量。</p><pre><code class="language-yaml">              http_filters:
                  - name: dgp.filter.http.traffic
                    config:
                      traffics:
                        - name: "user-v1"
                          router: "/user"
                          canary-by-header: v1
                          canary-weight: 0
                        - name: "user-v2"
                          router: "/user"
                          canary-by-header: v2
                          canary-weight: 100
</code></pre><p>samples： <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fshawnh2%2Fdubbo-go-pixiu-samples%2Ftree%2Fmain%2Fdubbogo%2Fsimple%2Ftraffic" target="_blank">https://github.com/shawnh2/dubbo-go-pixiu-samples/tree/main/dubbogo/simple/traffic</a></p><h2>1.4 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fdubbo-go-pixiu%2Fpull%2F571" target="_blank">錯誤注入</a></h2><p>支持對特定 API 做錯誤注入，例如返回固定的響應，施加隨機性的延時/錯誤等。</p><pre><code class="language-yaml">                http_filters:
                  - name: dgp.filter.http.faultinjection
                    config:
                      fail_inject_rules:
                        "/UserService/com.dubbogo.pixiu.UserService/GetUserByCode":
                          type: delay
                          trigger_type: random
                          status_code: 500
                          body: 'error'
                          delay: 5s
                          odds: 30
</code></pre><p>samples： <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fdubbo-go-pixiu%2Fblob%2Fdevelop%2Fdocs%2Fsample%2Fothers%2Ffail-inject.md" target="_blank">https://github.com/apache/dubbo-go-pixiu/blob/develop/docs/sample/others/fail-inject.md</a></p><h2>1.5 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fdubbo-go-pixiu%2Fpull%2F522" target="_blank">Add GracefulShutdown Signal For Windows</a></h2><p>支持 Windows 優雅下線，Pixiu 關閉時避免流量損失。</p><pre><code class="language-yaml">static_resources:
.......
.......
  shutdown_config:
    timeout: "60s"
    step_timeout: "10s"
    reject_policy: "immediacy"
</code></pre><p>配置方式參考： <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fdubbo-go-pixiu-samples%2Ftree%2Fmain%2Fshutdown" target="_blank">https://github.com/apache/dubbo-go-pixiu-samples/tree/main/shutdown</a></p><h1>2 Enhancement in v1.0.0</h1><ul><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fdubbo-go-pixiu%2Fpull%2F573" target="_blank">優化 Prometheus 指標上報</a></li><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fdubbo-go-pixiu%2Fpull%2F530" target="_blank">修復一致性 Hash 數組越界</a></li><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fdubbo-go-pixiu%2Fpull%2F521" target="_blank">優化 Timeout 時的 http status code</a></li><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fdubbo-go-pixiu%2Fpull%2F528" target="_blank">優化 Metric 推拉模式</a></li><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fdubbo-go-pixiu%2Fpull%2F524" target="_blank">優化 Nacos 客戶端啓動時的參數配置</a></li><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fdubbo-go-pixiu%2Fpull%2F517" target="_blank">修復特定 Filter 配置為空時的 NPE 問題</a></li><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fdubbo-go-pixiu%2Fpull%2F515" target="_blank">升級 wasmer-go v1.0.4 以支持 Mac ARM 版本</a></li><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fdubbo-go-pixiu%2Fpull%2F506" target="_blank">fix sample url using github.com/apache/dubbo-go-pixiu-samples</a></li><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fdubbo-go-pixiu%2Fpull%2F507" target="_blank">修復流量管理路由權重計算錯誤的問題</a></li><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fdubbo-go-pixiu%2Fpull%2F513" target="_blank">修復負載均衡在特定情況下無法正常工作的問題</a></li><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fdubbo-go-pixiu%2Fpull%2F574" target="_blank">移除無用的 imports</a></li><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fdubbo-go-pixiu%2Fpull%2F575" target="_blank">chore: unnecessary use of fmt.Sprintf</a></li><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fdubbo-go-pixiu%2Fpull%2F567" target="_blank">chore:use wasm filter build tags add wasm</a></li><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fdubbo-go-pixiu%2Fpull%2F556" target="_blank">修復無法錯誤的 samples 鏈接等</a></li><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fdubbo-go-pixiu%2Fpull%2F557" target="_blank">revert gatewayCmd to Run dubbo go pixiu</a></li><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fdubbo-go-pixiu%2Fpull%2F516" target="_blank">升級 hessian2 依賴到 v1.11.3</a></li></ul><h1>3 參考文檔</h1><ul><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FRwIA7TitRfUMU8rTI4JsBg" target="_blank">What's new in dubbo-go-pixiu v0.6.0</a></li><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F5syzT64koPV77aRh04Izsw" target="_blank">What's new in dubbo-go-pixiu 0.5.1</a></li><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2Fdok42ssPJqazjeSRYaifVw" target="_blank">What's new in dubbo-go-pixiu 0.4.0</a></li><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FC7TxU0Zbee7EZ_6SJOLK8w" target="_blank">Dubbo 跨語言調用神獸：dubbo-go-pixiu</a></li></ul><h1>4 社區</h1><p>歡迎釘釘掃碼加入 dubbogo 社區釘釘羣【釘釘羣號 23331795】進行交流。</p><p><img src="https://oscimg.oschina.net/oscnet/up-ff09984b6821a6da40dcdb6db415fcca4b8.png" alt="" referrerpolicy="no-referrer"></p><p>以及 dubbogo 社區微信公眾號：</p><p><img src="https://oscimg.oschina.net/oscnet/up-8feb2024cbf754333e9d7564cd0316dbb71.jpg" alt="" referrerpolicy="no-referrer"></p><p>從今年開始，除了以往負責的 dubbogo 社區項目外，於雨還負責了 pika 項目 (<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FOpenAtomFoundation%2Fpika" target="_blank">https://github.com/OpenAtomFoundation/pika</a>)，如果對該項目感興趣，請掃碼：</p><p><img src="https://oscimg.oschina.net/oscnet/up-3e900aa69386ac2190edb8035f4abb68415.png" alt="" referrerpolicy="no-referrer"></p></div>
                                    ]]>
            </description>
            <pubDate>Sun, 26 Nov 2023 09:16:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/dubbogo/blog/10294380</guid>
            <link>https://my.oschina.net/dubbogo/blog/10294380</link>
            <author>
                <![CDATA[原創]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Linux 內核開發人員爭論基於優先級的 Shutdown 支持]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">Pengutronix 嵌入式 Linux 諮詢公司的 Oleksij Rempel 上週五發布了一系列<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flore.kernel.org%2Flkml%2F2023112403-laxative-lustiness-6a7f%40gregkh%2FT%2F" target="_blank">補丁</a>，提出了針<span style="background-color:#ffffff">對驅動程序/硬件的</span>基於優先級的 shutdown 支持。</span></p><p><span style="color:#000000">主要目的是<span style="background-color:#ffffff">在主線 Linux 內核提供優先關閉</span><span style="background-color:#ffffff">特定設備的功能</span>，「這在 power loss&nbsp;等情況下尤為重要，如果處理不當，可能會造成硬件損壞」。</span></p><p><span style="color:#000000">其內容<span style="background-color:#ffffff">重點在於，在</span>意外/<span style="background-color:#ffffff">即時&nbsp;shutdown&nbsp;</span>事件（例如電源/電壓下降或完全斷電）期間正確關閉關鍵設備。作為補丁系列的一部分，Oleksij Rempel&nbsp;還提出在 shutdown 階段將 (e)MMC 存儲設備設置為更高優先級，以幫助確保數據完整性/損壞。</span></p><p><img height="334" src="https://oscimg.oschina.net/oscnet/up-4ea11ce65c8b13c903a1f017372e8425e3b.png" width="500" referrerpolicy="no-referrer"></p><p><span style="color:#000000">Oleksij Rempel 的這一想法引發了 Linux 內核開發人員間的激烈討論，並形成了<span style="background-color:#ffffff">兩極分化的看法。</span><span style="background-color:#ffffff">Greg Kroah-Hartman&nbsp;</span>首先對這種基於優先級的<span style="background-color:#ffffff">&nbsp;shutdown&nbsp;</span>支持提出了質疑。他指出，這一做法會導致驅動程序和子系統之間出現優先級的爭奪：</span></p><blockquote><p><span style="color:#000000">每個驅動程序和子系統都堅持認為自己是最重要的！</span></p><p><span style="color:#000000">總之，從長遠來看，這樣做會帶來很多問題，這些硬件有什麼特別之處能使得其不可以按照現有順序 shutdown，而必須比其他人"優先"？這樣做究竟是為了防止什麼，哪些設備需要這樣做？</span></p><p><span style="color:#000000">最重要的是，在過去的 20 多年中，有什麼變化導致突然需要這種新功能，其他操作系統是如何處理的？</span></p></blockquote><p><span style="color:#000000">觀點雙方就<span style="background-color:#ffffff">主線 Linux 內核是否應該具有這樣的功能，以有效解決有問題的硬件設計做出了很多討論。最後事實證明，一些用於汽車行業的外層 Linux 內核版本已經提供了這種優先 shutdown 支持。Oleksij Rempel 將這一需求總結為：</span></span></p><blockquote><p><span style="color:#000000">它能防止硬件損壞。在典型的汽車欠壓測試中，通常可以在 Y 個欠壓週期內重現 X 個損壞的 eMMC 或 NAND（我現在沒有確切的數字）。即使在人工測試中出現的數量不是很多（有時一個月的測試中就會出現一個損壞的設備），但現場的回報率也很高，足以讓我們關心這個問題的軟件解決方案。</span></p><p><span style="color:#000000">同樣的問題不僅出現在汽車設備上，也出現在工業或農業設備上。換句話説，這個問題非常重要，必須要有某種解決方案。</span></p></blockquote><p><span style="color:#000000">對此，<span style="background-color:#ffffff">Greg 則用反問的語氣調侃稱，「這麼説的話，硬件試圖依靠軟件來防止同一硬件遭到破壞？硬件設計師肯定沒那麼瘋狂吧？」</span></span></p><p><span style="color:#000000">科技網站 Phoronix <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.phoronix.com%2Fnews%2FLinux-Priority-Based-Shutdown" target="_blank">評論</a>稱，從較高層次上來看，如果設備/驅動程序有充分的理由希望優先為設備 shutdown&nbsp;做好準備，例如可以防止數據丟失或獲得其他重大優勢，那麼這種基於優先級的 shutdown&nbsp;支持似乎沒有問題。但在實踐中，如果有多個驅動程序聲稱在 shutdown&nbsp;過程中擁有"優先權"，並且在確保設計可靠且能妥善解決實際問題方面存在其他障礙，那麼具體的實現就會存在一些困難。</span></p><p><span style="color:#000000">目前為止，大家對這種方法的意見還很不統一。現階段能否設計出一種既能為主線所接受，又能滿足汽車和更廣泛的嵌入式/工業領域需求的適當解決方案，還有待觀察。</span></p></div>
                                    ]]>
            </description>
            <pubDate>Sun, 26 Nov 2023 09:02:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/268371/linux-priority-based-shutdown</guid>
            <link>https://www.oschina.net/news/268371/linux-priority-based-shutdown</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[LG 成立 webOS 開發小組]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>LG 電子宣佈改革組織架構，併成立 webOS 開發小組。</p><p>11 月 24 日，LG 電子<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.lgnewsroom.com%2F2023%2F11%2Flg-electronics-announces-organizational-restructuring-for-future-growth%2F" target="_blank">發佈公告</a></u>稱將改革組織架構，以提升競爭力、促進增長。重組計劃包括為國際業務建立一個新的銷售和營銷公司，由 LG 電子北美公司前總裁兼首席執行官 Thomas Yoon 負責，管理世界各地的銷售子公司，以及直接面向消費者（D2C）的銷售業務集團。</p><p>此外，LG 家庭娛樂公司將成立 webOS 軟件開發小組，提高這一智能電視操作系統的實力，由該公司總裁直接領導；還將設立總部直屬的 XR 事業部。家電和空氣解決方案公司將增設工程銷售部門，併入其他部門的家居業務，以與家庭空間現有的產品陣容產生協同效應。車輛零部件解決方案公司將設立總部直屬的全球客戶戰略部。</p><blockquote><p><img height="400" src="https://oscimg.oschina.net/oscnet/up-cdf9a79048dc46240b393d4e2278760273b.png" width="1728" referrerpolicy="no-referrer"></p></blockquote><p>webOS 是基於 Linux 內核的智能電視操作系統，其前身是由&nbsp;Palm&nbsp;所開發的智能手機操作系統，最早於 2009 年面向公眾發佈。2010 年惠普收購 Palm，但之後終止了 Palm 手機和操作系統項目，並在 2011 年<u><a href="https://www.oschina.net/news/23908/hp-make-webos-opensource">決定開源</a></u>&nbsp;webOS。</p><p>2013 年，LG 宣佈收購惠普 webOS 部門，包括系統源代碼和僱員等。此後該操作系統被 LG 用於智能電視和電冰箱等產品。</p><p><img alt="080830_QqVe_2720166.png" src="https://static.oschina.net/uploads/space/2021/0302/080830_QqVe_2720166.png" referrerpolicy="no-referrer"></p><hr><p>延伸閲讀</p><ul><li><a href="https://www.oschina.net/news/131577/lg-says-it-will-license-webos-to-other-tv-mak">LG 將授權 webOS 給其他電視廠商使用</a></li><li><a href="https://www.oschina.net/news/94374/lg-webos-open-source-edition">LG 宣佈推出 webOS 開源版本，仍尋求將其商業化</a></li></ul></div>
                                    ]]>
            </description>
            <pubDate>Sun, 26 Nov 2023 06:00:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/268346</guid>
            <link>https://www.oschina.net/news/268346</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[三個月寫了個短信平台，開源出來！]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><img src="https://oscimg.oschina.net/oscnet/up-e82e722c7dca4558ca6271436d0dcfe9665.png" alt="" referrerpolicy="no-referrer"></p><h1>1 初心</h1><p>大家好，我是勇哥。花了三個月的時間，我手寫了個短信平台服務 <code>platform-sms</code>，今天開源出來 Beta 版本。</p><p>寫這個開源項目的初心其實很簡單："<strong>幫助初中級研發工程師入門架構設計，提升他們的技術認知</strong>"。</p><p>2018 年，作為架構師，我參與一個短信平台的重構。發送短信的場景包括還款業務、CRM、促銷業務等。</p><p>不同的技術團隊都是使用客戶端模式發送短信，但並不統一，大概分為四種 ：</p><ul><li>使用阿里雲提供的短信 SDK 發送短信 。</li><li>根據億美提供的樣例直接發送短信 。</li><li>使用綠城提供的短信 SDK 發送短信。</li><li>架構團隊短信 SDK ，類似於 <code>SMS4J</code>的設計方式，支持億美、綠城短信發送 。</li></ul><p>客戶端的模式在多團隊協作場景中，缺點還是很明顯：</p><ul><li><p><strong>維護成本</strong></p><p>假如運營不再使用某一個短信渠道，那麼很多團隊將會收到影響，不得不配合重新修改配置，重新上線，耗費的時間成本很高。</p></li><li><p><strong>無法支持高級功能</strong></p><p>客戶端實現某些功能比較麻煩，比如：客戶端因為偶發情況（網絡原因）通過三方渠道發送短信超時，此時需要將短信發送到備份渠道，從而確保短信發送的成功率。</p></li></ul><p>因此，多團隊協作的場景中，短信服務的模式應該是<strong>服務端模式</strong>。</p><p><img src="https://javayong.cn/pics/sms/server.png?a=23212" alt="服務端模式" referrerpolicy="no-referrer"></p><p>我參考了騰訊雲的短信服務的設計思路 ：</p><ol><li>模仿騰訊雲的 SDK 設計，提供簡單易用的發送短信方法 （單發，羣發，營銷單發，營銷羣發，模板單發，模板羣發） ；</li><li>設計短信服務 API 端，接收發短信請求，發送短信信息到消息隊列；</li><li>worker 服務消費消息，按照負載均衡的算法，調用不同渠道商的短信接口；</li><li>控制枱可以查看短信發送記錄，配置渠道商信息、模版信息等。</li></ol><p><img src="https://oscimg.oschina.net/oscnet/up-a7b05e5217cc92a8d6b17b9741ebb961d66.png" alt="" referrerpolicy="no-referrer"></p><p>短信平台研發完成之後，滿足了當時的業務需求，因為短信的管理也歸於統一，提升了業務接入短信服務的效率，所以各個技術團隊也比較認可。</p><p>隨着經驗的累積，我見過了不少公司的短信服務，核心問題不外乎兩點：</p><ol><li><p>短信服務與業務服務邊界問題。</p><p>為了滿足業務服務需求，在短信平台中添加過多的業務功能，導致短信服務功能臃腫，也不經意的加入了隱藏的風險 。</p></li><li><p>切換三方渠道非常不方便。</p><p>當運營端需要從三方短信渠道 A 切換到 B 時，因為代碼不夠抽象，增加三方渠道代碼時維護成本較高。</p></li></ol><p>基於這些原因，我想寫一個<strong>迷你版</strong>的短信服務，它應該包含如下的功能：</p><ol><li><p>簡單的短信 SDK 支持按照模版發送短信 。</p><p>業務服務對於短信是從哪一個三方短信渠道發送出來的並不在乎，只需要確保發送短信的成功率即可。</p><p>因此，SDK 提供的核心接口是：<strong>按照模版編號發送短信</strong>。</p><p>阿里雲、騰訊雲、華為雲提供的都是按照模版發送短信的接口，為了統一管理模版，我們也只提供按照模版發送短信的接口。</p><p>短信平台需要提供業務服務的<code>appKey</code> 和<code>appSecret</code> , SDK 與服務端之間通過固定協議交互。</p></li><li><p>短信平台支持模版的管理 。</p><p>阿里雲、騰訊雲、華為雲都提供簽名、模版管理的接口，因此從產品設計層面，理論上，我們可以通過短信平台管理所有的簽名和模版。</p><p>短信平台當前提供了手工綁定的短信模版的功能，也就是我們需要先在阿里雲或者騰訊雲先申請簽名和模版，然後綁定到我們在平台創建的模版。</p></li><li><p>適配器模式維護三方短信渠道。</p><p>參考了開源項目<code>canal</code>的適配器模塊，將三方短信渠道的 API 獨立成模塊單獨維護，這樣可以大大提升代碼的可維護性。</p></li></ol><h1>2 架構</h1><p>項目的設計應該設計得簡單，因為它的目標首先是讓<strong>初中級工程師快速入門架構設計</strong>。</p><p>所以，我將短信平台設計成<strong>單體應用</strong>的模式，架構圖如下：</p><p><img src="https://javayong.cn/pics/sms/smsjiagou.png" alt="" referrerpolicy="no-referrer"></p><p>短信平台分為兩個部分，<strong>這兩部分可以獨立部署，也可以將前端文件放置在後端中，生成單部署包。</strong></p><p><strong>1、前端：admin-ui</strong></p><p>控制枱模塊是 vue 項目，管理員登錄之後可以進行應用管理、渠道管理、短信管理、模版管理。</p><p><strong>2、後端：admin-web</strong></p><p>後端模塊按照功能依次分為五個模塊：請求控制層、業務服務層、命令處理器、三方渠道適配器插件、數據庫訪問層。</p><h1>3 演示</h1><h2>3.1 環境準備</h2><p><strong>1、創建數據庫以及相關表</strong></p><p>創建數據庫<code>tech_platform</code> ，執行<code> doc/sql</code> 目錄下的 <code> tech_platform.sql</code>。</p><p>執行後效果如下：</p><p><img src="https://javayong.cn/pics/sms/tables.png" alt="" referrerpolicy="no-referrer"></p><p><strong>2、修改部署包配置</strong></p><p>從 Release 下載 <code>platform-sms-admin.tar.gz</code> ，解壓縮後，進入 <code>conf </code>目錄 。</p><p><img src="https://javayong.cn/pics/sms//adminconfdir.png" alt="" referrerpolicy="no-referrer"></p><p>編輯 <code>application.yml </code> 文件：</p><p><img src="https://javayong.cn/pics/sms//prepare.png" alt="" referrerpolicy="no-referrer"></p><p>進入 bin 目錄，啓動服務：</p><pre><code class="language-sh">bin/startup.sh
</code></pre><h2>3.2 操作流程</h2><p><strong>1、登錄頁面</strong></p><p>服務啓動後，訪問地址：<code>http://localhost:8089</code> 。 <img src="https://javayong.cn/pics/sms/login.png" alt="" referrerpolicy="no-referrer"></p><blockquote><p>用戶名和密碼存儲在 <code>conf</code> 目錄的 <code>application.yml</code>，默認用戶名密碼分別是：admin/admin1984 。</p></blockquote><p><strong>2、新建應用</strong><img src="https://javayong.cn/pics/sms/createapp.png" alt="" referrerpolicy="no-referrer"></p><p>應用信息包含應用名稱、應用 <code>appKey</code> , <code>應用祕鑰</code>，<code>備註</code>。其中，應用 key 和，密鑰在使用客戶端 SDK 時需要配置 。</p><p><strong>3、新建三方短信渠道</strong><img src="https://javayong.cn/pics/sms/createchannel.png" alt="" referrerpolicy="no-referrer"></p><blockquote><p>注意：因為騰訊雲的 SDK 請求，中需要攜帶 APPID ，所以 Beta 版中將 appId 存儲在，附件屬性中。</p></blockquote><p><strong>4、創建模版</strong> 在<code>模版管理</code>模塊，點擊<code>新建模版</code>按鈕。</p><p><img src="https://javayong.cn/pics/sms/createtemplate.png" alt="" referrerpolicy="no-referrer"></p><p><strong>新建模版時，簽名名稱必須和渠道申請的簽名必須一致。</strong></p><p>下圖展示了筆者的騰訊雲申請的簽名，筆者創建的模版必須和騰訊雲賬號的簽名保持一致。</p><p><img src="https://javayong.cn/pics/sms/tencentsign.png" alt="" referrerpolicy="no-referrer"></p><p>創建完模版之後，需要綁定渠道，我們需要在三方渠道先創建短信模版，然後提交綁定。</p><ol><li>三方渠道先創建短信模版</li></ol><p><img src="https://javayong.cn/pics/sms/applytencenttemplate.png" alt="" referrerpolicy="no-referrer"></p><p>如上圖，筆者創建了編號為 1955325 的短信模版，因為我們需要在綁定界面綁定該渠道的模版，理論上在短信平台創建的模版可以綁定多個渠道。</p><ol start="2"><li><strong>綁定渠道</strong></li></ol><p><img src="https://javayong.cn/pics/sms/bingdingtemplate.png" alt="" referrerpolicy="no-referrer"></p><p>綁定完成之後，可以在模版管理頁面查看模版列表 。</p><p><img src="https://javayong.cn/pics/sms/templatelist.png" alt="" referrerpolicy="no-referrer"></p><h2>3.3 發送短信</h2><p>發送短信可以參考 DEMO 模塊：</p><p><img src="https://javayong.cn/pics/sms/demoproject.png" alt="" referrerpolicy="no-referrer"></p><p><strong>1、添加依賴</strong></p><pre><code class="language-xml">&lt;dependency&gt;
    &lt;groupId&gt;com.courage&lt;/groupId&gt;
    &lt;artifactId&gt;platform-sms-client&lt;/artifactId&gt;
    &lt;version&gt;${parent.version}&lt;/version&gt;
&lt;/dependency&gt;
</code></pre><p><strong>2、客戶端配置</strong></p><p>首先在 <code>application.yml </code>中配置如下：</p><pre><code class="language-yaml">sms:
  smsServerUrl: http://localhost:8089
  appKey: qQjEiFzn80v8VM4h
  appSecret: 9c465ece754bd26a9be77f3d0e2606bd
</code></pre><p>然後編寫配置類：</p><pre><code class="language-java">@Configuration
public class SmsConfiguration {

    @Value("${sms.smsServerUrl}")
    private String smsServerUrl;

    @Value("${sms.appKey}")
    private String appKey;

    @Value("${sms.appSecret}")
    private String appSecret;

    @Bean
    public SmsSenderClient createClient() {
        SmsConfig smsConfig = new SmsConfig();
        smsConfig.setAppKey(appKey);
        smsConfig.setSmsServerUrl(smsServerUrl);
        smsConfig.setAppSecret(appSecret);
        SmsSenderClient smsSenderClient = new SmsSenderClient(smsConfig);
        return smsSenderClient;
    }

}

</code></pre><p><strong>3、單發短信</strong></p><pre><code class="language-java">@Autowired
private SmsSenderClient smsSenderClient;

@GetMapping("/test")
public String test() {
    // 手機號
    String mobile = "15011319235";
    // 短信平台模版編號
    String templateId = "555829270636703745";
    // 模版參數
    Map&lt;String, String&gt; param = new HashMap&lt;String, String&gt;();
    param.put("code", "1234");
    param.put("time", "10");
    SmsSenderResult senderResult = smsSenderClient.sendSmsByTemplateId(mobile, templateId, param);
    System.out.println("senderResult:" + JSON.toJSONString(senderResult));
    return "hello , first short message !";
}
</code></pre><p>調用接口之後，用戶就會收到如下的短信：</p><p><img src="https://javayong.cn/pics/sms/sendsmssucceed.png?b" alt="" referrerpolicy="no-referrer"></p><h1>4 開源</h1><p><img src="https://javayong.cn/pics/sms/platformsmsgithub.png" alt="" referrerpolicy="no-referrer"></p><blockquote><p>代碼庫地址：</p><p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fmakemyownlife%2Fplatform-sms" target="_blank">https://github.com/makemyownlife/platform-sms</a></p></blockquote><p>勇哥想把這個項目做為架構入門的教學項目，您可以從中學到 ：</p><ol><li>設計一個精簡的客戶端 SDK 。</li><li>理解 SPI 機制以及適配器模式。</li><li>配置合理的線程模型。</li></ol><hr><p>如果我的文章對你有所幫助，還請幫忙<strong>點贊、在看、轉發</strong>一下，你的支持會激勵我輸出更高質量的文章，非常感謝！</p><p><img src="https://javayong.cn/pics/shipinhao/gongzhonghaonew.png" alt="" referrerpolicy="no-referrer"></p></div>
                                    ]]>
            </description>
            <pubDate>Sun, 26 Nov 2023 03:44:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/makemyownlife/blog/10243610</guid>
            <link>https://my.oschina.net/makemyownlife/blog/10243610</link>
            <author>
                <![CDATA[原創]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[報告：16% 的 AI 工作者正在使用開源模型]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">O'Reilly 發佈的一份"<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fae.oreilly.com%2FGenerative_AI_in_the_Enterprise" target="_blank">2023 Generative AI in the Enterprise</a>"報告<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.infoworld.com%2Farticle%2F3711380%2Fgenerative-ai-adoption-speed-unprecedented-oreilly-survey-says.html" target="_blank">指出</a>，由 OpenAI 的 GPT 大型語言模型和 ChatGPT 引領的生成式 AI 浪潮正在經歷前所未有的快速普及。</span></p><p><span style="color:#000000">報告基於 2013 年 9 月 14 日至 9 月 23 日期間收到的共 4782 份回覆。其中有 2857 名受訪者回答了所有問題。74% 的受訪者來自北美或歐洲。</span></p><p><img height="415" src="https://static.oschina.net/uploads/space/2023/1127/114145_aRHK_4252687.png" width="500" referrerpolicy="no-referrer"></p><p><span style="color:#000000">有三分之二的受訪者表示，他們已經在使用生成式 AI。"我們從未見過一項技術能像生成式 AI 一樣被如此快速地採用 -- 很難相信 ChatGPT 才誕生不到一年。"</span></p><p><span style="color:#000000">但與此同時，生成式 AI 技術在採用過程中仍存在一些問題。報告發現，難以找到商業用例以及對法律問題的擔憂阻礙了 AI 的發展。AI 解決方案的構思和實施不當可能會造成損害，而使用生成式 AI 的法律後果仍是未知數，例如存在誰擁有 AI 生成結果的版權等問題。</span></p><p><span style="color:#000000">並且一些公司文化還會制約 AI 的應用。另一方面，構建生成式 AI 建設基礎設施的難度和高成本也是一個令人擔憂的問題。</span></p><p><span style="color:#000000">報告的一些其他發現包括：</span></p><ul><li><span style="color:#000000">54% 的 AI 用戶預計 AI 的最大好處是提高生產力。</span></li><li><span style="color:#000000">77% 的受訪者使用 AI 來輔助編程。其中提到的具體應用包括欺詐檢測、教學和客戶關係管理。</span></li><li><span style="color:#000000">AI 用戶表示，AI 編程（66%）和數據分析（59%）是最需要的技能。</span></li><li><span style="color:#000000">許多 AI 採用者仍處於早期階段：26% 的人使用 AI 不到一年，而 18% 的人已經在生產中進行了應用。</span></li><li><span style="color:#000000">16% 的從事 AI 工作的受訪者表示正在使用開源模型。</span></li><li><span style="color:#000000">意外結果、安全性、公平性、偏見和隱私是採用者測試的最大風險。</span></li></ul><p><span style="color:#000000">詳情可<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fae.oreilly.com%2FGenerative_AI_in_the_Enterprise" target="_blank">查看完整報告</a>。&nbsp;</span></p></div>
                                    ]]>
            </description>
            <pubDate>Sun, 26 Nov 2023 03:40:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/268318/generative-ai-in-the-enterprise</guid>
            <link>https://www.oschina.net/news/268318/generative-ai-in-the-enterprise</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Fish Shell 採用 Rust 重寫會導致性能下降]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>fish 是適用於 Linux、macOS 的命令行 Shell，其名字取於 "the&nbsp;<strong>f</strong>riendly&nbsp;<strong>i</strong>nteractive&nbsp;<strong>sh</strong>ell" 的簡稱，最大特點就是方便易用、功能強大、智能並且用戶友好。很多其他 Shell 需要配置才有的功能，fish 默認提供，不需要任何配置。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-8ac37b9a595ea6b4d16839034fa3b00e68f.png" referrerpolicy="no-referrer"></p><p>項目維護者 Fabian Boehm 今天在 GitHub 迴應了<u><a href="https://www.oschina.net/news/226616/fish-shell-be-rewritten-rust">使用 Rust 重寫 Fish Shell</a></u>&nbsp;的進度，稱已幾乎完成。</p><p>根據開發者的説法，他們已經完成了從 C++ 到 Rust 的大部分移植工作，但還有一些剩餘的組件需要進行翻譯。目前，他們正在處理與輸入系統相關的讀取器、屏幕處理、輸入和分頁器等強耦合組件。一旦這些組件完成翻譯，剩下的工作就是一些零散的部分和去除構建系統的 C++ 依賴。</p><p>開發者表示，<strong>這不是一個適合臨時貢獻的項目</strong>，因為還有很多工作要做。</p><p>此外，開發者還回答了一些關於移植的問題和誤解。<strong>他們表示不會刪除所有的 C++ 代碼</strong>，也沒有計劃移植到 Windows 平台。他們還表示不會更改 Fish Shell 的名稱或吉祥物，並且對於最終移植的性能，他們表示早期結果是令人鼓舞的，<strong>但可能在某些情況下會比現有版本慢約 20%</strong>。</p><p>最後，他們提到即使完成了初始移植工作，項目也還有很多工作要做。</p><p>來源：<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Ffish-shell%2Ffish-shell%2Fdiscussions%2F10123">https://github.com/fish-shell/fish-shell/discussions/10123</a></u></p></div>
                                    ]]>
            </description>
            <pubDate>Sun, 26 Nov 2023 03:19:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/268315</guid>
            <link>https://www.oschina.net/news/268315</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[精選網站流量分析工具]]>
            </title>
            <description>
                <![CDATA[精選網站流量分析工具]]>
            </description>
            <pubDate>Sun, 26 Nov 2023 02:40:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/project/awesome?columnId=65</guid>
            <link>https://www.oschina.net/project/awesome?columnId=65</link>
        </item>
        <item>
            <title>
                <![CDATA[Numbat —— 用於科學計算的靜態類型編程語言]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="text-align:start"><span><span><span><span style="color:#000000"><span><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span>Numbat 是一種用於科學計算的靜態類型編程語言，對物理尺寸和單位具有一流的支持。</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></p><p style="text-align:start"><span><span><span><span style="color:#000000"><span><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span>可以使用它進行簡單的數學計算：</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></p><pre><code>&gt;&gt;&gt; 1920/16*9

    = 1080

&gt;&gt;&gt; 2^32

    = 4294967296

&gt;&gt;&gt; sqrt(1.4^2 + 1.5^2) * cos(pi/3)^2

    = 0.512957</code></pre><p style="text-align:start"><span><span><span><span style="color:#000000"><span><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span>然而，Numbat 的真正優勢在於使用物理單位執行計算：</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></p><pre><code>&gt;&gt;&gt; 8 km / (1 h + 25 min)

  8 kilometer / (1 hour + 25 minute)

    = 5.64706 km/h    [Velocity]

&gt;&gt;&gt; 140 € -&gt; GBP

  140 euro ➞ british_pound

    = 120.768 £    [Money]

&gt;&gt;&gt; atan2(30 cm, 1 m) -&gt; deg

  atan2(30 centimeter, 1 meter) ➞ degree

    = 16.6992°

&gt;&gt;&gt; let ω = 2π c / 660 nm

  let ω: Frequency = 2 π × c / 660 nanometer

&gt;&gt;&gt; ℏ ω -&gt; eV

  ℏ × ω ➞ electronvolt

    = 1.87855 eV    [Energy]</code></pre></div>
                                                                ]]>
            </description>
            <pubDate>Sun, 26 Nov 2023 02:25:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/p/numbat</guid>
            <link>https://www.oschina.net/p/numbat</link>
        </item>
        <item>
            <title>
                <![CDATA[阿里達摩院撤裁量子實驗室，已將實驗室及儀器設備贈予浙江大學]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>此前網傳阿里巴巴達摩院由於預算及盈利等原因，已經撤裁旗下量子實驗室。</p><blockquote><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-f56d238fc4cd0472484cff8074725c56bb7.png" referrerpolicy="no-referrer"></p></blockquote><p>對此，阿里巴巴達摩院相關人士迴應九派財經稱，為了進一步推動量子科技協同發展，達摩院聯合浙江大學發展量子科技，<strong>達摩院將量子實驗室及可移交的量子實驗儀器設備捐贈予浙江大學</strong>，並向其他高校和科研機構進行開放。</p><p>目前，達摩院量子實驗室網站已撤下之前的所有內容 (<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdamo.alibaba.com%2Flabs%2Fquantum%2F%3Flang%3Dzh" target="_blank">https://damo.alibaba.com/labs/quantum/?lang=zh</a></u>)。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-1fe3290832247ef64372a3cecccec9e368c.png" referrerpolicy="no-referrer"></p><p>「中國科學院-阿里巴巴量子計算實驗室（AQL）」於 2015 年 7 月 30 日揭牌成立，計劃在量子信息科學領域開展前瞻性研究，研製量子計算機。根據該聯合實驗室的研究計劃：</p><ul><li><p>預計到 2025 年，量子模擬將達到當今世界最快的超級計算機的水平；</p></li><li><p>到 2030 年，研製具有 50—100 個量子比特的通用量子計算原型機，突破大規模量子計算機的芯片工藝，從物理層設計、製造，到算法運行實現自主研發，全面實現通用量子計算功能，並應用於大數據處理等重大實際問題。</p></li></ul><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-ab648e496bed5f27f8694b13032b63f27da.png" referrerpolicy="no-referrer"></p><p>達摩院此前在該領域進行了長期投入，配置了國際領先的量子實驗專用儀器設備，建成 Lab-1、Lab-2 兩座硬件實驗室，具備量子計算軟硬件全棧開發能力。</p><p>除此之外，達摩院在芯片製備、比特相干時長、門操控、量子糾錯，量子計算控制架構等領域取得了多個重要成果，包括高精度、多比特超導量子芯片，量子電路經典模擬器「太章」等。</p><hr><p><strong>延伸閲讀</strong></p><ul><li><a href="https://www.oschina.net/news/259545" target="news">百度發佈首個量子領域大模型</a></li><li><a href="https://www.oschina.net/news/203591/cirq-1-0-released" target="news">谷歌發佈量子編程框架 Cirq 1.0 版本</a></li><li><a href="https://www.oschina.net/news/180254/mit-new-language-quantum-computing-twist" target="news">MIT 推出用於量子計算的編程語言 Twist</a></li><li><a href="https://www.oschina.net/news/124369/alibaba-open-source-taizhang-2-0" target="news">阿里開源量子模擬器 「太章 2.0」</a></li><li><a href="https://www.oschina.net/news/122471/china-quantum-hegemony" target="news">中國「量子霸權」成果：比最快超級計算機快一百萬億倍</a></li><li><a href="https://www.oschina.net/news/117459/us-plans-quantum-internet" target="news">美國發布量子互聯網藍圖：十年內建成</a></li><li><a href="https://www.oschina.net/news/116574/silq-programming-language-for-quantum-computers" target="news">量子計算機領域內第一種高級編程語言 Silq 誕生</a></li><li><a href="https://www.oschina.net/news/108172/microsoft-quantum-oss-available-github" target="news">微軟宣佈開源量子開發工具包</a></li><li><a href="https://www.oschina.net/news/98474/google-opensource-cirq" target="news">擁抱新時代，Google 開源量子算法框架 CIRQ</a></li></ul></div>
                                    ]]>
            </description>
            <pubDate>Sun, 26 Nov 2023 02:21:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/268299</guid>
            <link>https://www.oschina.net/news/268299</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Gitee 推薦 | 輕量級本地化熱點檢測/降級框架 Akali]]>
            </title>
            <description>
                <![CDATA[<p align="center"><a href="https://gitee.com/link?target=https%3A%2F%2Fakali.yomahub.com%2F"><img src="https://gitee.com/dromara/Akali/raw/master/static/img/logo-main.svg" height="auto" alt="logo" referrerpolicy="no-referrer"></a></p><h3><a id="user-content-官網 httpsakaliyomahubcom" class="anchor" href="https://gitee.com/dromara/Akali#%E5%AE%98%E7%BD%91httpsakaliyomahubcom"></a>官網：<a href="https://gitee.com/link?target=https%3A%2F%2Fakali.yomahub.com">https://akali.yomahub.com</a></h3><h3><a id="user-content-介紹" class="anchor" href="https://gitee.com/dromara/Akali#%E4%BB%8B%E7%BB%8D"></a>介紹</h3><p>Akali（阿卡麗）是一個輕量級本地化熱點檢測/降級框架，適用於大流量場景，可輕鬆解決業務中超高流量的併發查詢等場景。並且接入和使用極其簡單，10 秒鐘即可接入使用！</p><p>Akali 框架的理念就是小巧，實用，來無影去無蹤，絲血團戰，滿血退場，所到之處，皆為虛無。</p><h3><a id="user-content-使用" class="anchor" href="https://gitee.com/dromara/Akali#%E4%BD%BF%E7%94%A8"></a>使用</h3><p>引入依賴：</p><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"><span class="nt">&lt;dependency&gt;</span></span><span id="LC2" class="line"><span class="nt">&lt;groupId&gt;</span>org.dromara<span class="nt">&lt;/groupId&gt;</span></span><span id="LC3" class="line"><span class="nt">&lt;artifactId&gt;</span>akali<span class="nt">&lt;/artifactId&gt;</span></span><span id="LC4" class="line"><span class="nt">&lt;version&gt;</span>1.1.3<span class="nt">&lt;/version&gt;</span></span><span id="LC5" class="line"><span class="nt">&lt;/dependency&gt;</span></span></pre><div class="markdown-code-block-copy-btn"></div></div></div><h4><a id="user-content-對任意方法進行熱點處理" class="anchor" href="https://gitee.com/dromara/Akali#%E5%AF%B9%E4%BB%BB%E6%84%8F%E6%96%B9%E6%B3%95%E8%BF%9B%E8%A1%8C%E7%83%AD%E7%82%B9%E5%A4%84%E7%90%86"></a>對任意方法進行熱點處理</h4><p>只需要加上<code>@AkaliHot</code>這個標註，任意方法均可以獲得熱點檢測，並在熱點期間用熱點數據進行返回，在熱點過後，又會自動調用原本業務邏輯。</p><p>舉例：比如有一個商品查詢的業務，傳入 SkuCode，返回商品信息。當某個商品進行促銷時，訪問的量就會增加，但是對於相同的 SkuCode 而言，其短時間窗口內返回的 SkuInfo 是一致的，我們的目標是當某個商品 sku 被大量查詢時，框架能夠在短時間內把這個商品 sku 提為熱點數據，並通過對其進行緩存返回來降低對下游業務的壓力。而當熱點值過後，框架又能夠自動摘除這個熱點值，使其按照原有方式進行查詢。</p><p>其本質相當於實時的監測了熱點，並對其熱點數據做了一個短時間內的緩存。</p><p>以下示例代表了：當相同的 skuCode 在 5 秒內超過 50 次調用時，會自動把這個 skuCode 的值提為熱點，並用最後一次的返回值直接返回。當調用低於 5 秒 50 次調用時，框架會自動的摘除掉這個熱點。使其正常的調用你原有代碼進行邏輯計算並返回。這一切都是自動的。</p><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"><span class="nd">@AkaliHot</span><span class="o">(</span><span class="n">grade</span><span class="o">=</span><span class="nc">FlowGradeEnum</span><span class="o">.</span><span class="na">FLOW_GRADE_QPS</span><span class="o">,</span><span class="n">count</span><span class="o">=</span><span class="mi">50</span><span class="o">,</span><span class="n">duration</span><span class="o">=</span><span class="mi">5</span><span class="o">)</span></span><span id="LC2" class="line"><span class="kd">public</span><span class="nc">SkuInfo</span><span class="nf">getSkuInfo</span><span class="o">(</span><span class="nc">String</span><span class="n">skuCode</span><span class="o">){</span></span><span id="LC3" class="line"><span class="c1">//do your biz and return sku info</span></span><span id="LC4" class="line"><span class="o">}</span></span></pre><div class="markdown-code-block-copy-btn"></div></div></div><p>其中<code>grade</code>參數除了有以<code>QPS</code>作為維度統計，還有以<code>Thread</code>個數作為維度統計。比如：</p><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"><span class="nd">@AkaliHot</span><span class="o">(</span><span class="n">grade</span><span class="o">=</span><span class="nc">FlowGradeEnum</span><span class="o">.</span><span class="na">FLOW_GRADE_THREAD</span><span class="o">,</span><span class="n">count</span><span class="o">=</span><span class="mi">50</span><span class="o">,</span><span class="n">duration</span><span class="o">=</span><span class="mi">5</span><span class="o">)</span></span><span id="LC2" class="line"><span class="kd">public</span><span class="nc">SkuInfo</span><span class="nf">getSkuInfo</span><span class="o">(</span><span class="nc">String</span><span class="n">skuCode</span><span class="o">){</span></span><span id="LC3" class="line"><span class="c1">//do your biz and return sku info</span></span><span id="LC4" class="line"><span class="o">}</span></span></pre><div class="markdown-code-block-copy-btn"></div></div></div><p>這就代表了，如果某個 skuCode 在 5 秒之內有超過 50 個線程正在運行，那麼就提為熱點，並用熱點數據直接返回。</p><p>對開源項目比較熟悉的同學看到這肯定想到了京東的框架-<code>hotkey</code>，<code>Akali</code>不同於<code>hotkey</code>，完全是本地運行的，不依賴於服務端，而且接入比<code>hotkey</code> 方便多了。性能完全相當於<code>hotkey</code>。</p><h4><a id="user-content-對任意方法進行降級" class="anchor" href="https://gitee.com/dromara/Akali#%E5%AF%B9%E4%BB%BB%E6%84%8F%E6%96%B9%E6%B3%95%E8%BF%9B%E8%A1%8C%E9%99%8D%E7%BA%A7"></a>對任意方法進行降級</h4><p>只需要加上<code>@AkaliFallback</code>註解。任意方法均可獲得降級功能。</p><p>舉例：某一個方法需要調用外部的接口，但是外部的接口性能不佳，耗時高。當併發一高時，線程池就會吃滿，線程池隊列也會逐漸堆積從而導致超時，或者丟棄，嚴重時會拖垮整個系統。</p><p>這時，我們只要對這個方法加上<code>@AkaliFallback</code>標註，即可解決。</p><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"><span class="nd">@AkaliFallback</span><span class="o">(</span><span class="n">grade</span><span class="o">=</span><span class="nc">FlowGradeEnum</span><span class="o">.</span><span class="na">FLOW_GRADE_THREAD</span><span class="o">,</span><span class="n">count</span><span class="o">=</span><span class="mi">100</span><span class="o">)</span></span><span id="LC2" class="line"><span class="kd">public</span><span class="nc">String</span><span class="nf">sayHi</span><span class="o">(</span><span class="nc">String</span><span class="n">name</span><span class="o">){</span></span><span id="LC3" class="line"><span class="k">return</span><span class="s">"hi,"</span><span class="o">+</span><span class="n">name</span><span class="o">;</span></span><span id="LC4" class="line"><span class="o">}</span></span><span id="LC5" class="line"></span><span id="LC6" class="line"><span class="kd">public</span><span class="nc">String</span><span class="nf">sayHiFallback</span><span class="o">(</span><span class="nc">String</span><span class="n">name</span><span class="o">){</span></span><span id="LC7" class="line"><span class="k">return</span><span class="s">"fallback str"</span><span class="o">;</span></span><span id="LC8" class="line"><span class="o">}</span></span></pre><div class="markdown-code-block-copy-btn"></div></div></div><p>以上註解表示了，當這個方法的同時運行的線程超過 100 個時，觸發降級，降級會自動調用<code>原方法名+Fallback</code>方法名 (並且參數要一致)，當降級觸發後會直接返回<code>fallback str</code>，當線程數小於 100 時，框架也會自動摘除降級，還是輸出<code>hi,xxxx</code>。</p><p>如果你的類中沒有定義 fallback 方法，那麼觸發降級時會報錯，當然你可以在降級方法中去拋錯，來讓上游系統知道你這個方法已經達到了瓶頸。</p><h3><a id="user-content-注意事項" class="anchor" href="https://gitee.com/dromara/Akali#%E6%B3%A8%E6%84%8F%E4%BA%8B%E9%A1%B9"></a>注意事項</h3><p>Akali 只針對於 Springboot，Spring 環境，並且所有標註了<code>@AkaliHot</code>或者<code>@AkaliFallback</code>的類一定得註冊到 spring 上下文中。</p><p>Akali 在 springboot 中會自動掃描所有標註的類，您無需做任何配置，在 spring 中，你需要配置：</p><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"><span class="nt">&lt;bean</span><span class="na">class=</span><span class="s">"org.dromara.akali.strategy.FallbackStrategy"</span><span class="nt">/&gt;</span></span><span id="LC2" class="line"><span class="nt">&lt;bean</span><span class="na">class=</span><span class="s">"org.dromara.akali.strategy.MethodHotspotStrategy"</span><span class="nt">/&gt;</span></span><span id="LC3" class="line"><span class="nt">&lt;bean</span><span class="na">class=</span><span class="s">"org.dromara.akali.spring.AkaliScanner"</span><span class="nt">/&gt;</span></span></pre><div class="markdown-code-block-copy-btn"></div></div></div><h3><a id="user-content-交流羣" class="anchor" href="https://gitee.com/dromara/Akali#%E4%BA%A4%E6%B5%81%E7%BE%A4"></a>交流羣</h3><img src="https://gitee.com/dromara/Akali/raw/master/static/img/chat.png" referrerpolicy="no-referrer">]]>
            </description>
            <pubDate>Sun, 26 Nov 2023 02:11:00 GMT</pubDate>
            <guid isPermaLink="false">https://gitee.com/dromara/Akali</guid>
            <link>https://gitee.com/dromara/Akali</link>
        </item>
        <item>
            <title>
                <![CDATA[每日一博 | 深入理解 BigBird 的塊稀疏注意力]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div class="rich_media_content js_underline_content
                       autoTypeSetting24psection
            " id="js_content"><section data-tool="mdnice 編輯器" data-website="https://www.mdnice.com" style="font-size: 16px;color: black;padding-right: 10px;padding-left: 10px;line-height: 1.6;letter-spacing: 0px;word-break: break-word;text-align: left;font-family: Roboto, Oxygen, Ubuntu, Cantarell, PingFangSC-regular, PingFangTC-regular, &quot;Open Sans&quot;, &quot;Helvetica Neue&quot;, sans-serif;" data-mpa-powered-by="yiban.io"><span id="OSC_h2_1"></span><h2 data-tool="mdnice 編輯器" style="font-weight: bold;font-size: 22px;line-height: 1.2em;margin-top: 2em;margin-bottom: 35px;color: rgb(255, 157, 0);"><span style="color: rgb(255, 157, 11);visibility: visible;display: inline-block;border-left: 5px solid rgb(255, 157, 0);padding: 2px 13px;margin-right: 3px;height: 50%;font-size: 18px;">引言</span><span style="font-size: 18px;color: rgb(255, 157, 11);display: inline-block;padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;"></span></h2><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">基於 transformer 的模型已被證明對很多 NLP 任務都非常有用。然而，<span style="cursor:pointer;"><span role="presentation" data-formula="O(n^2)" data-formula-type="inline-equation" style=""><svg
                xmlns="http://www.w3.org/2000/svg" role="img" focusable="false" viewBox="0 -833.9 2544.6 1083.9" aria-hidden="true" style="vertical-align: -0.566ex;width: 5.757ex;height: 2.452ex;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="4F" d="M740 435Q740 320 676 213T511 42T304 -22Q207 -22 138 35T51 201Q50 209 50 244Q50 346 98 438T227 601Q351 704 476 704Q514 704 524 703Q621 689 680 617T740 435ZM637 476Q637 565 591 615T476 665Q396 665 322 605Q242 542 200 428T157 216Q157 126 200 73T314 19Q404 19 485 98T608 313Q637 408 637 476Z"></path></g><g data-mml-node="mo" transform="translate(763, 0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="msup" transform="translate(1152, 0)"><g data-mml-node="mi"><path data-c="6E" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mn" transform="translate(600, 363) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g></g><g data-mml-node="mo" transform="translate(2155.6, 0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g></g></svg></span></span> 的時間和內存複雜度 (其中 <span style="cursor:pointer;"><span role="presentation" data-formula="n" data-formula-type="inline-equation" style=""><svg
                xmlns="http://www.w3.org/2000/svg" role="img" focusable="false" viewBox="0 -442 600 453" aria-hidden="true" style="vertical-align: -0.025ex;width: 1.357ex;height: 1.025ex;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="6E" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g></g></g></svg></span></span> 是序列長度) 使得在長序列 (<span style="cursor:pointer;"><span role="presentation" data-formula="n > 512" data-formula-type="inline-equation" style=""><svg
                xmlns="http://www.w3.org/2000/svg" role="img" focusable="false" viewBox="0 -666 3433.6 706" aria-hidden="true" style="vertical-align: -0.09ex;width: 7.768ex;height: 1.597ex;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="6E" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(877.8, 0)"><path data-c="3E" d="M84 520Q84 528 88 533T96 539L99 540Q106 540 253 471T544 334L687 265Q694 260 694 250T687 235Q685 233 395 96L107 -40H101Q83 -38 83 -20Q83 -19 83 -17Q82 -10 98 -1Q117 9 248 71Q326 108 378 132L626 250L378 368Q90 504 86 509Q84 513 84 520Z"></path></g><g data-mml-node="mn" transform="translate(1933.6, 0)"><path data-c="35" d="M164 157Q164 133 148 117T109 101H102Q148 22 224 22Q294 22 326 82Q345 115 345 210Q345 313 318 349Q292 382 260 382H254Q176 382 136 314Q132 307 129 306T114 304Q97 304 95 310Q93 314 93 485V614Q93 664 98 664Q100 666 102 666Q103 666 123 658T178 642T253 634Q324 634 389 662Q397 666 402 666Q410 666 410 648V635Q328 538 205 538Q174 538 149 544L139 546V374Q158 388 169 396T205 412T256 420Q337 420 393 355T449 201Q449 109 385 44T229 -22Q148 -22 99 32T50 154Q50 178 61 192T84 210T107 214Q132 214 148 197T164 157Z"></path><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z" transform="translate(500, 0)"></path><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z" transform="translate(1000, 0)"></path></g></g></g></svg></span></span>) 上應用它們變得非常昂貴，因而大大限制了其應用。最近的幾篇論文，如 <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">Longformer</code> 、<code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">Performer</code> 、<code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">Reformer</code> 、<code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">簇狀注意力</code> 都試圖通過對完整注意力矩陣進行近似來解決這個問題。如果你不熟悉這些模型，可以查看 🤗 之前的，博文。</p><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);"><code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">BigBird</code> (由，該論文，引入) 是解決這個問題的最新模型之一。 <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">BigBird</code> 依賴於 <strong style="color: black;">塊稀疏注意力</strong> 而不是普通注意力 ( <em style="color: black;">即</em> BERT 的注意力)，與 BERT 相比，這一新算法能以低得多的計算成本處理長達 <strong style="color: black;">4096</strong> 的序列。在涉及很長序列的各種任務上，該模型都實現了 SOTA，例如長文檔摘要、長上下文問答。</p><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);"><strong style="color: black;">RoBERTa 架構的 BigBird</strong> 模型現已集成入 🤗 transformers 中。本文的目的是讓讀者 <strong style="color: black;">深入</strong> 瞭解 BigBird 的實現，並讓讀者能在 🤗 transformers 中輕鬆使用 BigBird。但是，在更深入之前，一定記住 <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">BigBird</code> 注意力只是 <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">BERT</code> 完全注意力的一個近似，因此我們並不糾結於讓它比 <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">BERT</code> 完全注意力 <strong style="color: black;">更好</strong>，而是致力於讓它更有效率。有了它，transformer 模型就可以作用於更長的序列，因為 BERT 的二次方內存需求很快會變得難以為繼。簡而言之，如果我們有 <span style="cursor:pointer;"><span role="presentation" data-formula="\infty" data-formula-type="inline-equation" style=""><svg
                xmlns="http://www.w3.org/2000/svg" role="img" focusable="false" viewBox="0 -442 1000 453" aria-hidden="true" style="vertical-align: -0.025ex;width: 2.262ex;height: 1.025ex;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="221E" d="M55 217Q55 305 111 373T254 442Q342 442 419 381Q457 350 493 303L507 284L514 294Q618 442 747 442Q833 442 888 374T944 214Q944 128 889 59T743 -11Q657 -11 580 50Q542 81 506 128L492 147L485 137Q381 -11 252 -11Q166 -11 111 57T55 217ZM907 217Q907 285 869 341T761 397Q740 397 720 392T682 378T648 359T619 335T594 310T574 285T559 263T548 246L543 238L574 198Q605 158 622 138T664 94T714 61T765 51Q827 51 867 100T907 217ZM92 214Q92 145 131 89T239 33Q357 33 456 193L425 233Q364 312 334 337Q285 380 233 380Q171 380 132 331T92 214Z"></path></g></g></g></svg></span></span> 計算和 <span style="cursor:pointer;"><span role="presentation" data-formula="\infty" data-formula-type="inline-equation" style=""><svg
                xmlns="http://www.w3.org/2000/svg" role="img" focusable="false" viewBox="0 -442 1000 453" aria-hidden="true" style="vertical-align: -0.025ex;width: 2.262ex;height: 1.025ex;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="221E" d="M55 217Q55 305 111 373T254 442Q342 442 419 381Q457 350 493 303L507 284L514 294Q618 442 747 442Q833 442 888 374T944 214Q944 128 889 59T743 -11Q657 -11 580 50Q542 81 506 128L492 147L485 137Q381 -11 252 -11Q166 -11 111 57T55 217ZM907 217Q907 285 869 341T761 397Q740 397 720 392T682 378T648 359T619 335T594 310T574 285T559 263T548 246L543 238L574 198Q605 158 622 138T664 94T714 61T765 51Q827 51 867 100T907 217ZM92 214Q92 145 131 89T239 33Q357 33 456 193L425 233Q364 312 334 337Q285 380 233 380Q171 380 132 331T92 214Z"></path></g></g></g></svg></span></span> 時間，那麼用 BERT 注意力就好了，完全沒必要用本文討論的塊稀疏注意力。</p><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">如果你想知道為什麼在處理較長序列時需要更多計算，那麼本文正合你意！</p><hr data-tool="mdnice 編輯器" style="height: 1px;border-right: none;border-bottom: none;border-left: none;border-top-style: solid;border-top-color: rgb(249, 191, 69);margin-top: 20px;margin-bottom: 20px;"><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">在使用標準的 <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">BERT</code> 類注意力時可能會遇到以下幾個主要問題:</p><ul data-tool="mdnice 編輯器" style="margin-top: 8px;margin-bottom: 8px;padding-left: 25px;" class="list-paddingleft-1"><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);">
      每個詞元真的都必須關注所有其他詞元嗎？ 
    </section></li><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);">
      為什麼不只計算重要詞元的注意力？ 
    </section></li><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);">
      如何決定哪些詞元重要？ 
    </section></li><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);">
      如何以高效的方式處理少量詞元？ 
    </section></li></ul><hr data-tool="mdnice 編輯器" style="height: 1px;border-right: none;border-bottom: none;border-left: none;border-top-style: solid;border-top-color: rgb(249, 191, 69);margin-top: 20px;margin-bottom: 20px;"><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">本文，我們將嘗試回答這些問題。</p><span id="OSC_h3_2"></span><h3 data-tool="mdnice 編輯器" style="font-weight: bold;font-size: 20px;line-height: 1.4;padding-top: 10px;margin-top: 10px;margin-bottom: 5px;"><span style="display: none;"></span><span style="color: rgb(81, 81, 81);font-size: 17px;padding-left: 1em;border-left: 3px solid rgb(249, 191, 69);">應該關注哪些詞元？</span><span style="display: none;"></span></h3><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">下面，我們將以句子 <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">BigBird is now available in HuggingFace for extractive Question Answering</code> 為例來説明注意力是如何工作的。在 <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">BERT</code> 這類的注意力機制中，每個詞元都簡單粗暴地關注所有其他詞元。從數學上來講，這意味着每個查詢的詞元 <span style="cursor:pointer;"><span role="presentation" data-formula=" \text{query-token} \in {\text{BigBird},\text{is},\text{now},\text{available},\text{in},\text{HuggingFace},\text{for},\text{extractive},\text{question},\text{answering}} " data-formula-type="inline-equation" style=""><embed style="vertical-align: -0.466ex;width: 90.929ex;height: auto;" src="https://oscimg.oschina.net/oscnet/3cb299f5-0dd9-498e-b671-c2cc91093e23.svg" data-type="svg+xml" data-imgfileid="100005775"></span></span>, 將關注每個鍵詞元 <span style="cursor:pointer;"><span role="presentation" data-formula="\text{key-tokens} = \left[\text{BigBird},\text{is},\text{now},\text{available},\text{in},\text{HuggingFace},\text{for},\text{extractive},\text{question},\text{answering} \right]" data-formula-type="inline-equation" style=""><embed style="vertical-align: -0.566ex;width: 91.185ex;height: auto;" src="https://oscimg.oschina.net/oscnet/f6bb45bf-4d15-409c-a819-d8e70016a46a.svg" data-type="svg+xml" data-imgfileid="100005777"></span></span>。</p><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">我們考慮一下 <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">每個查詢詞元應如何明智地選擇它實際上應該關注的鍵詞元</code> 這個問題，下面我們通過編寫偽代碼的方式來整理思考過程。</p><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">假設 <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">available</code> 是當前查詢詞元，我們來構建一個合理的、需要關注的鍵詞元列表。</p><pre data-tool="mdnice 編輯器" style="margin-top: 10px;margin-bottom: 10px;"><code style="overflow-x: auto;padding: 16px;color: #333;background: #f8f8f8;display: -webkit-box;font-family: Operator Mono, Consolas, Monaco, Menlo, monospace;border-radius: 0px;font-size: 12px;-webkit-overflow-scrolling: touch;"><span style="color: #998;font-style: italic;line-height: 26px;">#&nbsp;以下面的句子為例</span><br>example&nbsp;=&nbsp;[<span style="color: #d14;line-height: 26px;">'BigBird'</span>,&nbsp;<span style="color: #d14;line-height: 26px;">'is'</span>,&nbsp;<span style="color: #d14;line-height: 26px;">'now'</span>,&nbsp;<span style="color: #d14;line-height: 26px;">'available'</span>,&nbsp;<span style="color: #d14;line-height: 26px;">'in'</span>,&nbsp;<span style="color: #d14;line-height: 26px;">'HuggingFace'</span>,&nbsp;<span style="color: #d14;line-height: 26px;">'for'</span>,&nbsp;<span style="color: #d14;line-height: 26px;">'extractive'</span>,&nbsp;<span style="color: #d14;line-height: 26px;">'question'</span>,&nbsp;<span style="color: #d14;line-height: 26px;">'answering'</span>]<br><br><span style="color: #998;font-style: italic;line-height: 26px;">#&nbsp;假設當前需要計算&nbsp;'available'&nbsp;這個詞的表徵</span><br>query_token&nbsp;=&nbsp;<span style="color: #d14;line-height: 26px;">'available'</span><br><br><span style="color: #998;font-style: italic;line-height: 26px;">#&nbsp;初始化一個空集合，用於放&nbsp;'available'&nbsp;這個詞的鍵詞元</span><br>key_tokens&nbsp;=&nbsp;[]&nbsp;<span style="color: #998;font-style: italic;line-height: 26px;">#&nbsp;=&gt;&nbsp;目前，'available'&nbsp;詞元不關注任何詞元</span><br></code></pre><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">鄰近詞元當然很重要，因為在一個句子 (單詞序列) 中，當前詞高度依賴於前後的鄰近詞。<code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">滑動注意力</code> 即基於該直覺。</p><pre data-tool="mdnice 編輯器" style="margin-top: 10px;margin-bottom: 10px;"><code style="overflow-x: auto;padding: 16px;color: #333;background: #f8f8f8;display: -webkit-box;font-family: Operator Mono, Consolas, Monaco, Menlo, monospace;border-radius: 0px;font-size: 12px;-webkit-overflow-scrolling: touch;"><span style="color: #998;font-style: italic;line-height: 26px;">#&nbsp;考慮滑動窗大小為&nbsp;3,&nbsp;即將&nbsp;'available'&nbsp;的左邊一個詞和右邊一個詞納入考量</span><br><span style="color: #998;font-style: italic;line-height: 26px;">#&nbsp;左詞:&nbsp;'now';&nbsp;右詞:&nbsp;'in'</span><br>sliding_tokens&nbsp;=&nbsp;[<span style="color: #d14;line-height: 26px;">"now"</span>,&nbsp;<span style="color: #d14;line-height: 26px;">"available"</span>,&nbsp;<span style="color: #d14;line-height: 26px;">"in"</span>]<br><br><span style="color: #998;font-style: italic;line-height: 26px;">#&nbsp;用以上詞元更新集合</span><br>key_tokens.append(sliding_tokens)<br></code></pre><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);"><strong style="color: black;">長程依賴關係:</strong> 對某些任務而言，捕獲詞元間的長程關係至關重要。 <em style="color: black;">例如</em> ，在問答類任務中，模型需要將上下文的每個詞元與整個問題進行比較，以便能夠找出上下文的哪一部分對正確答案有用。如果大多數上下文詞元僅關注其他上下文詞元，而不關注問題，那麼模型從不太重要的上下文詞元中過濾重要的上下文詞元就會變得更加困難。</p><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);"><code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">BigBird</code> 提出了兩種允許長程注意力依賴的方法，這兩種方法都能保證計算效率。</p><ul data-tool="mdnice 編輯器" style="margin-top: 8px;margin-bottom: 8px;padding-left: 25px;" class="list-paddingleft-1"><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);"><strong style="color: black;">全局詞元:</strong> 引入一些詞元，這些詞元將關注每個詞元並且被每個詞元關注。例如，對 
     <em style="color: black;">「HuggingFace is building nice libraries for easy NLP」</em> ，現在假設 
     <em style="color: black;">'building'</em> 被定義為全局詞元，而對某些任務而言，模型需要知道 
     <em style="color: black;">'NLP'</em> 和 
     <em style="color: black;">'HuggingFace'</em> 之間的關係 (注意: 這 2 個詞元位於句子的兩端); 現在讓 
     <em style="color: black;">'building'</em> 在全局範圍內關注所有其他詞元，會對模型將 
     <em style="color: black;">'NLP'</em> 與 
     <em style="color: black;">'HuggingFace'</em> 關聯起來有幫助。 
    </section></li></ul><pre data-tool="mdnice 編輯器" style="margin-top: 10px;margin-bottom: 10px;"><code style="overflow-x: auto;padding: 16px;color: #333;background: #f8f8f8;display: -webkit-box;font-family: Operator Mono, Consolas, Monaco, Menlo, monospace;border-radius: 0px;font-size: 12px;-webkit-overflow-scrolling: touch;"><span style="color: #998;font-style: italic;line-height: 26px;">#&nbsp;我們假設第一個和最後一個詞元是全局的，則有:</span><br>global_tokens&nbsp;=&nbsp;[<span style="color: #d14;line-height: 26px;">"BigBird"</span>,&nbsp;<span style="color: #d14;line-height: 26px;">"answering"</span>]<br><br><span style="color: #998;font-style: italic;line-height: 26px;">#&nbsp;將全局詞元加入到集合中</span><br>key_tokens.append(global_tokens)<br></code></pre><ul data-tool="mdnice 編輯器" style="margin-top: 8px;margin-bottom: 8px;padding-left: 25px;" class="list-paddingleft-1"><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);"><strong style="color: black;">隨機詞元:</strong> 隨機選擇一些詞元，這些詞元將通過關注其他詞元來傳輸信息，而那些詞元又可以傳輸信息到其他詞元。這可以降低直接從一個詞元到另一個詞元的信息傳輸成本。 
    </section></li></ul><pre data-tool="mdnice 編輯器" style="margin-top: 10px;margin-bottom: 10px;"><code style="overflow-x: auto;padding: 16px;color: #333;background: #f8f8f8;display: -webkit-box;font-family: Operator Mono, Consolas, Monaco, Menlo, monospace;border-radius: 0px;font-size: 12px;-webkit-overflow-scrolling: touch;"><span style="color: #998;font-style: italic;line-height: 26px;">#&nbsp;現在，我們可以從句子中隨機選擇&nbsp;`r`&nbsp;個詞元。這裏，假設&nbsp;`r`&nbsp;為&nbsp;1，&nbsp;選擇了&nbsp;`is`&nbsp;這個詞元</span><br><span style="color: #999;font-weight: bold;line-height: 26px;">&gt;&gt;&gt;&nbsp;</span>random_tokens&nbsp;=&nbsp;[<span style="color: #d14;line-height: 26px;">"is"</span>]&nbsp;<span style="color: #998;font-style: italic;line-height: 26px;">#&nbsp;注意:&nbsp;這個是完全隨機選擇的，因此可以是任意詞元。</span><br><br><span style="color: #998;font-style: italic;line-height: 26px;">#&nbsp;將隨機詞元加入到集合中</span><br>key_tokens.append(random_tokens)<br><br><span style="color: #998;font-style: italic;line-height: 26px;">#&nbsp;現在看下&nbsp;`key_tokens`&nbsp;集合中有哪些詞元</span><br>key_tokens<br>{<span style="color: #d14;line-height: 26px;">'now'</span>,&nbsp;<span style="color: #d14;line-height: 26px;">'is'</span>,&nbsp;<span style="color: #d14;line-height: 26px;">'in'</span>,&nbsp;<span style="color: #d14;line-height: 26px;">'answering'</span>,&nbsp;<span style="color: #d14;line-height: 26px;">'available'</span>,&nbsp;<span style="color: #d14;line-height: 26px;">'BigBird'</span>}<br><br><span style="color: #998;font-style: italic;line-height: 26px;">#&nbsp;至此，查詢詞&nbsp;'available'&nbsp;僅關注集合中的這些詞元，而不用關心全部</span><br></code></pre><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">這樣，查詢詞元僅關注所有詞元的一個子集，該子集能夠產生完全注意力值的一個不錯的近似。相同的方法將用於所有其他查詢詞元。但請記住，這裏的重點是儘可能有效地接近 <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">BERT</code> 的完全注意力。BERT 那種簡單地讓每個查詢詞元關注所有鍵詞元的做法可以建模為一系列矩陣乘法，從而在現代硬件 (如 GPU) 上進行高效計算。然而，滑動、全局和隨機注意力的組合似乎意味着稀疏矩陣乘法，這在現代硬件上很難高效實現。<code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">BigBird</code> 的主要貢獻之一是提出了 <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">塊稀疏</code> 注意力機制，該機制可以高效計算滑動、全局和隨機注意力。我們來看看吧！</p><span id="OSC_h3_3"></span><h3 data-tool="mdnice 編輯器" style="font-weight: bold;font-size: 20px;line-height: 1.4;padding-top: 10px;margin-top: 10px;margin-bottom: 5px;"><span style="display: none;"></span><span style="color: rgb(81, 81, 81);font-size: 17px;padding-left: 1em;border-left: 3px solid rgb(249, 191, 69);">圖解全局、滑動、隨機注意力的概念</span><span style="display: none;"></span></h3><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">首先，我們藉助圖來幫助理解「全局」、「滑動」和「隨機」注意力，並嘗試理解這三種注意力機制的組合是如何較好地近似標準 BERT 類注意力的。</p><table data-tool="mdnice 編輯器"><tbody style="border-width: 0px;border-style: initial;border-color: initial;"><tr style="border-width: 1px 0px 0px;border-right-style: initial;border-bottom-style: initial;border-left-style: initial;border-right-color: initial;border-bottom-color: initial;border-left-color: initial;border-top-style: solid;border-top-color: rgb(204, 204, 204);background-color: white;"><td style="border-color: rgb(204, 204, 204);text-align: center;min-width: 85px;"><img data-imgfileid="100005778" data-ratio="0.9522058823529411" data-type="png" data-w="544" height="250" style="margin-right: auto;margin-left: auto;width: 100%;border-radius: 5px;display: block;margin-bottom: 15px;height: auto !important;" width="250" src="https://oscimg.oschina.net/oscnet/48d8f357-e08b-47a7-8590-a79741e9940f.png" referrerpolicy="no-referrer"></td><td style="border-color: rgb(204, 204, 204);text-align: center;min-width: 85px;"><img class="rich_pages wxw-img" data-imgfileid="100005780" data-ratio="0.9522058823529411" data-type="png" data-w="544" height="250" style="margin-right: auto;margin-left: auto;width: 100%;border-radius: 5px;display: block;margin-bottom: 15px;height: auto !important;" width="250" src="https://oscimg.oschina.net/oscnet/bf44ee17-227a-4bd2-8deb-ab00f6efbfa8.png" referrerpolicy="no-referrer"></td><td style="border-color: rgb(204, 204, 204);text-align: center;min-width: 85px;"><img data-imgfileid="100005781" data-ratio="0.9522058823529411" data-type="png" data-w="544" height="250" style="margin-right: auto;margin-left: auto;width: 100%;border-radius: 5px;display: block;margin-bottom: 15px;height: auto !important;" width="250" src="https://oscimg.oschina.net/oscnet/5556aef1-ce3e-41a8-b40c-fcb78b4139d8.png" referrerpolicy="no-referrer"></td></tr></tbody></table><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);"><em style="color: black;">上圖分別把「全局」(左) 、「滑動」(中) 和「隨機」(右) 連接建模成一個圖。每個節點對應一個詞元，每條邊代表一個注意力分數。如果 2 個詞元之間沒有邊連接，則其注意力分數為 0。</em></p><figure data-tool="mdnice 編輯器" style="margin-top: 10px;margin-bottom: 10px;display: flex;flex-direction: column;justify-content: center;align-items: center;"><img class="rich_pages wxw-img" data-imgfileid="100005782" data-ratio="0.535" data-type="gif" data-w="600" style="margin-right: auto;margin-left: auto;width: 409px;border-radius: 5px;display: block;margin-bottom: 15px;height: auto !important;" src="https://oscimg.oschina.net/oscnet/b059422c-eedb-4881-8ea4-75aebc73bb2d.gif" referrerpolicy="no-referrer"></figure><img class="rich_pages wxw-img" data-imgfileid="100005779" data-ratio="0.9522058823529411" data-type="png" data-w="544" height="230" style="margin-right: auto;margin-left: auto;width: 385px;border-radius: 5px;display: block;margin-bottom: 15px;height: auto !important;" width="230" src="https://oscimg.oschina.net/oscnet/d3b084c5-9bf4-4c47-a5e7-72edb7d1eb53.png" referrerpolicy="no-referrer"><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);"><strong style="color: black;">BigBird 塊稀疏注意力</strong> 是滑動連接、全局連接和隨機連接 (總共 10 個連接) 的組合，如上圖左側動圖所示。而 <strong style="color: black;">完全注意力</strong> 圖 (右側) 則是有全部 15 個連接 (注意: 總共有 6 個節點)。你可以簡單地將完全注意力視為所有詞元都是全局詞元 <span style="cursor:pointer;"><span role="presentation" data-formula="{}^1" data-formula-type="inline-equation" style=""><svg
                xmlns="http://www.w3.org/2000/svg" role="img" focusable="false" viewBox="0 -833.9 403.6 833.9" aria-hidden="true" style="vertical-align: 0px;width: 0.913ex;height: 1.887ex;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g data-mml-node="math"><g data-mml-node="msup"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"></g><g data-mml-node="mn" transform="translate(0, 363) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g></g></g></svg></span></span>。</p><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);"><strong style="color: black;">完全注意力:</strong> 模型可以直接在單個層中將信息從一個詞元傳輸到另一個詞元，因為每個詞元都會對每個其他詞元進行查詢，並且受到其他每個詞元的關注。我們考慮一個與上圖類似的例子，如果模型需要將 <em style="color: black;">'going'</em> 與 <em style="color: black;">'now'</em> 關聯起來，它可以簡單地在單層中執行此操作，因為它們兩個是有直接連接的。</p><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);"><strong style="color: black;">塊稀疏注意力:</strong> 如果模型需要在兩個節點 (或詞元) 之間共享信息，則對於某些詞元，信息將必須經過路徑中的各個其他節點; 因為不是所有節點都有直接連接的。<em style="color: black;">例如</em> ，假設模型需要將 <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">going</code> 與 <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">now</code> 關聯起來，那麼如果僅存在滑動注意力，則這兩個詞元之間的信息流由路徑 <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">going -&gt; am -&gt; i -&gt; now</code> 來定義，也就是説它必須經過 2 個其他詞元。因此，我們可能需要多個層來捕獲序列的全部信息，而正常的注意力可以在單層中捕捉到這一點。在極端情況下，這可能意味着需要與輸入詞元一樣多的層。然而，如果我們引入一些全局詞元，信息可以通過以下路徑傳播 <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">going -&gt; i -&gt; now</code> ，這可以幫助縮短路徑。如果我們再另外引入隨機連接，它就可以通過 <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">going -&gt; am -&gt; now</code> 傳播。藉助隨機連接和全局連接，信息可以非常快速地 (只需幾層) 從一個詞元傳輸到下一個詞元。</p><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">如果我們有很多全局詞元，那麼我們可能不需要隨機連接，因為信息可以通過多個短路徑傳播。這就是在使用 BigBird 的變體 (稱為 ETC) 時設置 <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">num_random_tokens = 0</code> 的動機 (稍後部分將會詳細介紹)。</p><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);"><span style="cursor:pointer;"><span role="presentation" data-formula="{}^1" data-formula-type="inline-equation" style=""><svg
                xmlns="http://www.w3.org/2000/svg" role="img" focusable="false" viewBox="0 -833.9 403.6 833.9" aria-hidden="true" style="vertical-align: 0px;width: 0.913ex;height: 1.887ex;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g data-mml-node="math"><g data-mml-node="msup"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"></g><g data-mml-node="mn" transform="translate(0, 363) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g></g></g></svg></span></span> 在這些圖中，我們假設注意力矩陣是對稱的 <strong style="color: black;">即</strong><span style="cursor:pointer;"><span role="presentation" data-formula="\mathbf{A} _{ij} = \mathbf{A}_ {ji}" data-formula-type="inline-equation" style=""><svg
                xmlns="http://www.w3.org/2000/svg" role="img" focusable="false" viewBox="0 -698 4242.1 992.2" aria-hidden="true" style="vertical-align: -0.666ex;width: 9.598ex;height: 2.245ex;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="41" d="M296 0Q278 3 164 3Q58 3 49 0H40V62H92Q144 62 144 64Q388 682 397 689Q403 698 434 698Q463 698 471 689Q475 686 538 530T663 218L724 64Q724 62 776 62H828V0H817Q796 3 658 3Q509 3 485 0H472V62H517Q561 62 561 63L517 175H262L240 120Q218 65 217 64Q217 62 261 62H306V0H296ZM390 237L492 238L440 365Q390 491 388 491Q287 239 287 237H390Z"></path></g></g><g data-mml-node="TeXAtom" transform="translate(869, -150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="69" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(345, 0)"><path data-c="6A" d="M297 596Q297 627 318 644T361 661Q378 661 389 651T403 623Q403 595 384 576T340 557Q322 557 310 567T297 596ZM288 376Q288 405 262 405Q240 405 220 393T185 362T161 325T144 293L137 279Q135 278 121 278H107Q101 284 101 286T105 299Q126 348 164 391T252 441Q253 441 260 441T272 442Q296 441 316 432Q341 418 354 401T367 348V332L318 133Q267 -67 264 -75Q246 -125 194 -164T75 -204Q25 -204 7 -183T-12 -137Q-12 -110 7 -91T53 -71Q70 -71 82 -81T95 -112Q95 -148 63 -167Q69 -168 77 -168Q111 -168 139 -140T182 -74L193 -32Q204 11 219 72T251 197T278 308T289 365Q289 372 288 376Z"></path></g></g></g><g data-mml-node="mo" transform="translate(1732.1, 0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="msub" transform="translate(2787.8, 0)"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="41" d="M296 0Q278 3 164 3Q58 3 49 0H40V62H92Q144 62 144 64Q388 682 397 689Q403 698 434 698Q463 698 471 689Q475 686 538 530T663 218L724 64Q724 62 776 62H828V0H817Q796 3 658 3Q509 3 485 0H472V62H517Q561 62 561 63L517 175H262L240 120Q218 65 217 64Q217 62 261 62H306V0H296ZM390 237L492 238L440 365Q390 491 388 491Q287 239 287 237H390Z"></path></g></g><g data-mml-node="TeXAtom" transform="translate(869, -150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="6A" d="M297 596Q297 627 318 644T361 661Q378 661 389 651T403 623Q403 595 384 576T340 557Q322 557 310 567T297 596ZM288 376Q288 405 262 405Q240 405 220 393T185 362T161 325T144 293L137 279Q135 278 121 278H107Q101 284 101 286T105 299Q126 348 164 391T252 441Q253 441 260 441T272 442Q296 441 316 432Q341 418 354 401T367 348V332L318 133Q267 -67 264 -75Q246 -125 194 -164T75 -204Q25 -204 7 -183T-12 -137Q-12 -110 7 -91T53 -71Q70 -71 82 -81T95 -112Q95 -148 63 -167Q69 -168 77 -168Q111 -168 139 -140T182 -74L193 -32Q204 11 219 72T251 197T278 308T289 365Q289 372 288 376Z"></path></g><g data-mml-node="mi" transform="translate(412, 0)"><path data-c="69" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g></g></g></g></svg></span></span> 因為在圖中如果某個詞元 <strong style="color: black;">A</strong> 關注 <strong style="color: black;">B</strong>，那麼 <strong style="color: black;">B</strong> 也會關注 <strong style="color: black;">A</strong>。從下一節所示的注意力矩陣圖中可以看出，這個假設對於 BigBird 中的大多數詞元都成立。</p><section data-tool="mdnice 編輯器" style="overflow-x: auto;"><table><thead><tr style="border-width: 1px 0px 0px;border-right-style: initial;border-bottom-style: initial;border-left-style: initial;border-right-color: initial;border-bottom-color: initial;border-left-color: initial;border-top-style: solid;border-top-color: rgb(204, 204, 204);background-color: white;"><th style="border-top-width: 1px;border-color: rgb(204, 204, 204);background-color: rgb(240, 240, 240);text-align: center;min-width: 85px;">注意力類型</th><th style="border-top-width: 1px;border-color: rgb(204, 204, 204);background-color: rgb(240, 240, 240);text-align: center;min-width: 85px;">全局次元</th><th style="border-top-width: 1px;border-color: rgb(204, 204, 204);background-color: rgb(240, 240, 240);text-align: center;min-width: 85px;">滑動詞元</th><th style="border-top-width: 1px;border-color: rgb(204, 204, 204);background-color: rgb(240, 240, 240);text-align: center;min-width: 85px;">隨機詞元</th></tr></thead><tbody style="border-width: 0px;border-style: initial;border-color: initial;"><tr style="border-width: 1px 0px 0px;border-right-style: initial;border-bottom-style: initial;border-left-style: initial;border-right-color: initial;border-bottom-color: initial;border-left-color: initial;border-top-style: solid;border-top-color: rgb(204, 204, 204);background-color: white;"><td style="border-color: rgb(204, 204, 204);text-align: center;min-width: 85px;">原始完全注意力</td><td style="border-color: rgb(204, 204, 204);text-align: center;min-width: 85px;"><code>n</code></td><td style="border-color: rgb(204, 204, 204);text-align: center;min-width: 85px;">0</td><td style="border-color: rgb(204, 204, 204);text-align: center;min-width: 85px;">0</td></tr><tr style="border-width: 1px 0px 0px;border-right-style: initial;border-bottom-style: initial;border-left-style: initial;border-right-color: initial;border-bottom-color: initial;border-left-color: initial;border-top-style: solid;border-top-color: rgb(204, 204, 204);background-color: rgb(248, 248, 248);"><td style="border-color: rgb(204, 204, 204);text-align: center;min-width: 85px;">塊稀疏注意力</td><td style="border-color: rgb(204, 204, 204);text-align: center;min-width: 85px;">2 x <code>block_size</code></td><td style="border-color: rgb(204, 204, 204);text-align: center;min-width: 85px;">3 x <code>block_size</code></td><td style="border-color: rgb(204, 204, 204);text-align: center;min-width: 85px;"><code>num_random_blocks</code> x <code>block_size</code></td></tr></tbody></table></section><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">原始完全注意力即 <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">BERT</code> 的注意力，而塊稀疏注意力則是 <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">BigBird</code> 的注意力。想知道 <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">block_size</code> 是什麼？請繼續閲讀下文。_現在，為簡單起見，將其視為 1。_</p><span id="OSC_h2_4"></span><h2 data-tool="mdnice 編輯器" style="font-weight: bold;font-size: 22px;line-height: 1.2em;margin-top: 2em;margin-bottom: 35px;color: rgb(255, 157, 0);"><span style="font-size: 18px;color: rgb(255, 157, 11);padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;display: none;"></span><span style="color: rgb(255, 157, 11);visibility: visible;display: inline-block;border-left: 5px solid rgb(255, 157, 0);padding: 2px 13px;margin-right: 3px;height: 50%;font-size: 18px;">BigBird 塊稀疏注意力</span><span style="font-size: 18px;color: rgb(255, 157, 11);display: inline-block;padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;"></span></h2><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">BigBird 塊稀疏注意力是我們上文討論的內容的高效實現。每個詞元都關注某些 <strong style="color: black;">全局詞元</strong> 、 <strong style="color: black;">滑動詞元</strong> 和 <strong style="color: black;">隨機詞元</strong>，而不管其他 <strong style="color: black;">所有</strong> 詞元。作者分別實現了每類查詢注意力矩陣，並使用了一個很酷的技巧來加速 GPU 和 TPU 上的訓練/推理。</p><figure data-tool="mdnice 編輯器" style="margin-top: 10px;margin-bottom: 10px;display: flex;flex-direction: column;justify-content: center;align-items: center;"><img class="rich_pages wxw-img" data-imgfileid="100005786" data-ratio="0.6129629629629629" data-type="png" data-w="1080" style="margin-right: auto;margin-left: auto;width: 543px;border-radius: 5px;display: block;margin-bottom: 15px;height: auto !important;" src="https://oscimg.oschina.net/oscnet/f653f75a-ff61-452b-b0b1-aedeab166e25.png" referrerpolicy="no-referrer"><figcaption style="margin-top: 5px;text-align: center;color: #dda52d;font-size: 14px;">
     BigBird 塊稀疏注意力 
   </figcaption></figure><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);"><em style="color: black;">注意: 在上圖的頂部有 2 個額外的句子。正如你所注意到的，兩個句子中的每個詞元都只是交換了一個位置。這就是滑動注意力的實現方式。當 <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">q[i]</code> 與 <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">k[i,0:3]</code> 相乘時，我們會得到 <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">q[i]</code> 的滑動注意力分數 (其中<code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">i</code> 是序列中元素的索引)。</em></p><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">你可以在，這兒，找到 <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">block_sparse</code> 注意力的具體實現。現在看起來可能非常可怕😨😨，但這篇文章肯定會讓你輕鬆理解它。</p><span id="OSC_h3_5"></span><h3 data-tool="mdnice 編輯器" style="font-weight: bold;font-size: 20px;line-height: 1.4;padding-top: 10px;margin-top: 10px;margin-bottom: 5px;"><span style="display: none;"></span><span style="color: rgb(81, 81, 81);font-size: 17px;padding-left: 1em;border-left: 3px solid rgb(249, 191, 69);">全局注意力</span><span style="display: none;"></span></h3><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">對於全局注意力而言，每個查詢詞元關注序列中的所有其他詞元，並且被其他每個詞元關注。我們假設 <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">Vasudev</code> (第一個詞元) 和 <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">them</code> (最後一個詞元) 是全局的 (如上圖所示)。你可以看到這些詞元直接連接到所有其他詞元 (藍色框)。</p><pre data-tool="mdnice 編輯器" style="margin-top: 10px;margin-bottom: 10px;"><code style="overflow-x: auto;padding: 16px;color: #333;background: #f8f8f8;display: -webkit-box;font-family: Operator Mono, Consolas, Monaco, Menlo, monospace;border-radius: 0px;font-size: 12px;-webkit-overflow-scrolling: touch;"><span style="color: #998;font-style: italic;line-height: 26px;">#&nbsp;偽代碼</span><br><br>Q&nbsp;-&gt;&nbsp;Query&nbsp;martix&nbsp;(seq_length,&nbsp;head_dim)<br>K&nbsp;-&gt;&nbsp;Key&nbsp;matrix&nbsp;(seq_length,&nbsp;head_dim)<br><br><span style="color: #998;font-style: italic;line-height: 26px;">#&nbsp;第一個和最後一個詞元關注所有其他詞元</span><br>Q[<span style="color: #008080;line-height: 26px;">0</span>]&nbsp;x&nbsp;[K[<span style="color: #008080;line-height: 26px;">0</span>],&nbsp;K[<span style="color: #008080;line-height: 26px;">1</span>],&nbsp;K[<span style="color: #008080;line-height: 26px;">2</span>],&nbsp;......,&nbsp;K[n<span style="color: #008080;line-height: 26px;">-1</span>]]<br>Q[n<span style="color: #008080;line-height: 26px;">-1</span>]&nbsp;x&nbsp;[K[<span style="color: #008080;line-height: 26px;">0</span>],&nbsp;K[<span style="color: #008080;line-height: 26px;">1</span>],&nbsp;K[<span style="color: #008080;line-height: 26px;">2</span>],&nbsp;......,&nbsp;K[n<span style="color: #008080;line-height: 26px;">-1</span>]]<br><br><span style="color: #998;font-style: italic;line-height: 26px;">#&nbsp;第一個和最後一個詞元也被其他所有詞元關注</span><br>K[<span style="color: #008080;line-height: 26px;">0</span>]&nbsp;x&nbsp;[Q[<span style="color: #008080;line-height: 26px;">0</span>],&nbsp;Q[<span style="color: #008080;line-height: 26px;">1</span>],&nbsp;Q[<span style="color: #008080;line-height: 26px;">2</span>],&nbsp;......,&nbsp;Q[n<span style="color: #008080;line-height: 26px;">-1</span>]]<br>K[n<span style="color: #008080;line-height: 26px;">-1</span>]&nbsp;x&nbsp;[Q[<span style="color: #008080;line-height: 26px;">0</span>],&nbsp;Q[<span style="color: #008080;line-height: 26px;">1</span>],&nbsp;Q[<span style="color: #008080;line-height: 26px;">2</span>],&nbsp;......,&nbsp;Q[n<span style="color: #008080;line-height: 26px;">-1</span>]]<br></code></pre><span id="OSC_h3_6"></span><h3 data-tool="mdnice 編輯器" style="font-weight: bold;font-size: 20px;line-height: 1.4;padding-top: 10px;margin-top: 10px;margin-bottom: 5px;"><span style="display: none;"></span><span style="color: rgb(81, 81, 81);font-size: 17px;padding-left: 1em;border-left: 3px solid rgb(249, 191, 69);">滑動注意力</span><span style="display: none;"></span></h3><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">鍵詞元序列被複制兩次，其中一份每個詞元向右移動一步，另一份每個詞元向左移動一步。現在，如果我們將查詢序列向量乘以這 3 個序列向量，我們將覆蓋所有滑動詞元。計算複雜度就是 <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">O(3n) = O(n)</code> 。參考上圖，橙色框代表滑動注意力。你可以在圖的頂部看到 3 個序列，其中 2 個序列各移動了一個詞元 (1 個向左，1 個向右)。</p><pre data-tool="mdnice 編輯器" style="margin-top: 10px;margin-bottom: 10px;"><code style="overflow-x: auto;padding: 16px;color: #333;background: #f8f8f8;display: -webkit-box;font-family: Operator Mono, Consolas, Monaco, Menlo, monospace;border-radius: 0px;font-size: 12px;-webkit-overflow-scrolling: touch;"><span style="color: #998;font-style: italic;line-height: 26px;">#&nbsp;我們想做的</span><br>Q[i]&nbsp;x&nbsp;[K[i<span style="color: #008080;line-height: 26px;">-1</span>],&nbsp;K[i],&nbsp;K[i+<span style="color: #008080;line-height: 26px;">1</span>]]&nbsp;<span style="font-weight: bold;line-height: 26px;">for</span>&nbsp;i&nbsp;=&nbsp;<span style="color: #008080;line-height: 26px;">1</span>:<span style="color: #008080;line-height: 26px;">-1</span><br><br><span style="color: #998;font-style: italic;line-height: 26px;">#&nbsp;高效的代碼實現&nbsp;(👇&nbsp;乘法為點乘)</span><br>[Q[<span style="color: #008080;line-height: 26px;">0</span>],&nbsp;Q[<span style="color: #008080;line-height: 26px;">1</span>],&nbsp;Q[<span style="color: #008080;line-height: 26px;">2</span>],&nbsp;......,&nbsp;Q[n<span style="color: #008080;line-height: 26px;">-2</span>],&nbsp;Q[n<span style="color: #008080;line-height: 26px;">-1</span>]]&nbsp;x&nbsp;[K[<span style="color: #008080;line-height: 26px;">1</span>],&nbsp;K[<span style="color: #008080;line-height: 26px;">2</span>],&nbsp;K[<span style="color: #008080;line-height: 26px;">3</span>],&nbsp;......,&nbsp;K[n<span style="color: #008080;line-height: 26px;">-1</span>],&nbsp;K[<span style="color: #008080;line-height: 26px;">0</span>]]<br>[Q[<span style="color: #008080;line-height: 26px;">0</span>],&nbsp;Q[<span style="color: #008080;line-height: 26px;">1</span>],&nbsp;Q[<span style="color: #008080;line-height: 26px;">2</span>],&nbsp;......,&nbsp;Q[n<span style="color: #008080;line-height: 26px;">-1</span>]]&nbsp;x&nbsp;[K[n<span style="color: #008080;line-height: 26px;">-1</span>],&nbsp;K[<span style="color: #008080;line-height: 26px;">0</span>],&nbsp;K[<span style="color: #008080;line-height: 26px;">1</span>],&nbsp;......,&nbsp;K[n<span style="color: #008080;line-height: 26px;">-2</span>]]<br>[Q[<span style="color: #008080;line-height: 26px;">0</span>],&nbsp;Q[<span style="color: #008080;line-height: 26px;">1</span>],&nbsp;Q[<span style="color: #008080;line-height: 26px;">2</span>],&nbsp;......,&nbsp;Q[n<span style="color: #008080;line-height: 26px;">-1</span>]]&nbsp;x&nbsp;[K[<span style="color: #008080;line-height: 26px;">0</span>],&nbsp;K[<span style="color: #008080;line-height: 26px;">1</span>],&nbsp;K[<span style="color: #008080;line-height: 26px;">2</span>],&nbsp;......,&nbsp;K[n<span style="color: #008080;line-height: 26px;">-1</span>]]<br><br><span style="color: #998;font-style: italic;line-height: 26px;">#&nbsp;每個序列被乘&nbsp;3&nbsp;詞，&nbsp;即&nbsp;`window_size&nbsp;=&nbsp;3`。為示意，僅列出主要計算，省略了一些計算。</span><br></code></pre><span id="OSC_h3_7"></span><h3 data-tool="mdnice 編輯器" style="font-weight: bold;font-size: 20px;line-height: 1.4;padding-top: 10px;margin-top: 10px;margin-bottom: 5px;"><span style="display: none;"></span><span style="color: rgb(81, 81, 81);font-size: 17px;padding-left: 1em;border-left: 3px solid rgb(249, 191, 69);">隨機注意力</span><span style="display: none;"></span></h3><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">隨機注意力確保每個查詢詞元也會關注一些隨機詞元。對實現而言，這意味着模型隨機選取一些詞元並計算它們的注意力分數。</p><pre data-tool="mdnice 編輯器" style="margin-top: 10px;margin-bottom: 10px;"><code style="overflow-x: auto;padding: 16px;color: #333;background: #f8f8f8;display: -webkit-box;font-family: Operator Mono, Consolas, Monaco, Menlo, monospace;border-radius: 0px;font-size: 12px;-webkit-overflow-scrolling: touch;"><span style="color: #998;font-style: italic;line-height: 26px;">#&nbsp;r1,&nbsp;r2,&nbsp;r&nbsp;為隨機索引;&nbsp;注意&nbsp;r1,&nbsp;r2,&nbsp;r&nbsp;每行取值不同&nbsp;👇</span><br>Q[<span style="color: #008080;line-height: 26px;">1</span>]&nbsp;x&nbsp;[Q[r1],&nbsp;Q[r2],&nbsp;......,&nbsp;Q[r]]<br>.<br>.<br>.<br>Q[n<span style="color: #008080;line-height: 26px;">-2</span>]&nbsp;x&nbsp;[Q[r1],&nbsp;Q[r2],&nbsp;......,&nbsp;Q[r]]<br><br><span style="color: #998;font-style: italic;line-height: 26px;">#&nbsp;不用管第&nbsp;0&nbsp;個和第&nbsp;n-1&nbsp;個詞元，因為它們已經是全局詞元了。</span><br></code></pre><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);"><strong style="color: black;">注意:</strong> 當前的實現進一步將序列劃分為塊，並且每個符號都依塊而定義而非依詞元而定義。我們在下一節中會更詳細地討論這個問題。</p><span id="OSC_h3_8"></span><h3 data-tool="mdnice 編輯器" style="font-weight: bold;font-size: 20px;line-height: 1.4;padding-top: 10px;margin-top: 10px;margin-bottom: 5px;"><span style="display: none;"></span><span style="color: rgb(81, 81, 81);font-size: 17px;padding-left: 1em;border-left: 3px solid rgb(249, 191, 69);">實現</span><span style="display: none;"></span></h3><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);"><strong style="color: black;">回顧:</strong> 在常規 BERT 注意力中，一系列詞元，即 <span style="cursor:pointer;"><span role="presentation" data-formula="X = x_1, x_2, …., x_n" data-formula-type="inline-equation" style=""><svg
                xmlns="http://www.w3.org/2000/svg" role="img" focusable="false" viewBox="0 -683 8300.3 877" aria-hidden="true" style="vertical-align: -0.439ex;width: 18.779ex;height: 1.984ex;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="58" d="M42 0H40Q26 0 26 11Q26 15 29 27Q33 41 36 43T55 46Q141 49 190 98Q200 108 306 224T411 342Q302 620 297 625Q288 636 234 637H206Q200 643 200 645T202 664Q206 677 212 683H226Q260 681 347 681Q380 681 408 681T453 682T473 682Q490 682 490 671Q490 670 488 658Q484 643 481 640T465 637Q434 634 411 620L488 426L541 485Q646 598 646 610Q646 628 622 635Q617 635 609 637Q594 637 594 648Q594 650 596 664Q600 677 606 683H618Q619 683 643 683T697 681T738 680Q828 680 837 683H845Q852 676 852 672Q850 647 840 637H824Q790 636 763 628T722 611T698 593L687 584Q687 585 592 480L505 384Q505 383 536 304T601 142T638 56Q648 47 699 46Q734 46 734 37Q734 35 732 23Q728 7 725 4T711 1Q708 1 678 1T589 2Q528 2 496 2T461 1Q444 1 444 10Q444 11 446 25Q448 35 450 39T455 44T464 46T480 47T506 54Q523 62 523 64Q522 64 476 181L429 299Q241 95 236 84Q232 76 232 72Q232 53 261 47Q262 47 267 47T273 46Q276 46 277 46T280 45T283 42T284 35Q284 26 282 19Q279 6 276 4T261 1Q258 1 243 1T201 2T142 2Q64 2 42 0Z"></path></g><g data-mml-node="mo" transform="translate(1129.8, 0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="msub" transform="translate(2185.6, 0)"><g data-mml-node="mi"><path data-c="78" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mn" transform="translate(572, -150) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g><g data-mml-node="mo" transform="translate(3161.1, 0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="msub" transform="translate(3605.8, 0)"><g data-mml-node="mi"><path data-c="78" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mn" transform="translate(572, -150) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g></g><g data-mml-node="mo" transform="translate(4581.3, 0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mo" transform="translate(5026, 0)"><path data-c="2026" d="M78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60ZM525 60Q525 84 542 102T585 120Q609 120 627 104T646 61Q646 36 629 18T586 0T543 17T525 60ZM972 60Q972 84 989 102T1032 120Q1056 120 1074 104T1093 61Q1093 36 1076 18T1033 0T990 17T972 60Z"></path></g><g data-mml-node="mo" transform="translate(6364.7, 0)"><path data-c="2E" d="M78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60Z"></path></g><g data-mml-node="mo" transform="translate(6809.3, 0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="msub" transform="translate(7254, 0)"><g data-mml-node="mi"><path data-c="78" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mi" transform="translate(572, -150) scale(0.707)"><path data-c="6E" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g></g></g></g></svg></span></span> 通過線性層投影到 <span style="cursor:pointer;"><span role="presentation" data-formula="Q，K，V" data-formula-type="inline-equation" style=""><svg
                xmlns="http://www.w3.org/2000/svg" role="img" focusable="false" viewBox="0 -750 5234.7 950" aria-hidden="true" style="vertical-align: -0.452ex;width: 11.843ex;height: 2.149ex;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="51" d="M399 -80Q399 -47 400 -30T402 -11V-7L387 -11Q341 -22 303 -22Q208 -22 138 35T51 201Q50 209 50 244Q50 346 98 438T227 601Q351 704 476 704Q514 704 524 703Q621 689 680 617T740 435Q740 255 592 107Q529 47 461 16L444 8V3Q444 2 449 -24T470 -66T516 -82Q551 -82 583 -60T625 -3Q631 11 638 11Q647 11 649 2Q649 -6 639 -34T611 -100T557 -165T481 -194Q399 -194 399 -87V-80ZM636 468Q636 523 621 564T580 625T530 655T477 665Q429 665 379 640Q277 591 215 464T153 216Q153 110 207 59Q231 38 236 38V46Q236 86 269 120T347 155Q372 155 390 144T417 114T429 82T435 55L448 64Q512 108 557 185T619 334T636 468ZM314 18Q362 18 404 39L403 49Q399 104 366 115Q354 117 347 117Q344 117 341 117T337 118Q317 118 296 98T274 52Q274 18 314 18Z"></path></g><g data-mml-node="mo" transform="translate(1068.8, 0)"><text data-variant="normal" transform="matrix(1 0 0 -1 0 0)" font-size="836.9px" font-family="serif">
           ， 
         </text></g><g data-mml-node="mi" transform="translate(2183.9, 0)"><path data-c="4B" d="M285 628Q285 635 228 637Q205 637 198 638T191 647Q191 649 193 661Q199 681 203 682Q205 683 214 683H219Q260 681 355 681Q389 681 418 681T463 682T483 682Q500 682 500 674Q500 669 497 660Q496 658 496 654T495 648T493 644T490 641T486 639T479 638T470 637T456 637Q416 636 405 634T387 623L306 305Q307 305 490 449T678 597Q692 611 692 620Q692 635 667 637Q651 637 651 648Q651 650 654 662T659 677Q662 682 676 682Q680 682 711 681T791 680Q814 680 839 681T869 682Q889 682 889 672Q889 650 881 642Q878 637 862 637Q787 632 726 586Q710 576 656 534T556 455L509 418L518 396Q527 374 546 329T581 244Q656 67 661 61Q663 59 666 57Q680 47 717 46H738Q744 38 744 37T741 19Q737 6 731 0H720Q680 3 625 3Q503 3 488 0H478Q472 6 472 9T474 27Q478 40 480 43T491 46H494Q544 46 544 71Q544 75 517 141T485 216L427 354L359 301L291 248L268 155Q245 63 245 58Q245 51 253 49T303 46H334Q340 37 340 35Q340 19 333 5Q328 0 317 0Q314 0 280 1T180 2Q118 2 85 2T49 1Q31 1 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Z"></path></g><g data-mml-node="mo" transform="translate(3350.6, 0)"><text data-variant="normal" transform="matrix(1 0 0 -1 0 0)" font-size="836.9px" font-family="serif">
           ， 
         </text></g><g data-mml-node="mi" transform="translate(4465.7, 0)"><path data-c="56" d="M52 648Q52 670 65 683H76Q118 680 181 680Q299 680 320 683H330Q336 677 336 674T334 656Q329 641 325 637H304Q282 635 274 635Q245 630 242 620Q242 618 271 369T301 118L374 235Q447 352 520 471T595 594Q599 601 599 609Q599 633 555 637Q537 637 537 648Q537 649 539 661Q542 675 545 679T558 683Q560 683 570 683T604 682T668 681Q737 681 755 683H762Q769 676 769 672Q769 655 760 640Q757 637 743 637Q730 636 719 635T698 630T682 623T670 615T660 608T652 599T645 592L452 282Q272 -9 266 -16Q263 -18 259 -21L241 -22H234Q216 -22 216 -15Q213 -9 177 305Q139 623 138 626Q133 637 76 637H59Q52 642 52 648Z"></path></g></g></g></svg></span></span>，並基於它們計算注意力分數 <span style="cursor:pointer;"><span role="presentation" data-formula="Z" data-formula-type="inline-equation" style=""><svg
                xmlns="http://www.w3.org/2000/svg" role="img" focusable="false" viewBox="0 -683 723 683" aria-hidden="true" style="vertical-align: 0px;width: 1.636ex;height: 1.545ex;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="5A" d="M58 8Q58 23 64 35Q64 36 329 334T596 635L586 637Q575 637 512 637H500H476Q442 637 420 635T365 624T311 598T266 548T228 469Q227 466 226 463T224 458T223 453T222 450L221 448Q218 443 202 443Q185 443 182 453L214 561Q228 606 241 651Q249 679 253 681Q256 683 487 683H718Q723 678 723 675Q723 673 717 649Q189 54 188 52L185 49H274Q369 50 377 51Q452 60 500 100T579 247Q587 272 590 277T603 282H607Q628 282 628 271Q547 5 541 2Q538 0 300 0H124Q58 0 58 8Z"></path></g></g></g></svg></span></span>，公式為 <span style="cursor:pointer;"><span role="presentation" data-formula="Z=Softmax(QK^T)" data-formula-type="inline-equation" style=""><svg
                xmlns="http://www.w3.org/2000/svg" role="img" focusable="false" viewBox="0 -841.7 9140.4 1091.7" aria-hidden="true" style="vertical-align: -0.566ex;width: 20.68ex;height: 2.47ex;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="5A" d="M58 8Q58 23 64 35Q64 36 329 334T596 635L586 637Q575 637 512 637H500H476Q442 637 420 635T365 624T311 598T266 548T228 469Q227 466 226 463T224 458T223 453T222 450L221 448Q218 443 202 443Q185 443 182 453L214 561Q228 606 241 651Q249 679 253 681Q256 683 487 683H718Q723 678 723 675Q723 673 717 649Q189 54 188 52L185 49H274Q369 50 377 51Q452 60 500 100T579 247Q587 272 590 277T603 282H607Q628 282 628 271Q547 5 541 2Q538 0 300 0H124Q58 0 58 8Z"></path></g><g data-mml-node="mo" transform="translate(1000.8, 0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mi" transform="translate(2056.6, 0)"><path data-c="53" d="M308 24Q367 24 416 76T466 197Q466 260 414 284Q308 311 278 321T236 341Q176 383 176 462Q176 523 208 573T273 648Q302 673 343 688T407 704H418H425Q521 704 564 640Q565 640 577 653T603 682T623 704Q624 704 627 704T632 705Q645 705 645 698T617 577T585 459T569 456Q549 456 549 465Q549 471 550 475Q550 478 551 494T553 520Q553 554 544 579T526 616T501 641Q465 662 419 662Q362 662 313 616T263 510Q263 480 278 458T319 427Q323 425 389 408T456 390Q490 379 522 342T554 242Q554 216 546 186Q541 164 528 137T492 78T426 18T332 -20Q320 -22 298 -22Q199 -22 144 33L134 44L106 13Q83 -14 78 -18T65 -22Q52 -22 52 -14Q52 -11 110 221Q112 227 130 227H143Q149 221 149 216Q149 214 148 207T144 186T142 153Q144 114 160 87T203 47T255 29T308 24Z"></path></g><g data-mml-node="mi" transform="translate(2701.6, 0)"><path data-c="6F" d="M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z"></path></g><g data-mml-node="mi" transform="translate(3186.6, 0)"><path data-c="66" d="M118 -162Q120 -162 124 -164T135 -167T147 -168Q160 -168 171 -155T187 -126Q197 -99 221 27T267 267T289 382V385H242Q195 385 192 387Q188 390 188 397L195 425Q197 430 203 430T250 431Q298 431 298 432Q298 434 307 482T319 540Q356 705 465 705Q502 703 526 683T550 630Q550 594 529 578T487 561Q443 561 443 603Q443 622 454 636T478 657L487 662Q471 668 457 668Q445 668 434 658T419 630Q412 601 403 552T387 469T380 433Q380 431 435 431Q480 431 487 430T498 424Q499 420 496 407T491 391Q489 386 482 386T428 385H372L349 263Q301 15 282 -47Q255 -132 212 -173Q175 -205 139 -205Q107 -205 81 -186T55 -132Q55 -95 76 -78T118 -61Q162 -61 162 -103Q162 -122 151 -136T127 -157L118 -162Z"></path></g><g data-mml-node="mi" transform="translate(3736.6, 0)"><path data-c="74" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mi" transform="translate(4097.6, 0)"><path data-c="6D" d="M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(4975.6, 0)"><path data-c="61" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path></g><g data-mml-node="mi" transform="translate(5504.6, 0)"><path data-c="78" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mo" transform="translate(6076.6, 0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(6465.6, 0)"><path data-c="51" d="M399 -80Q399 -47 400 -30T402 -11V-7L387 -11Q341 -22 303 -22Q208 -22 138 35T51 201Q50 209 50 244Q50 346 98 438T227 601Q351 704 476 704Q514 704 524 703Q621 689 680 617T740 435Q740 255 592 107Q529 47 461 16L444 8V3Q444 2 449 -24T470 -66T516 -82Q551 -82 583 -60T625 -3Q631 11 638 11Q647 11 649 2Q649 -6 639 -34T611 -100T557 -165T481 -194Q399 -194 399 -87V-80ZM636 468Q636 523 621 564T580 625T530 655T477 665Q429 665 379 640Q277 591 215 464T153 216Q153 110 207 59Q231 38 236 38V46Q236 86 269 120T347 155Q372 155 390 144T417 114T429 82T435 55L448 64Q512 108 557 185T619 334T636 468ZM314 18Q362 18 404 39L403 49Q399 104 366 115Q354 117 347 117Q344 117 341 117T337 118Q317 118 296 98T274 52Q274 18 314 18Z"></path></g><g data-mml-node="msup" transform="translate(7256.6, 0)"><g data-mml-node="mi"><path data-c="4B" d="M285 628Q285 635 228 637Q205 637 198 638T191 647Q191 649 193 661Q199 681 203 682Q205 683 214 683H219Q260 681 355 681Q389 681 418 681T463 682T483 682Q500 682 500 674Q500 669 497 660Q496 658 496 654T495 648T493 644T490 641T486 639T479 638T470 637T456 637Q416 636 405 634T387 623L306 305Q307 305 490 449T678 597Q692 611 692 620Q692 635 667 637Q651 637 651 648Q651 650 654 662T659 677Q662 682 676 682Q680 682 711 681T791 680Q814 680 839 681T869 682Q889 682 889 672Q889 650 881 642Q878 637 862 637Q787 632 726 586Q710 576 656 534T556 455L509 418L518 396Q527 374 546 329T581 244Q656 67 661 61Q663 59 666 57Q680 47 717 46H738Q744 38 744 37T741 19Q737 6 731 0H720Q680 3 625 3Q503 3 488 0H478Q472 6 472 9T474 27Q478 40 480 43T491 46H494Q544 46 544 71Q544 75 517 141T485 216L427 354L359 301L291 248L268 155Q245 63 245 58Q245 51 253 49T303 46H334Q340 37 340 35Q340 19 333 5Q328 0 317 0Q314 0 280 1T180 2Q118 2 85 2T49 1Q31 1 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Z"></path></g><g data-mml-node="mi" transform="translate(947, 363) scale(0.707)"><path data-c="54" d="M40 437Q21 437 21 445Q21 450 37 501T71 602L88 651Q93 669 101 677H569H659Q691 677 697 676T704 667Q704 661 687 553T668 444Q668 437 649 437Q640 437 637 437T631 442L629 445Q629 451 635 490T641 551Q641 586 628 604T573 629Q568 630 515 631Q469 631 457 630T439 622Q438 621 368 343T298 60Q298 48 386 46Q418 46 427 45T436 36Q436 31 433 22Q429 4 424 1L422 0Q419 0 415 0Q410 0 363 1T228 2Q99 2 64 0H49Q43 6 43 9T45 27Q49 40 55 46H83H94Q174 46 189 55Q190 56 191 56Q196 59 201 76T241 233Q258 301 269 344Q339 619 339 625Q339 630 310 630H279Q212 630 191 624Q146 614 121 583T67 467Q60 445 57 441T43 437H40Z"></path></g></g><g data-mml-node="mo" transform="translate(8751.4, 0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g></g></svg></span></span>。使用 BigBird 塊稀疏注意力時，我們使用相同的算法，但僅針對一些選定的查詢和鍵向量進行計算。</p><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">我們來看看 BigBird 塊稀疏注意力是如何實現的。首先，我們用 <span style="cursor:pointer;"><span role="presentation" data-formula="b、r、s、g" data-formula-type="inline-equation" style=""><svg
                xmlns="http://www.w3.org/2000/svg" role="img" focusable="false" viewBox="0 -750 6004.6 955" aria-hidden="true" style="vertical-align: -0.464ex;width: 13.585ex;height: 2.161ex;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="62" d="M73 647Q73 657 77 670T89 683Q90 683 161 688T234 694Q246 694 246 685T212 542Q204 508 195 472T180 418L176 399Q176 396 182 402Q231 442 283 442Q345 442 383 396T422 280Q422 169 343 79T173 -11Q123 -11 82 27T40 150V159Q40 180 48 217T97 414Q147 611 147 623T109 637Q104 637 101 637H96Q86 637 83 637T76 640T73 647ZM336 325V331Q336 405 275 405Q258 405 240 397T207 376T181 352T163 330L157 322L136 236Q114 150 114 114Q114 66 138 42Q154 26 178 26Q211 26 245 58Q270 81 285 114T318 219Q336 291 336 325Z"></path></g><g data-mml-node="mo" transform="translate(706.8, 0)"><text data-variant="normal" transform="matrix(1 0 0 -1 0 0)" font-size="836.9px" font-family="serif">
           、 
         </text></g><g data-mml-node="mi" transform="translate(1821.9, 0)"><path data-c="72" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(2550.6, 0)"><text data-variant="normal" transform="matrix(1 0 0 -1 0 0)" font-size="836.9px" font-family="serif">
           、 
         </text></g><g data-mml-node="mi" transform="translate(3665.7, 0)"><path data-c="73" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"></path></g><g data-mml-node="mo" transform="translate(4412.5, 0)"><text data-variant="normal" transform="matrix(1 0 0 -1 0 0)" font-size="836.9px" font-family="serif">
           、 
         </text></g><g data-mml-node="mi" transform="translate(5527.6, 0)"><path data-c="67" d="M311 43Q296 30 267 15T206 0Q143 0 105 45T66 160Q66 265 143 353T314 442Q361 442 401 394L404 398Q406 401 409 404T418 412T431 419T447 422Q461 422 470 413T480 394Q480 379 423 152T363 -80Q345 -134 286 -169T151 -205Q10 -205 10 -137Q10 -111 28 -91T74 -71Q89 -71 102 -80T116 -111Q116 -121 114 -130T107 -144T99 -154T92 -162L90 -164H91Q101 -167 151 -167Q189 -167 211 -155Q234 -144 254 -122T282 -75Q288 -56 298 -13Q311 35 311 43ZM384 328L380 339Q377 350 375 354T369 368T359 382T346 393T328 402T306 405Q262 405 221 352Q191 313 171 233T151 117Q151 38 213 38Q269 38 323 108L331 118L384 328Z"></path></g></g></g></svg></span></span> 分別代表 <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">block_size</code> 、<code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">num_random_blocks</code> 、<code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">num_sliding_blocks</code> 、<code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">num_global_blocks</code> 。我們以 <span style="cursor:pointer;"><span role="presentation" data-formula="b=4，r=1，g=2，s=3，d=5" data-formula-type="inline-equation" style=""><svg
                xmlns="http://www.w3.org/2000/svg" role="img" focusable="false" viewBox="0 -750 17085.2 955" aria-hidden="true" style="vertical-align: -0.464ex;width: 38.654ex;height: 2.161ex;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="62" d="M73 647Q73 657 77 670T89 683Q90 683 161 688T234 694Q246 694 246 685T212 542Q204 508 195 472T180 418L176 399Q176 396 182 402Q231 442 283 442Q345 442 383 396T422 280Q422 169 343 79T173 -11Q123 -11 82 27T40 150V159Q40 180 48 217T97 414Q147 611 147 623T109 637Q104 637 101 637H96Q86 637 83 637T76 640T73 647ZM336 325V331Q336 405 275 405Q258 405 240 397T207 376T181 352T163 330L157 322L136 236Q114 150 114 114Q114 66 138 42Q154 26 178 26Q211 26 245 58Q270 81 285 114T318 219Q336 291 336 325Z"></path></g><g data-mml-node="mo" transform="translate(706.8, 0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mn" transform="translate(1762.6, 0)"><path data-c="34" d="M462 0Q444 3 333 3Q217 3 199 0H190V46H221Q241 46 248 46T265 48T279 53T286 61Q287 63 287 115V165H28V211L179 442Q332 674 334 675Q336 677 355 677H373L379 671V211H471V165H379V114Q379 73 379 66T385 54Q393 47 442 46H471V0H462ZM293 211V545L74 212L183 211H293Z"></path></g><g data-mml-node="mo" transform="translate(2540.3, 0)"><text data-variant="normal" transform="matrix(1 0 0 -1 0 0)" font-size="836.9px" font-family="serif">
           ， 
         </text></g><g data-mml-node="mi" transform="translate(3655.4, 0)"><path data-c="72" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(4384.2, 0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mn" transform="translate(5440, 0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g><g data-mml-node="mo" transform="translate(6217.7, 0)"><text data-variant="normal" transform="matrix(1 0 0 -1 0 0)" font-size="836.9px" font-family="serif">
           ， 
         </text></g><g data-mml-node="mi" transform="translate(7332.8, 0)"><path data-c="67" d="M311 43Q296 30 267 15T206 0Q143 0 105 45T66 160Q66 265 143 353T314 442Q361 442 401 394L404 398Q406 401 409 404T418 412T431 419T447 422Q461 422 470 413T480 394Q480 379 423 152T363 -80Q345 -134 286 -169T151 -205Q10 -205 10 -137Q10 -111 28 -91T74 -71Q89 -71 102 -80T116 -111Q116 -121 114 -130T107 -144T99 -154T92 -162L90 -164H91Q101 -167 151 -167Q189 -167 211 -155Q234 -144 254 -122T282 -75Q288 -56 298 -13Q311 35 311 43ZM384 328L380 339Q377 350 375 354T369 368T359 382T346 393T328 402T306 405Q262 405 221 352Q191 313 171 233T151 117Q151 38 213 38Q269 38 323 108L331 118L384 328Z"></path></g><g data-mml-node="mo" transform="translate(8087.6, 0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mn" transform="translate(9143.4, 0)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g><g data-mml-node="mo" transform="translate(9921.2, 0)"><text data-variant="normal" transform="matrix(1 0 0 -1 0 0)" font-size="836.9px" font-family="serif">
           ， 
         </text></g><g data-mml-node="mi" transform="translate(11036.2, 0)"><path data-c="73" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"></path></g><g data-mml-node="mo" transform="translate(11783, 0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mn" transform="translate(12838.8, 0)"><path data-c="33" d="M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z"></path></g><g data-mml-node="mo" transform="translate(13616.6, 0)"><text data-variant="normal" transform="matrix(1 0 0 -1 0 0)" font-size="836.9px" font-family="serif">
           ， 
         </text></g><g data-mml-node="mi" transform="translate(14731.6, 0)"><path data-c="64" d="M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g><g data-mml-node="mo" transform="translate(15529.4, 0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mn" transform="translate(16585.2, 0)"><path data-c="35" d="M164 157Q164 133 148 117T109 101H102Q148 22 224 22Q294 22 326 82Q345 115 345 210Q345 313 318 349Q292 382 260 382H254Q176 382 136 314Q132 307 129 306T114 304Q97 304 95 310Q93 314 93 485V614Q93 664 98 664Q100 666 102 666Q103 666 123 658T178 642T253 634Q324 634 389 662Q397 666 402 666Q410 666 410 648V635Q328 538 205 538Q174 538 149 544L139 546V374Q158 388 169 396T205 412T256 420Q337 420 393 355T449 201Q449 109 385 44T229 -22Q148 -22 99 32T50 154Q50 178 61 192T84 210T107 214Q132 214 148 197T164 157Z"></path></g></g></g></svg></span></span> 為例來説明 BigBird 塊稀疏注意力的機制部分，如下所示:</p><img class="rich_pages wxw-img" data-imgfileid="100005784" data-ratio="0.47685185185185186" data-type="png" data-w="1080" height="250" style="margin-right: auto;margin-left: auto;width: 454px;border-radius: 5px;display: block;margin-bottom: 15px;height: auto !important;" width="500" src="https://oscimg.oschina.net/oscnet/fab7065d-9994-4720-bcaf-b18128043c8e.png" referrerpolicy="no-referrer"><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);"><span style="cursor:pointer;"><span role="presentation" data-formula="{q} _{1}、{q}_ {2}、{q} _{3:n-2}、{q}_ {n-1}、{q}_{n}" data-formula-type="inline-equation" style=""><svg
                xmlns="http://www.w3.org/2000/svg" role="img" focusable="false" viewBox="0 -750 12388.8 1037.3" aria-hidden="true" style="vertical-align: -0.65ex;width: 28.029ex;height: 2.347ex;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="71" d="M33 157Q33 258 109 349T280 441Q340 441 372 389Q373 390 377 395T388 406T404 418Q438 442 450 442Q454 442 457 439T460 434Q460 425 391 149Q320 -135 320 -139Q320 -147 365 -148H390Q396 -156 396 -157T393 -175Q389 -188 383 -194H370Q339 -192 262 -192Q234 -192 211 -192T174 -192T157 -193Q143 -193 143 -185Q143 -182 145 -170Q149 -154 152 -151T172 -148Q220 -148 230 -141Q238 -136 258 -53T279 32Q279 33 272 29Q224 -10 172 -10Q117 -10 75 30T33 157ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g></g><g data-mml-node="TeXAtom" transform="translate(446, -229.4) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g></g><g data-mml-node="mo" transform="translate(1127.3, 0)"><text data-variant="normal" transform="matrix(1 0 0 -1 0 0)" font-size="836.9px" font-family="serif">
           、 
         </text></g><g data-mml-node="msub" transform="translate(2242.4, 0)"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="71" d="M33 157Q33 258 109 349T280 441Q340 441 372 389Q373 390 377 395T388 406T404 418Q438 442 450 442Q454 442 457 439T460 434Q460 425 391 149Q320 -135 320 -139Q320 -147 365 -148H390Q396 -156 396 -157T393 -175Q389 -188 383 -194H370Q339 -192 262 -192Q234 -192 211 -192T174 -192T157 -193Q143 -193 143 -185Q143 -182 145 -170Q149 -154 152 -151T172 -148Q220 -148 230 -141Q238 -136 258 -53T279 32Q279 33 272 29Q224 -10 172 -10Q117 -10 75 30T33 157ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g></g><g data-mml-node="TeXAtom" transform="translate(446, -229.4) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g></g></g><g data-mml-node="mo" transform="translate(3369.7, 0)"><text data-variant="normal" transform="matrix(1 0 0 -1 0 0)" font-size="836.9px" font-family="serif">
           、 
         </text></g><g data-mml-node="msub" transform="translate(4484.8, 0)"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="71" d="M33 157Q33 258 109 349T280 441Q340 441 372 389Q373 390 377 395T388 406T404 418Q438 442 450 442Q454 442 457 439T460 434Q460 425 391 149Q320 -135 320 -139Q320 -147 365 -148H390Q396 -156 396 -157T393 -175Q389 -188 383 -194H370Q339 -192 262 -192Q234 -192 211 -192T174 -192T157 -193Q143 -193 143 -185Q143 -182 145 -170Q149 -154 152 -151T172 -148Q220 -148 230 -141Q238 -136 258 -53T279 32Q279 33 272 29Q224 -10 172 -10Q117 -10 75 30T33 157ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g></g><g data-mml-node="TeXAtom" transform="translate(446, -229.4) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="33" d="M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z"></path></g><g data-mml-node="mo" transform="translate(500, 0)"><path data-c="3A" d="M78 370Q78 394 95 412T138 430Q162 430 180 414T199 371Q199 346 182 328T139 310T96 327T78 370ZM78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60Z"></path></g><g data-mml-node="mi" transform="translate(778, 0)"><path data-c="6E" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(1378, 0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mn" transform="translate(2156, 0)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g></g></g><g data-mml-node="mo" transform="translate(7136.7, 0)"><text data-variant="normal" transform="matrix(1 0 0 -1 0 0)" font-size="836.9px" font-family="serif">
           、 
         </text></g><g data-mml-node="msub" transform="translate(8251.8, 0)"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="71" d="M33 157Q33 258 109 349T280 441Q340 441 372 389Q373 390 377 395T388 406T404 418Q438 442 450 442Q454 442 457 439T460 434Q460 425 391 149Q320 -135 320 -139Q320 -147 365 -148H390Q396 -156 396 -157T393 -175Q389 -188 383 -194H370Q339 -192 262 -192Q234 -192 211 -192T174 -192T157 -193Q143 -193 143 -185Q143 -182 145 -170Q149 -154 152 -151T172 -148Q220 -148 230 -141Q238 -136 258 -53T279 32Q279 33 272 29Q224 -10 172 -10Q117 -10 75 30T33 157ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g></g><g data-mml-node="TeXAtom" transform="translate(446, -229.4) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="6E" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(600, 0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mn" transform="translate(1378, 0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g></g><g data-mml-node="mo" transform="translate(10353.5, 0)"><text data-variant="normal" transform="matrix(1 0 0 -1 0 0)" font-size="836.9px" font-family="serif">
           、 
         </text></g><g data-mml-node="msub" transform="translate(11468.6, 0)"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="71" d="M33 157Q33 258 109 349T280 441Q340 441 372 389Q373 390 377 395T388 406T404 418Q438 442 450 442Q454 442 457 439T460 434Q460 425 391 149Q320 -135 320 -139Q320 -147 365 -148H390Q396 -156 396 -157T393 -175Q389 -188 383 -194H370Q339 -192 262 -192Q234 -192 211 -192T174 -192T157 -193Q143 -193 143 -185Q143 -182 145 -170Q149 -154 152 -151T172 -148Q220 -148 230 -141Q238 -136 258 -53T279 32Q279 33 272 29Q224 -10 172 -10Q117 -10 75 30T33 157ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g></g><g data-mml-node="TeXAtom" transform="translate(446, -229.4) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="6E" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g></g></g></g></g></svg></span></span> 的注意力分數分別計算如下:</p><hr data-tool="mdnice 編輯器" style="height: 1px;border-right: none;border-bottom: none;border-left: none;border-top-style: solid;border-top-color: rgb(249, 191, 69);margin-top: 20px;margin-bottom: 20px;"><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);"><span style="cursor:pointer;"><span role="presentation" data-formula="\mathbf{q}_{1}" data-formula-type="inline-equation" style=""><svg
                xmlns="http://www.w3.org/2000/svg" role="img" focusable="false" viewBox="0 -450 1010.6 679.4" aria-hidden="true" style="vertical-align: -0.519ex;width: 2.286ex;height: 1.537ex;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="71" d="M38 220Q38 273 54 314T95 380T152 421T211 443T264 449Q368 449 429 386L438 377L484 450H540V-132H609V-194H600Q582 -191 475 -191Q360 -191 351 -194H342V-132H411V42Q409 41 399 34T383 25T367 16T347 7T324 1T296 -4T264 -6Q162 -6 100 56T38 220ZM287 46Q368 46 417 127V301L412 312Q398 347 369 371T302 395Q282 395 263 388T225 362T194 308T182 221Q182 126 214 86T287 46Z"></path></g></g><g data-mml-node="TeXAtom" transform="translate(607, -229.4) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g></g></g></g></svg></span></span> 的注意力分數由 <span style="cursor:pointer;"><span role="presentation" data-formula="a_1" data-formula-type="inline-equation" style=""><svg
                xmlns="http://www.w3.org/2000/svg" role="img" focusable="false" viewBox="0 -441 932.6 591" aria-hidden="true" style="vertical-align: -0.339ex;width: 2.11ex;height: 1.337ex;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="61" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path></g><g data-mml-node="mn" transform="translate(529, -150) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g></g></g></svg></span></span> 表示，其中 <span style="cursor:pointer;"><span role="presentation" data-formula="a_1=Softmax(q_1 * K^T)" data-formula-type="inline-equation" style=""><svg
                xmlns="http://www.w3.org/2000/svg" role="img" focusable="false" viewBox="0 -841.7 10352.9 1091.7" aria-hidden="true" style="vertical-align: -0.566ex;width: 23.423ex;height: 2.47ex;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="61" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path></g><g data-mml-node="mn" transform="translate(529, -150) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g><g data-mml-node="mo" transform="translate(1210.3, 0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mi" transform="translate(2266.1, 0)"><path data-c="53" d="M308 24Q367 24 416 76T466 197Q466 260 414 284Q308 311 278 321T236 341Q176 383 176 462Q176 523 208 573T273 648Q302 673 343 688T407 704H418H425Q521 704 564 640Q565 640 577 653T603 682T623 704Q624 704 627 704T632 705Q645 705 645 698T617 577T585 459T569 456Q549 456 549 465Q549 471 550 475Q550 478 551 494T553 520Q553 554 544 579T526 616T501 641Q465 662 419 662Q362 662 313 616T263 510Q263 480 278 458T319 427Q323 425 389 408T456 390Q490 379 522 342T554 242Q554 216 546 186Q541 164 528 137T492 78T426 18T332 -20Q320 -22 298 -22Q199 -22 144 33L134 44L106 13Q83 -14 78 -18T65 -22Q52 -22 52 -14Q52 -11 110 221Q112 227 130 227H143Q149 221 149 216Q149 214 148 207T144 186T142 153Q144 114 160 87T203 47T255 29T308 24Z"></path></g><g data-mml-node="mi" transform="translate(2911.1, 0)"><path data-c="6F" d="M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z"></path></g><g data-mml-node="mi" transform="translate(3396.1, 0)"><path data-c="66" d="M118 -162Q120 -162 124 -164T135 -167T147 -168Q160 -168 171 -155T187 -126Q197 -99 221 27T267 267T289 382V385H242Q195 385 192 387Q188 390 188 397L195 425Q197 430 203 430T250 431Q298 431 298 432Q298 434 307 482T319 540Q356 705 465 705Q502 703 526 683T550 630Q550 594 529 578T487 561Q443 561 443 603Q443 622 454 636T478 657L487 662Q471 668 457 668Q445 668 434 658T419 630Q412 601 403 552T387 469T380 433Q380 431 435 431Q480 431 487 430T498 424Q499 420 496 407T491 391Q489 386 482 386T428 385H372L349 263Q301 15 282 -47Q255 -132 212 -173Q175 -205 139 -205Q107 -205 81 -186T55 -132Q55 -95 76 -78T118 -61Q162 -61 162 -103Q162 -122 151 -136T127 -157L118 -162Z"></path></g><g data-mml-node="mi" transform="translate(3946.1, 0)"><path data-c="74" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mi" transform="translate(4307.1, 0)"><path data-c="6D" d="M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(5185.1, 0)"><path data-c="61" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path></g><g data-mml-node="mi" transform="translate(5714.1, 0)"><path data-c="78" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mo" transform="translate(6286.1, 0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="msub" transform="translate(6675.1, 0)"><g data-mml-node="mi"><path data-c="71" d="M33 157Q33 258 109 349T280 441Q340 441 372 389Q373 390 377 395T388 406T404 418Q438 442 450 442Q454 442 457 439T460 434Q460 425 391 149Q320 -135 320 -139Q320 -147 365 -148H390Q396 -156 396 -157T393 -175Q389 -188 383 -194H370Q339 -192 262 -192Q234 -192 211 -192T174 -192T157 -193Q143 -193 143 -185Q143 -182 145 -170Q149 -154 152 -151T172 -148Q220 -148 230 -141Q238 -136 258 -53T279 32Q279 33 272 29Q224 -10 172 -10Q117 -10 75 30T33 157ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g><g data-mml-node="mn" transform="translate(446, -150) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g><g data-mml-node="mo" transform="translate(7746.9, 0)"><path data-c="2217" d="M229 286Q216 420 216 436Q216 454 240 464Q241 464 245 464T251 465Q263 464 273 456T283 436Q283 419 277 356T270 286L328 328Q384 369 389 372T399 375Q412 375 423 365T435 338Q435 325 425 315Q420 312 357 282T289 250L355 219L425 184Q434 175 434 161Q434 146 425 136T401 125Q393 125 383 131T328 171L270 213Q283 79 283 63Q283 53 276 44T250 35Q231 35 224 44T216 63Q216 80 222 143T229 213L171 171Q115 130 110 127Q106 124 100 124Q87 124 76 134T64 161Q64 166 64 169T67 175T72 181T81 188T94 195T113 204T138 215T170 230T210 250L74 315Q65 324 65 338Q65 353 74 363T98 374Q106 374 116 368T171 328L229 286Z"></path></g><g data-mml-node="msup" transform="translate(8469.1, 0)"><g data-mml-node="mi"><path data-c="4B" d="M285 628Q285 635 228 637Q205 637 198 638T191 647Q191 649 193 661Q199 681 203 682Q205 683 214 683H219Q260 681 355 681Q389 681 418 681T463 682T483 682Q500 682 500 674Q500 669 497 660Q496 658 496 654T495 648T493 644T490 641T486 639T479 638T470 637T456 637Q416 636 405 634T387 623L306 305Q307 305 490 449T678 597Q692 611 692 620Q692 635 667 637Q651 637 651 648Q651 650 654 662T659 677Q662 682 676 682Q680 682 711 681T791 680Q814 680 839 681T869 682Q889 682 889 672Q889 650 881 642Q878 637 862 637Q787 632 726 586Q710 576 656 534T556 455L509 418L518 396Q527 374 546 329T581 244Q656 67 661 61Q663 59 666 57Q680 47 717 46H738Q744 38 744 37T741 19Q737 6 731 0H720Q680 3 625 3Q503 3 488 0H478Q472 6 472 9T474 27Q478 40 480 43T491 46H494Q544 46 544 71Q544 75 517 141T485 216L427 354L359 301L291 248L268 155Q245 63 245 58Q245 51 253 49T303 46H334Q340 37 340 35Q340 19 333 5Q328 0 317 0Q314 0 280 1T180 2Q118 2 85 2T49 1Q31 1 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Z"></path></g><g data-mml-node="mi" transform="translate(947, 363) scale(0.707)"><path data-c="54" d="M40 437Q21 437 21 445Q21 450 37 501T71 602L88 651Q93 669 101 677H569H659Q691 677 697 676T704 667Q704 661 687 553T668 444Q668 437 649 437Q640 437 637 437T631 442L629 445Q629 451 635 490T641 551Q641 586 628 604T573 629Q568 630 515 631Q469 631 457 630T439 622Q438 621 368 343T298 60Q298 48 386 46Q418 46 427 45T436 36Q436 31 433 22Q429 4 424 1L422 0Q419 0 415 0Q410 0 363 1T228 2Q99 2 64 0H49Q43 6 43 9T45 27Q49 40 55 46H83H94Q174 46 189 55Q190 56 191 56Q196 59 201 76T241 233Q258 301 269 344Q339 619 339 625Q339 630 310 630H279Q212 630 191 624Q146 614 121 583T67 467Q60 445 57 441T43 437H40Z"></path></g></g><g data-mml-node="mo" transform="translate(9963.9, 0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g></g></svg></span></span>，即為第一塊中的所有詞元與序列中的所有其他詞元之間的注意力分數。</p><figure data-tool="mdnice 編輯器" style="margin-top: 10px;margin-bottom: 10px;display: flex;flex-direction: column;justify-content: center;align-items: center;"><img class="rich_pages wxw-img" data-imgfileid="100005785" data-ratio="0.18981481481481483" data-type="png" data-w="1080" style="margin-right: auto;margin-left: auto;width: 540px;border-radius: 5px;display: block;margin-bottom: 15px;height: auto !important;" src="https://oscimg.oschina.net/oscnet/e529cce5-c61b-4f5b-aead-50797118edfa.png" referrerpolicy="no-referrer"><figcaption style="margin-top: 5px;text-align: center;color: #dda52d;font-size: 14px;">
     BigBird 塊稀疏注意力 
   </figcaption></figure><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);"><span style="cursor:pointer;"><span role="presentation" data-formula="q_1" data-formula-type="inline-equation" style=""><svg
                xmlns="http://www.w3.org/2000/svg" role="img" focusable="false" viewBox="0 -442 849.6 636" aria-hidden="true" style="vertical-align: -0.439ex;width: 1.922ex;height: 1.439ex;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="71" d="M33 157Q33 258 109 349T280 441Q340 441 372 389Q373 390 377 395T388 406T404 418Q438 442 450 442Q454 442 457 439T460 434Q460 425 391 149Q320 -135 320 -139Q320 -147 365 -148H390Q396 -156 396 -157T393 -175Q389 -188 383 -194H370Q339 -192 262 -192Q234 -192 211 -192T174 -192T157 -193Q143 -193 143 -185Q143 -182 145 -170Q149 -154 152 -151T172 -148Q220 -148 230 -141Q238 -136 258 -53T279 32Q279 33 272 29Q224 -10 172 -10Q117 -10 75 30T33 157ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g><g data-mml-node="mn" transform="translate(446, -150) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g></g></g></svg></span></span> 表示第 1 塊，<span style="cursor:pointer;"><span role="presentation" data-formula="g_i" data-formula-type="inline-equation" style=""><svg
                xmlns="http://www.w3.org/2000/svg" role="img" focusable="false" viewBox="0 -442 771 647" aria-hidden="true" style="vertical-align: -0.464ex;width: 1.744ex;height: 1.464ex;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="67" d="M311 43Q296 30 267 15T206 0Q143 0 105 45T66 160Q66 265 143 353T314 442Q361 442 401 394L404 398Q406 401 409 404T418 412T431 419T447 422Q461 422 470 413T480 394Q480 379 423 152T363 -80Q345 -134 286 -169T151 -205Q10 -205 10 -137Q10 -111 28 -91T74 -71Q89 -71 102 -80T116 -111Q116 -121 114 -130T107 -144T99 -154T92 -162L90 -164H91Q101 -167 151 -167Q189 -167 211 -155Q234 -144 254 -122T282 -75Q288 -56 298 -13Q311 35 311 43ZM384 328L380 339Q377 350 375 354T369 368T359 382T346 393T328 402T306 405Q262 405 221 352Q191 313 171 233T151 117Q151 38 213 38Q269 38 323 108L331 118L384 328Z"></path></g><g data-mml-node="mi" transform="translate(477, -150) scale(0.707)"><path data-c="69" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g></g></g></svg></span></span> 表示第 <span style="cursor:pointer;"><span role="presentation" data-formula="i" data-formula-type="inline-equation" style=""><svg
                xmlns="http://www.w3.org/2000/svg" role="img" focusable="false" viewBox="0 -661 345 672" aria-hidden="true" style="vertical-align: -0.025ex;width: 0.781ex;height: 1.52ex;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="69" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g></g></svg></span></span> 塊。我們僅在 <span style="cursor:pointer;"><span role="presentation" data-formula="q_1" data-formula-type="inline-equation" style=""><svg
                xmlns="http://www.w3.org/2000/svg" role="img" focusable="false" viewBox="0 -442 849.6 636" aria-hidden="true" style="vertical-align: -0.439ex;width: 1.922ex;height: 1.439ex;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="71" d="M33 157Q33 258 109 349T280 441Q340 441 372 389Q373 390 377 395T388 406T404 418Q438 442 450 442Q454 442 457 439T460 434Q460 425 391 149Q320 -135 320 -139Q320 -147 365 -148H390Q396 -156 396 -157T393 -175Q389 -188 383 -194H370Q339 -192 262 -192Q234 -192 211 -192T174 -192T157 -193Q143 -193 143 -185Q143 -182 145 -170Q149 -154 152 -151T172 -148Q220 -148 230 -141Q238 -136 258 -53T279 32Q279 33 272 29Q224 -10 172 -10Q117 -10 75 30T33 157ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g><g data-mml-node="mn" transform="translate(446, -150) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g></g></g></svg></span></span> 和 &nbsp;<span style="cursor:pointer;"><span role="presentation" data-formula="g" data-formula-type="inline-equation" style=""><svg
                xmlns="http://www.w3.org/2000/svg" role="img" focusable="false" viewBox="0 -442 477 647" aria-hidden="true" style="vertical-align: -0.464ex;width: 1.079ex;height: 1.464ex;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="67" d="M311 43Q296 30 267 15T206 0Q143 0 105 45T66 160Q66 265 143 353T314 442Q361 442 401 394L404 398Q406 401 409 404T418 412T431 419T447 422Q461 422 470 413T480 394Q480 379 423 152T363 -80Q345 -134 286 -169T151 -205Q10 -205 10 -137Q10 -111 28 -91T74 -71Q89 -71 102 -80T116 -111Q116 -121 114 -130T107 -144T99 -154T92 -162L90 -164H91Q101 -167 151 -167Q189 -167 211 -155Q234 -144 254 -122T282 -75Q288 -56 298 -13Q311 35 311 43ZM384 328L380 339Q377 350 375 354T369 368T359 382T346 393T328 402T306 405Q262 405 221 352Q191 313 171 233T151 117Q151 38 213 38Q269 38 323 108L331 118L384 328Z"></path></g></g></g></svg></span></span> (即所有鍵) 之間執行正常的注意力操作。</p><hr data-tool="mdnice 編輯器" style="height: 1px;border-right: none;border-bottom: none;border-left: none;border-top-style: solid;border-top-color: rgb(249, 191, 69);margin-top: 20px;margin-bottom: 20px;"><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">為了計算第二塊中詞元的注意力分數，我們收集前三塊、最後一塊和第五塊。然後我們可以計算 <span style="cursor:pointer;"><span role="presentation" data-formula="a_2 = Softmax(q_2 * concat(k_1, k_2, k_3, k_5, k_7))" data-formula-type="inline-equation" style=""><embed style="vertical-align: -0.566ex;width: 42.712ex;height: auto;" src="https://oscimg.oschina.net/oscnet/63e34c61-946b-4bd4-bdd2-31f707091583.svg" data-type="svg+xml" data-imgfileid="100005776"></span></span>。</p><figure data-tool="mdnice 編輯器" style="margin-top: 10px;margin-bottom: 10px;display: flex;flex-direction: column;justify-content: center;align-items: center;"><img class="rich_pages wxw-img" data-imgfileid="100005783" data-ratio="0.2101851851851852" data-type="png" data-w="1080" style="margin-right: auto;margin-left: auto;width: 546px;border-radius: 5px;display: block;margin-bottom: 15px;height: auto !important;" src="https://oscimg.oschina.net/oscnet/9bbea6fc-3f75-40d4-ba61-d47c6ec63c69.png" referrerpolicy="no-referrer"><figcaption style="margin-top: 5px;text-align: center;color: #dda52d;font-size: 14px;">
     BigBird 塊稀疏注意力 
   </figcaption></figure><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);"><em style="color: black;">這裏，我用 <span style="cursor:pointer;"><span role="presentation" data-formula="g，r，s" data-formula-type="inline-equation" style=""><svg
                xmlns="http://www.w3.org/2000/svg" role="img" focusable="false" viewBox="0 -750 4182.7 955" aria-hidden="true" style="vertical-align: -0.464ex;width: 9.463ex;height: 2.161ex;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="67" d="M311 43Q296 30 267 15T206 0Q143 0 105 45T66 160Q66 265 143 353T314 442Q361 442 401 394L404 398Q406 401 409 404T418 412T431 419T447 422Q461 422 470 413T480 394Q480 379 423 152T363 -80Q345 -134 286 -169T151 -205Q10 -205 10 -137Q10 -111 28 -91T74 -71Q89 -71 102 -80T116 -111Q116 -121 114 -130T107 -144T99 -154T92 -162L90 -164H91Q101 -167 151 -167Q189 -167 211 -155Q234 -144 254 -122T282 -75Q288 -56 298 -13Q311 35 311 43ZM384 328L380 339Q377 350 375 354T369 368T359 382T346 393T328 402T306 405Q262 405 221 352Q191 313 171 233T151 117Q151 38 213 38Q269 38 323 108L331 118L384 328Z"></path></g><g data-mml-node="mo" transform="translate(754.8, 0)"><text data-variant="normal" transform="matrix(1 0 0 -1 0 0)" font-size="836.9px" font-family="serif">
            ， 
          </text></g><g data-mml-node="mi" transform="translate(1869.9, 0)"><path data-c="72" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(2598.6, 0)"><text data-variant="normal" transform="matrix(1 0 0 -1 0 0)" font-size="836.9px" font-family="serif">
            ， 
          </text></g><g data-mml-node="mi" transform="translate(3713.7, 0)"><path data-c="73" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"></path></g></g></g></svg></span></span> 表示詞元只是為了明確地表示它們的性質 (即是全局、隨機還是滑動詞元)，只用 <span style="cursor:pointer;"><span role="presentation" data-formula="k" data-formula-type="inline-equation" style=""><svg
                xmlns="http://www.w3.org/2000/svg" role="img" focusable="false" viewBox="0 -694 521 705" aria-hidden="true" style="vertical-align: -0.025ex;width: 1.179ex;height: 1.595ex;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="6B" d="M121 647Q121 657 125 670T137 683Q138 683 209 688T282 694Q294 694 294 686Q294 679 244 477Q194 279 194 272Q213 282 223 291Q247 309 292 354T362 415Q402 442 438 442Q468 442 485 423T503 369Q503 344 496 327T477 302T456 291T438 288Q418 288 406 299T394 328Q394 353 410 369T442 390L458 393Q446 405 434 405H430Q398 402 367 380T294 316T228 255Q230 254 243 252T267 246T293 238T320 224T342 206T359 180T365 147Q365 130 360 106T354 66Q354 26 381 26Q429 26 459 145Q461 153 479 153H483Q499 153 499 144Q499 139 496 130Q455 -11 378 -11Q333 -11 305 15T277 90Q277 108 280 121T283 145Q283 167 269 183T234 206T200 217T182 220H180Q168 178 159 139T145 81T136 44T129 20T122 7T111 -2Q98 -11 83 -11Q66 -11 57 -1T48 16Q48 26 85 176T158 471L195 616Q196 629 188 632T149 637H144Q134 637 131 637T124 640T121 647Z"></path></g></g></g></svg></span></span> 無法表示他們各自的性質。</em></p><hr data-tool="mdnice 編輯器" style="height: 1px;border-right: none;border-bottom: none;border-left: none;border-top-style: solid;border-top-color: rgb(249, 191, 69);margin-top: 20px;margin-bottom: 20px;"><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">為了計算 <span style="cursor:pointer;"><span role="presentation" data-formula="{q} _{3:n-2}" data-formula-type="inline-equation" style=""><svg
                xmlns="http://www.w3.org/2000/svg" role="img" focusable="false" viewBox="0 -442 2374.1 729.3" aria-hidden="true" style="vertical-align: -0.65ex;width: 5.371ex;height: 1.65ex;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="71" d="M33 157Q33 258 109 349T280 441Q340 441 372 389Q373 390 377 395T388 406T404 418Q438 442 450 442Q454 442 457 439T460 434Q460 425 391 149Q320 -135 320 -139Q320 -147 365 -148H390Q396 -156 396 -157T393 -175Q389 -188 383 -194H370Q339 -192 262 -192Q234 -192 211 -192T174 -192T157 -193Q143 -193 143 -185Q143 -182 145 -170Q149 -154 152 -151T172 -148Q220 -148 230 -141Q238 -136 258 -53T279 32Q279 33 272 29Q224 -10 172 -10Q117 -10 75 30T33 157ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g></g><g data-mml-node="TeXAtom" transform="translate(446, -229.4) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="33" d="M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z"></path></g><g data-mml-node="mo" transform="translate(500, 0)"><path data-c="3A" d="M78 370Q78 394 95 412T138 430Q162 430 180 414T199 371Q199 346 182 328T139 310T96 327T78 370ZM78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60Z"></path></g><g data-mml-node="mi" transform="translate(778, 0)"><path data-c="6E" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(1378, 0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mn" transform="translate(2156, 0)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g></g></g></g></g></svg></span></span> 的注意力分數，我們先收集相應的全局、滑動、隨機鍵向量，並基於它們正常計算 <span style="cursor:pointer;"><span role="presentation" data-formula="{q}_ {3:n-2}" data-formula-type="inline-equation" style=""><svg
                xmlns="http://www.w3.org/2000/svg" role="img" focusable="false" viewBox="0 -442 2374.1 729.3" aria-hidden="true" style="vertical-align: -0.65ex;width: 5.371ex;height: 1.65ex;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="71" d="M33 157Q33 258 109 349T280 441Q340 441 372 389Q373 390 377 395T388 406T404 418Q438 442 450 442Q454 442 457 439T460 434Q460 425 391 149Q320 -135 320 -139Q320 -147 365 -148H390Q396 -156 396 -157T393 -175Q389 -188 383 -194H370Q339 -192 262 -192Q234 -192 211 -192T174 -192T157 -193Q143 -193 143 -185Q143 -182 145 -170Q149 -154 152 -151T172 -148Q220 -148 230 -141Q238 -136 258 -53T279 32Q279 33 272 29Q224 -10 172 -10Q117 -10 75 30T33 157ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g></g><g data-mml-node="TeXAtom" transform="translate(446, -229.4) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="33" d="M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z"></path></g><g data-mml-node="mo" transform="translate(500, 0)"><path data-c="3A" d="M78 370Q78 394 95 412T138 430Q162 430 180 414T199 371Q199 346 182 328T139 310T96 327T78 370ZM78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60Z"></path></g><g data-mml-node="mi" transform="translate(778, 0)"><path data-c="6E" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(1378, 0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mn" transform="translate(2156, 0)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g></g></g></g></g></svg></span></span> 上的注意力。請注意，正如前面滑動注意力部分所討論的，滑動鍵是使用特殊的移位技巧來收集的。</p><figure data-tool="mdnice 編輯器" style="margin-top: 10px;margin-bottom: 10px;display: flex;flex-direction: column;justify-content: center;align-items: center;"><img class="rich_pages wxw-img" data-imgfileid="100005787" data-ratio="0.1925925925925926" data-type="png" data-w="1080" style="margin-right: auto;margin-left: auto;width: 518px;border-radius: 5px;display: block;margin-bottom: 15px;height: auto !important;" src="https://oscimg.oschina.net/oscnet/d6d57300-3e72-471f-8996-bc71b71674d8.png" referrerpolicy="no-referrer"><figcaption style="margin-top: 5px;text-align: center;color: #dda52d;font-size: 14px;">
     BigBird 塊稀疏注意力 
   </figcaption></figure><hr data-tool="mdnice 編輯器" style="height: 1px;border-right: none;border-bottom: none;border-left: none;border-top-style: solid;border-top-color: rgb(249, 191, 69);margin-top: 20px;margin-bottom: 20px;"><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">為了計算倒數第二塊 (即 <span style="cursor:pointer;"><span role="presentation" data-formula="{q} _{n-1}" data-formula-type="inline-equation" style=""><svg
                xmlns="http://www.w3.org/2000/svg" role="img" focusable="false" viewBox="0 -442 1823.9 729.3" aria-hidden="true" style="vertical-align: -0.65ex;width: 4.127ex;height: 1.65ex;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="71" d="M33 157Q33 258 109 349T280 441Q340 441 372 389Q373 390 377 395T388 406T404 418Q438 442 450 442Q454 442 457 439T460 434Q460 425 391 149Q320 -135 320 -139Q320 -147 365 -148H390Q396 -156 396 -157T393 -175Q389 -188 383 -194H370Q339 -192 262 -192Q234 -192 211 -192T174 -192T157 -193Q143 -193 143 -185Q143 -182 145 -170Q149 -154 152 -151T172 -148Q220 -148 230 -141Q238 -136 258 -53T279 32Q279 33 272 29Q224 -10 172 -10Q117 -10 75 30T33 157ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g></g><g data-mml-node="TeXAtom" transform="translate(446, -229.4) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="6E" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(600, 0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mn" transform="translate(1378, 0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g></g></g></g></svg></span></span>) 中詞元的注意力分數，我們收集第一塊、最後三塊和第三塊的鍵向量。然後我們用公式 <span style="cursor:pointer;"><span role="presentation" data-formula="{a}_ {n-1} = Softmax({q}_{n-1} * concat(k_1, k_3, k_5, k_6, k_7))" data-formula-type="inline-equation" style=""><embed style="vertical-align: -0.65ex;width: 47.121ex;height: auto;" src="https://oscimg.oschina.net/oscnet/7d3fe6d1-79cd-4a4f-9b73-e294300d9bb5.svg" data-type="svg+xml" data-imgfileid="100005774"></span></span> 進行計算。這和計算 <span style="cursor:pointer;"><span role="presentation" data-formula="q_2" data-formula-type="inline-equation" style=""><svg
                xmlns="http://www.w3.org/2000/svg" role="img" focusable="false" viewBox="0 -442 849.6 636" aria-hidden="true" style="vertical-align: -0.439ex;width: 1.922ex;height: 1.439ex;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="71" d="M33 157Q33 258 109 349T280 441Q340 441 372 389Q373 390 377 395T388 406T404 418Q438 442 450 442Q454 442 457 439T460 434Q460 425 391 149Q320 -135 320 -139Q320 -147 365 -148H390Q396 -156 396 -157T393 -175Q389 -188 383 -194H370Q339 -192 262 -192Q234 -192 211 -192T174 -192T157 -193Q143 -193 143 -185Q143 -182 145 -170Q149 -154 152 -151T172 -148Q220 -148 230 -141Q238 -136 258 -53T279 32Q279 33 272 29Q224 -10 172 -10Q117 -10 75 30T33 157ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g><g data-mml-node="mn" transform="translate(446, -150) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g></g></g></g></svg></span></span> 非常相似。</p><figure data-tool="mdnice 編輯器" style="margin-top: 10px;margin-bottom: 10px;display: flex;flex-direction: column;justify-content: center;align-items: center;"><img class="rich_pages wxw-img" data-imgfileid="100005790" data-ratio="0.21481481481481482" data-type="png" data-w="1080" style="margin-right: auto;margin-left: auto;width: 545px;border-radius: 5px;display: block;margin-bottom: 15px;height: auto !important;" src="https://oscimg.oschina.net/oscnet/807b8c9a-d09f-438b-90a6-3fa86c3ded16.png" referrerpolicy="no-referrer"><figcaption style="margin-top: 5px;text-align: center;color: #dda52d;font-size: 14px;">
     BigBird 塊稀疏注意力 
   </figcaption></figure><hr data-tool="mdnice 編輯器" style="height: 1px;border-right: none;border-bottom: none;border-left: none;border-top-style: solid;border-top-color: rgb(249, 191, 69);margin-top: 20px;margin-bottom: 20px;"><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">最後一塊 <span style="cursor:pointer;"><span role="presentation" data-formula="\mathbf{q}_{n}" data-formula-type="inline-equation" style=""><svg
                xmlns="http://www.w3.org/2000/svg" role="img" focusable="false" viewBox="0 -450 1081.3 687.1" aria-hidden="true" style="vertical-align: -0.537ex;width: 2.446ex;height: 1.555ex;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="71" d="M38 220Q38 273 54 314T95 380T152 421T211 443T264 449Q368 449 429 386L438 377L484 450H540V-132H609V-194H600Q582 -191 475 -191Q360 -191 351 -194H342V-132H411V42Q409 41 399 34T383 25T367 16T347 7T324 1T296 -4T264 -6Q162 -6 100 56T38 220ZM287 46Q368 46 417 127V301L412 312Q398 347 369 371T302 395Q282 395 263 388T225 362T194 308T182 221Q182 126 214 86T287 46Z"></path></g></g><g data-mml-node="TeXAtom" transform="translate(607, -229.4) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="6E" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g></g></g></g></g></svg></span></span> 的注意力分數由 <span style="cursor:pointer;"><span role="presentation" data-formula="a_n" data-formula-type="inline-equation" style=""><svg
                xmlns="http://www.w3.org/2000/svg" role="img" focusable="false" viewBox="0 -441 1003.3 598.8" aria-hidden="true" style="vertical-align: -0.357ex;width: 2.27ex;height: 1.355ex;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="61" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path></g><g data-mml-node="mi" transform="translate(529, -150) scale(0.707)"><path data-c="6E" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g></g></g></g></svg></span></span> 表示，其中 <span style="cursor:pointer;"><span role="presentation" data-formula="a_n=Softmax(q_n * K^T)" data-formula-type="inline-equation" style=""><embed style="vertical-align: -0.566ex;width: 23.743ex;height: auto;" src="https://oscimg.oschina.net/oscnet/6681adae-1d7d-47f4-bece-c7a7198818a9.svg" data-type="svg+xml" data-imgfileid="100005773"></span></span>，只不過是最後一塊中的所有詞元與序列中的所有其他詞元之間的注意力分數。這與我們對 <span style="cursor:pointer;"><span role="presentation" data-formula="q_1" data-formula-type="inline-equation" style=""><svg
                xmlns="http://www.w3.org/2000/svg" role="img" focusable="false" viewBox="0 -442 849.6 636" aria-hidden="true" style="vertical-align: -0.439ex;width: 1.922ex;height: 1.439ex;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="71" d="M33 157Q33 258 109 349T280 441Q340 441 372 389Q373 390 377 395T388 406T404 418Q438 442 450 442Q454 442 457 439T460 434Q460 425 391 149Q320 -135 320 -139Q320 -147 365 -148H390Q396 -156 396 -157T393 -175Q389 -188 383 -194H370Q339 -192 262 -192Q234 -192 211 -192T174 -192T157 -193Q143 -193 143 -185Q143 -182 145 -170Q149 -154 152 -151T172 -148Q220 -148 230 -141Q238 -136 258 -53T279 32Q279 33 272 29Q224 -10 172 -10Q117 -10 75 30T33 157ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g><g data-mml-node="mn" transform="translate(446, -150) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g></g></g></svg></span></span> 所做的非常相似。</p><figure data-tool="mdnice 編輯器" style="margin-top: 10px;margin-bottom: 10px;display: flex;flex-direction: column;justify-content: center;align-items: center;"><img class="rich_pages wxw-img" data-imgfileid="100005789" data-ratio="0.1925925925925926" data-type="png" data-w="1080" style="margin-right: auto;margin-left: auto;width: 539px;border-radius: 5px;display: block;margin-bottom: 15px;height: auto !important;" src="https://oscimg.oschina.net/oscnet/1e5c321a-8a47-4f4d-8c68-c55f68e0ba07.png" referrerpolicy="no-referrer"><figcaption style="margin-top: 5px;text-align: center;color: #dda52d;font-size: 14px;">
     BigBird 塊稀疏注意力 
   </figcaption></figure><hr data-tool="mdnice 編輯器" style="height: 1px;border-right: none;border-bottom: none;border-left: none;border-top-style: solid;border-top-color: rgb(249, 191, 69);margin-top: 20px;margin-bottom: 20px;"><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">我們將上面的矩陣組合起來得到最終的注意力矩陣。該注意力矩陣可用於獲取所有詞元的表徵。</p><figure data-tool="mdnice 編輯器" style="margin-top: 10px;margin-bottom: 10px;display: flex;flex-direction: column;justify-content: center;align-items: center;"><img class="rich_pages wxw-img" data-imgfileid="100005791" data-ratio="0.6916666666666667" data-type="gif" data-w="600" style="margin-right: auto;margin-left: auto;width: 537px;border-radius: 5px;display: block;margin-bottom: 15px;height: auto !important;" src="https://oscimg.oschina.net/oscnet/d02815bd-44c4-4a61-94f0-f8c6e767b059.gif" referrerpolicy="no-referrer"><figcaption style="margin-top: 5px;text-align: center;color: #dda52d;font-size: 14px;">
     BigBird 塊稀疏注意力 
   </figcaption></figure><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);"><em style="color: black;">上圖中 <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">藍色 -&gt; 全局塊</code> 、<code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">紅色 -&gt; 隨機塊</code> 、<code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">橙色 -&gt; 滑動塊</code> 。在前向傳播過程中，我們不存儲「白色」塊，而是直接為每個單獨的部分計算加權值矩陣 (即每個詞元的表示)，如上所述。</em></p><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">現在，我們已經介紹了塊稀疏注意力最難的部分，即它的實現。希望對你更好地理解實際代碼有幫助。現在你可以深入研究代碼了，在此過程中你可以將代碼的每個部分與上面的某個部分聯繫起來以助於理解。</p><span id="OSC_h2_9"></span><h2 data-tool="mdnice 編輯器" style="font-weight: bold;font-size: 22px;line-height: 1.2em;margin-top: 2em;margin-bottom: 35px;color: rgb(255, 157, 0);"><span style="font-size: 18px;color: rgb(255, 157, 11);padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;display: none;"></span><span style="color: rgb(255, 157, 11);visibility: visible;display: inline-block;border-left: 5px solid rgb(255, 157, 0);padding: 2px 13px;margin-right: 3px;height: 50%;font-size: 18px;">時間和內存複雜度</span><span style="font-size: 18px;color: rgb(255, 157, 11);display: inline-block;padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;"></span></h2><section data-tool="mdnice 編輯器" style="overflow-x: auto;"><table><thead><tr style="border-width: 1px 0px 0px;border-right-style: initial;border-bottom-style: initial;border-left-style: initial;border-right-color: initial;border-bottom-color: initial;border-left-color: initial;border-top-style: solid;border-top-color: rgb(204, 204, 204);background-color: white;"><th style="border-top-width: 1px;border-color: rgb(204, 204, 204);background-color: rgb(240, 240, 240);text-align: center;min-width: 85px;">注意力類型</th><th style="border-top-width: 1px;border-color: rgb(204, 204, 204);background-color: rgb(240, 240, 240);text-align: center;min-width: 85px;">序列長度</th><th style="border-top-width: 1px;border-color: rgb(204, 204, 204);background-color: rgb(240, 240, 240);text-align: center;min-width: 85px;">時間和內存複雜度</th></tr></thead><tbody style="border-width: 0px;border-style: initial;border-color: initial;"><tr style="border-width: 1px 0px 0px;border-right-style: initial;border-bottom-style: initial;border-left-style: initial;border-right-color: initial;border-bottom-color: initial;border-left-color: initial;border-top-style: solid;border-top-color: rgb(204, 204, 204);background-color: white;"><td style="border-color: rgb(204, 204, 204);text-align: center;min-width: 85px;">原始完全注意力</td><td style="border-color: rgb(204, 204, 204);text-align: center;min-width: 85px;">512</td><td style="border-color: rgb(204, 204, 204);text-align: center;min-width: 85px;"><code>T</code></td></tr><tr style="border-width: 1px 0px 0px;border-right-style: initial;border-bottom-style: initial;border-left-style: initial;border-right-color: initial;border-bottom-color: initial;border-left-color: initial;border-top-style: solid;border-top-color: rgb(204, 204, 204);background-color: rgb(248, 248, 248);"><td style="border-color: rgb(204, 204, 204);text-align: center;min-width: 85px;"><br></td><td style="border-color: rgb(204, 204, 204);text-align: center;min-width: 85px;">1024</td><td style="border-color: rgb(204, 204, 204);text-align: center;min-width: 85px;">4 x <code>T</code></td></tr><tr style="border-width: 1px 0px 0px;border-right-style: initial;border-bottom-style: initial;border-left-style: initial;border-right-color: initial;border-bottom-color: initial;border-left-color: initial;border-top-style: solid;border-top-color: rgb(204, 204, 204);background-color: white;"><td style="border-color: rgb(204, 204, 204);text-align: center;min-width: 85px;"><br></td><td style="border-color: rgb(204, 204, 204);text-align: center;min-width: 85px;">4096</td><td style="border-color: rgb(204, 204, 204);text-align: center;min-width: 85px;">64 x <code>T</code></td></tr><tr style="border-width: 1px 0px 0px;border-right-style: initial;border-bottom-style: initial;border-left-style: initial;border-right-color: initial;border-bottom-color: initial;border-left-color: initial;border-top-style: solid;border-top-color: rgb(204, 204, 204);background-color: rgb(248, 248, 248);"><td style="border-color: rgb(204, 204, 204);text-align: center;min-width: 85px;">塊稀疏注意力</td><td style="border-color: rgb(204, 204, 204);text-align: center;min-width: 85px;">1024</td><td style="border-color: rgb(204, 204, 204);text-align: center;min-width: 85px;">2 x <code>T</code></td></tr><tr style="border-width: 1px 0px 0px;border-right-style: initial;border-bottom-style: initial;border-left-style: initial;border-right-color: initial;border-bottom-color: initial;border-left-color: initial;border-top-style: solid;border-top-color: rgb(204, 204, 204);background-color: white;"><td style="border-color: rgb(204, 204, 204);text-align: center;min-width: 85px;"><br></td><td style="border-color: rgb(204, 204, 204);text-align: center;min-width: 85px;">4096</td><td style="border-color: rgb(204, 204, 204);text-align: center;min-width: 85px;">8 x <code>T</code></td></tr></tbody></table></section><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);"><em style="color: black;">BERT 注意力和 BigBird 塊稀疏注意力的時間和空間複雜度之比較。</em></p><summary>展開以瞭解複雜度的計算過程。</summary><pre style="margin-top: 10px;margin-bottom: 10px;"><code style="overflow-x: auto;padding: 16px;color: #333;background: #f8f8f8;display: -webkit-box;font-family: Operator Mono, Consolas, Monaco, Menlo, monospace;border-radius: 0px;font-size: 12px;-webkit-overflow-scrolling: touch;">BigBird&nbsp;時間複雜度&nbsp;=&nbsp;O(w&nbsp;x&nbsp;n&nbsp;+&nbsp;r&nbsp;x&nbsp;n&nbsp;+&nbsp;g&nbsp;x&nbsp;n)<br>BERT&nbsp;時間複雜度&nbsp;=&nbsp;O(n^2)<br><br>假設:<br><span style="line-height: 26px;">&nbsp;&nbsp;&nbsp;&nbsp;w&nbsp;=&nbsp;3&nbsp;x&nbsp;64</span><br><span style="line-height: 26px;">&nbsp;&nbsp;&nbsp;&nbsp;r&nbsp;=&nbsp;3&nbsp;x&nbsp;64</span><br><span style="line-height: 26px;">&nbsp;&nbsp;&nbsp;&nbsp;g&nbsp;=&nbsp;2&nbsp;x&nbsp;64</span><br><br>當序列長度為&nbsp;512&nbsp;時<br>=&gt;&nbsp;<span style="font-weight: bold;line-height: 26px;">**BERT&nbsp;時間複雜度&nbsp;=&nbsp;512^2**</span><br><br>當序列長度為&nbsp;1024&nbsp;時<br>=&gt;&nbsp;BERT&nbsp;時間複雜度&nbsp;=&nbsp;(2&nbsp;x&nbsp;512)^2<br>=&gt;&nbsp;<span style="font-weight: bold;line-height: 26px;">**BERT&nbsp;時間複雜度&nbsp;=&nbsp;4&nbsp;x&nbsp;512^2**</span><br><br>=&gt;&nbsp;BigBird&nbsp;時間複雜度&nbsp;=&nbsp;(8&nbsp;x&nbsp;64)&nbsp;x&nbsp;(2&nbsp;x&nbsp;512)<br>=&gt;&nbsp;<span style="font-weight: bold;line-height: 26px;">**BigBird&nbsp;時間複雜度&nbsp;=&nbsp;2&nbsp;x&nbsp;512^2**</span><br><br>當序列長度為&nbsp;4096&nbsp;時<br>=&gt;&nbsp;BERT&nbsp;時間複雜度&nbsp;=&nbsp;(8&nbsp;x&nbsp;512)^2<br>=&gt;&nbsp;<span style="font-weight: bold;line-height: 26px;">**BERT&nbsp;時間複雜度&nbsp;=&nbsp;64&nbsp;x&nbsp;512^2**</span><br><br>=&gt;&nbsp;BigBird&nbsp;時間複雜度&nbsp;=&nbsp;(8&nbsp;x&nbsp;64)&nbsp;x&nbsp;(8&nbsp;x&nbsp;512)<br>=&gt;&nbsp;BigBird&nbsp;時間複雜度&nbsp;=&nbsp;8&nbsp;x&nbsp;(512&nbsp;x&nbsp;512)<br>=&gt;&nbsp;<span style="font-weight: bold;line-height: 26px;">**BigBird&nbsp;時間複雜度&nbsp;=&nbsp;8&nbsp;x&nbsp;512^2**</span><br></code></pre><span id="OSC_h2_10"></span><h2 data-tool="mdnice 編輯器" style="font-weight: bold;font-size: 22px;line-height: 1.2em;margin-top: 2em;margin-bottom: 35px;color: rgb(255, 157, 0);"><span style="font-size: 18px;color: rgb(255, 157, 11);padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;display: none;"></span><span style="color: rgb(255, 157, 11);visibility: visible;display: inline-block;border-left: 5px solid rgb(255, 157, 0);padding: 2px 13px;margin-right: 3px;height: 50%;font-size: 18px;">ITC 與 ETC</span><span style="font-size: 18px;color: rgb(255, 157, 11);display: inline-block;padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;"></span></h2><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">BigBird 模型可以使用 2 種不同的策略進行訓練: <strong style="color: black;">ITC</strong> 和 <strong style="color: black;">ETC</strong>。 ITC (internal transformer construction，內部 transformer 構建) 就是我們上面討論的。在 ETC (extended transformer construction，擴展 transformer 構建) 中，會有更多的全局詞元，以便它們關注所有詞元或者被所有詞元關注。</p><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">ITC 需要的計算量較小，因為很少有詞元是全局的，同時模型可以捕獲足夠的全局信息 (也可以藉助隨機注意力)。而 ETC 對於需要大量全局詞元的任務非常有幫助，例如對 <strong style="color: black;">問答</strong> 類任務而言，整個問題應該被所有上下文關注，以便能夠將上下文正確地與問題相關聯。</p><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);"><em style="color: black;"><strong>注意:</strong> BigBird 論文顯示，在很多 ETC 實驗中，隨機塊的數量設置為 0。考慮到我們上文圖解部分的討論，這是合理的。</em></p><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">下表總結了 ITC 和 ETC:</p><section data-tool="mdnice 編輯器" style="overflow-x: auto;"><table><thead><tr style="border-width: 1px 0px 0px;border-right-style: initial;border-bottom-style: initial;border-left-style: initial;border-right-color: initial;border-bottom-color: initial;border-left-color: initial;border-top-style: solid;border-top-color: rgb(204, 204, 204);background-color: white;"><th style="border-top-width: 1px;border-color: rgb(204, 204, 204);background-color: rgb(240, 240, 240);text-align: center;min-width: 85px;"><br></th><th style="border-top-width: 1px;border-color: rgb(204, 204, 204);background-color: rgb(240, 240, 240);text-align: center;min-width: 85px;">ITC</th><th style="border-top-width: 1px;border-color: rgb(204, 204, 204);background-color: rgb(240, 240, 240);text-align: center;min-width: 85px;">ETC</th></tr></thead><tbody style="border-width: 0px;border-style: initial;border-color: initial;"><tr style="border-width: 1px 0px 0px;border-right-style: initial;border-bottom-style: initial;border-left-style: initial;border-right-color: initial;border-bottom-color: initial;border-left-color: initial;border-top-style: solid;border-top-color: rgb(204, 204, 204);background-color: white;"><td style="border-color: rgb(204, 204, 204);text-align: center;min-width: 85px;">全局注意力的注意力矩陣</td><td style="border-color: rgb(204, 204, 204);text-align: center;min-width: 85px;word-break: break-all;"><img class="rich_pages wxw-img" data-galleryid="" data-imgfileid="100005792" data-ratio="0.9011976047904192" data-s="300,640" data-type="png" data-w="334" style="letter-spacing: 0px;height: auto !important;" src="https://oscimg.oschina.net/oscnet/d3907d2e-c92d-4c77-afbe-06b2b9a87f87.png" referrerpolicy="no-referrer"></td><td style="border-color: rgb(204, 204, 204);text-align: center;min-width: 85px;word-break: break-all;"><img class="rich_pages wxw-img" data-galleryid="" data-imgfileid="100005793" data-ratio="0.883054892601432" data-s="300,640" data-type="png" data-w="419" style="letter-spacing: 0px;height: auto !important;" src="https://oscimg.oschina.net/oscnet/8082e521-dcef-4270-aee5-5a44b3b87e56.png" referrerpolicy="no-referrer"></td></tr><tr style="border-width: 1px 0px 0px;border-right-style: initial;border-bottom-style: initial;border-left-style: initial;border-right-color: initial;border-bottom-color: initial;border-left-color: initial;border-top-style: solid;border-top-color: rgb(204, 204, 204);background-color: rgb(248, 248, 248);"><td style="border-color: rgb(204, 204, 204);text-align: center;min-width: 85px;">全局詞元</td><td style="border-color: rgb(204, 204, 204);text-align: center;min-width: 85px;">2 x <code>block_size</code></td><td style="border-color: rgb(204, 204, 204);text-align: center;min-width: 85px;"><code>extra_tokens</code> + 2 x <code>block_size</code></td></tr><tr style="border-width: 1px 0px 0px;border-right-style: initial;border-bottom-style: initial;border-left-style: initial;border-right-color: initial;border-bottom-color: initial;border-left-color: initial;border-top-style: solid;border-top-color: rgb(204, 204, 204);background-color: white;"><td style="border-color: rgb(204, 204, 204);text-align: center;min-width: 85px;">隨機詞元</td><td style="border-color: rgb(204, 204, 204);text-align: center;min-width: 85px;"><code>num_random_blocks</code> x <code>block_size</code></td><td style="border-color: rgb(204, 204, 204);text-align: center;min-width: 85px;"><code>num_random_blocks</code> x <code>block_size</code></td></tr><tr style="border-width: 1px 0px 0px;border-right-style: initial;border-bottom-style: initial;border-left-style: initial;border-right-color: initial;border-bottom-color: initial;border-left-color: initial;border-top-style: solid;border-top-color: rgb(204, 204, 204);background-color: rgb(248, 248, 248);"><td style="border-color: rgb(204, 204, 204);text-align: center;min-width: 85px;">滑動詞元</td><td style="border-color: rgb(204, 204, 204);text-align: center;min-width: 85px;">3 x <code>block_size</code></td><td style="border-color: rgb(204, 204, 204);text-align: center;min-width: 85px;">3 x <code>block_size</code></td></tr></tbody></table></section><span id="OSC_h2_11"></span><h2 data-tool="mdnice 編輯器" style="font-weight: bold;font-size: 22px;line-height: 1.2em;margin-top: 2em;margin-bottom: 35px;color: rgb(255, 157, 0);"><span style="font-size: 18px;color: rgb(255, 157, 11);padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;display: none;"></span><span style="color: rgb(255, 157, 11);visibility: visible;display: inline-block;border-left: 5px solid rgb(255, 157, 0);padding: 2px 13px;margin-right: 3px;height: 50%;font-size: 18px;">在 &nbsp;🤗Transformers 中使用 BigBird</span><span style="font-size: 18px;color: rgb(255, 157, 11);display: inline-block;padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;"></span></h2><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">你可以像使用任何其他 🤗 模型一樣使用 <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">BigBirdModel</code> 。我們看一下代碼:</p><pre data-tool="mdnice 編輯器" style="margin-top: 10px;margin-bottom: 10px;"><code style="overflow-x: auto;padding: 16px;color: #333;background: #f8f8f8;display: -webkit-box;font-family: Operator Mono, Consolas, Monaco, Menlo, monospace;border-radius: 0px;font-size: 12px;-webkit-overflow-scrolling: touch;"><span style="font-weight: bold;line-height: 26px;">from</span>&nbsp;transformers&nbsp;<span style="font-weight: bold;line-height: 26px;">import</span>&nbsp;BigBirdModel<br><br><span style="color: #998;font-style: italic;line-height: 26px;">#&nbsp;從預訓練&nbsp;checkpoint&nbsp;中加載&nbsp;bigbird&nbsp;模型</span><br>model&nbsp;=&nbsp;BigBirdModel.from_pretrained(<span style="color: #d14;line-height: 26px;">"google/bigbird-roberta-base"</span>)<br><span style="color: #998;font-style: italic;line-height: 26px;">#&nbsp;使用默認配置初始化模型，如&nbsp;attention_type&nbsp;=&nbsp;"block_sparse"，num_random_blocks&nbsp;=&nbsp;3，block_size&nbsp;=&nbsp;64</span><br><span style="color: #998;font-style: italic;line-height: 26px;">#&nbsp;你也可以按照自己的需要改變這些參數。這&nbsp;3&nbsp;個參數只改變每個查詢詞元關注的詞元數。</span><br>model&nbsp;=&nbsp;BigBirdModel.from_pretrained(<span style="color: #d14;line-height: 26px;">"google/bigbird-roberta-base"</span>,&nbsp;num_random_blocks=<span style="color: #008080;line-height: 26px;">2</span>,&nbsp;block_size=<span style="color: #008080;line-height: 26px;">16</span>)<br><br><span style="color: #998;font-style: italic;line-height: 26px;">#&nbsp;通過把&nbsp;attention_type&nbsp;設成&nbsp;`original_full`，BigBird&nbsp;就會用複雜度為&nbsp;n^2&nbsp;的完全注意力。此時，BigBird&nbsp;與&nbsp;BERT&nbsp;相似度為&nbsp;99.9%。</span><br>model&nbsp;=&nbsp;BigBirdModel.from_pretrained(<span style="color: #d14;line-height: 26px;">"google/bigbird-roberta-base"</span>,&nbsp;attention_type=<span style="color: #d14;line-height: 26px;">"original_full"</span>)<br></code></pre><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">截至現在， <strong style="color: black;">🤗 Hub</strong> 中總共有 <strong style="color: black;">3 個 BigBird checkpoint</strong>: <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">bigbird-roberta-base</code>，<code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">bigbird-roberta-large</code> 以及 <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">bigbird-base-trivia-itc</code>。前兩個檢查點是使用 <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">masked_lm 損失</code> 預訓練 <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">BigBirdForPretraining</code> 而得; 而最後一個是在 <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">trivia-qa</code> 數據集上微調 <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">BigBirdForQuestionAnswering</code> 而得。</p><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">讓我們看一下如果用你自己喜歡的 PyTorch 訓練器，最少需要多少代碼就可以使用 🤗 的 BigBird 模型來微調你自己的任務。</p><pre data-tool="mdnice 編輯器" style="margin-top: 10px;margin-bottom: 10px;"><code style="overflow-x: auto;padding: 16px;color: #333;background: #f8f8f8;display: -webkit-box;font-family: Operator Mono, Consolas, Monaco, Menlo, monospace;border-radius: 0px;font-size: 12px;-webkit-overflow-scrolling: touch;"><span style="color: #998;font-style: italic;line-height: 26px;">#&nbsp;以問答任務為例</span><br><span style="font-weight: bold;line-height: 26px;">from</span>&nbsp;transformers&nbsp;<span style="font-weight: bold;line-height: 26px;">import</span>&nbsp;BigBirdForQuestionAnswering,&nbsp;BigBirdTokenizer<br><span style="font-weight: bold;line-height: 26px;">import</span>&nbsp;torch<br><br>device&nbsp;=&nbsp;torch.device(<span style="color: #d14;line-height: 26px;">"cpu"</span>)<br><span style="font-weight: bold;line-height: 26px;">if</span>&nbsp;torch.cuda.is_available():<br>&nbsp;&nbsp;&nbsp;&nbsp;device&nbsp;=&nbsp;torch.device(<span style="color: #d14;line-height: 26px;">"cuda"</span>)<br><br><span style="color: #998;font-style: italic;line-height: 26px;">#&nbsp;我們用預訓練權重初始化&nbsp;bigbird&nbsp;模型，並隨機初始化其頭分類器</span><br>model&nbsp;=&nbsp;BigBirdForQuestionAnswering.from_pretrained(<span style="color: #d14;line-height: 26px;">"google/bigbird-roberta-base"</span>,&nbsp;block_size=<span style="color: #008080;line-height: 26px;">64</span>,&nbsp;num_random_blocks=<span style="color: #008080;line-height: 26px;">3</span>)<br>tokenizer&nbsp;=&nbsp;BigBirdTokenizer.from_pretrained(<span style="color: #d14;line-height: 26px;">"google/bigbird-roberta-base"</span>)<br>model.to(device)<br><br>dataset&nbsp;=&nbsp;<span style="color: #d14;line-height: 26px;">"torch.utils.data.DataLoader&nbsp;object"</span><br>optimizer&nbsp;=&nbsp;<span style="color: #d14;line-height: 26px;">"torch.optim&nbsp;object"</span><br>epochs&nbsp;=&nbsp;...<br><br><span style="color: #998;font-style: italic;line-height: 26px;">#&nbsp;最簡訓練循環</span><br><span style="font-weight: bold;line-height: 26px;">for</span>&nbsp;e&nbsp;<span style="font-weight: bold;line-height: 26px;">in</span>&nbsp;range(epochs):<br>&nbsp;&nbsp;&nbsp;&nbsp;<span style="font-weight: bold;line-height: 26px;">for</span>&nbsp;batch&nbsp;<span style="font-weight: bold;line-height: 26px;">in</span>&nbsp;dataset:<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;model.train()<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;batch&nbsp;=&nbsp;{k:&nbsp;batch[k].to(device)&nbsp;<span style="font-weight: bold;line-height: 26px;">for</span>&nbsp;k&nbsp;<span style="font-weight: bold;line-height: 26px;">in</span>&nbsp;batch}<br><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color: #998;font-style: italic;line-height: 26px;">#&nbsp;前向</span><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;output&nbsp;=&nbsp;model(**batch)<br><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color: #998;font-style: italic;line-height: 26px;">#&nbsp;後向</span><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;output[<span style="color: #d14;line-height: 26px;">"loss"</span>].backward()<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;optimizer.step()<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;optimizer.zero_grad()<br><br><span style="color: #998;font-style: italic;line-height: 26px;">#&nbsp;將最終權重存至本地目錄</span><br>model.save_pretrained(<span style="color: #d14;line-height: 26px;">"&lt;YOUR-WEIGHTS-DIR&gt;"</span>)<br><br><span style="color: #998;font-style: italic;line-height: 26px;">#&nbsp;將權重推到&nbsp;🤗&nbsp;Hub&nbsp;中</span><br><span style="font-weight: bold;line-height: 26px;">from</span>&nbsp;huggingface_hub&nbsp;<span style="font-weight: bold;line-height: 26px;">import</span>&nbsp;ModelHubMixin<br>ModelHubMixin.push_to_hub(<span style="color: #d14;line-height: 26px;">"&lt;YOUR-WEIGHTS-DIR&gt;"</span>,&nbsp;model_id=<span style="color: #d14;line-height: 26px;">"&lt;YOUR-FINETUNED-ID&gt;"</span>)<br><br><span style="color: #998;font-style: italic;line-height: 26px;">#&nbsp;使用微調後的模型，以用於推理</span><br>question&nbsp;=&nbsp;[<span style="color: #d14;line-height: 26px;">"How&nbsp;are&nbsp;you&nbsp;doing?"</span>,&nbsp;<span style="color: #d14;line-height: 26px;">"How&nbsp;is&nbsp;life&nbsp;going?"</span>]<br>context&nbsp;=&nbsp;[<span style="color: #d14;line-height: 26px;">"&lt;some&nbsp;big&nbsp;context&nbsp;having&nbsp;ans-1&gt;"</span>,&nbsp;<span style="color: #d14;line-height: 26px;">"&lt;some&nbsp;big&nbsp;context&nbsp;having&nbsp;ans-2&gt;"</span>]<br>batch&nbsp;=&nbsp;tokenizer(question,&nbsp;context,&nbsp;return_tensors=<span style="color: #d14;line-height: 26px;">"pt"</span>)<br>batch&nbsp;=&nbsp;{k:&nbsp;batch[k].to(device)&nbsp;<span style="font-weight: bold;line-height: 26px;">for</span>&nbsp;k&nbsp;<span style="font-weight: bold;line-height: 26px;">in</span>&nbsp;batch}<br><br>model&nbsp;=&nbsp;BigBirdForQuestionAnswering.from_pretrained(<span style="color: #d14;line-height: 26px;">"&lt;YOUR-FINETUNED-ID&gt;"</span>)<br>model.to(device)<br><span style="font-weight: bold;line-height: 26px;">with</span>&nbsp;torch.no_grad():<br>&nbsp;&nbsp;&nbsp;&nbsp;start_logits,&nbsp;end_logits&nbsp;=&nbsp;model(**batch).to_tuple()<br>&nbsp;&nbsp;&nbsp;&nbsp;<span style="color: #998;font-style: italic;line-height: 26px;">#&nbsp;這裏，你可以使用自己的策略對&nbsp;start_logits，end_logits&nbsp;進行解碼</span><br><br><span style="color: #998;font-style: italic;line-height: 26px;">#&nbsp;注意:</span><br><span style="color: #998;font-style: italic;line-height: 26px;">#&nbsp;該代碼段僅用於展示即使你想用自己的&nbsp;PyTorch&nbsp;訓練器微調&nbsp;BigBrid，這也是相當容易的。</span><br><span style="color: #998;font-style: italic;line-height: 26px;">#&nbsp;我會建議使用&nbsp;🤗&nbsp;Trainer，它更簡單，功能也更多。</span><br></code></pre><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">使用 BigBird 時，需要記住以下幾點:</p><ul data-tool="mdnice 編輯器" style="margin-top: 8px;margin-bottom: 8px;padding-left: 25px;" class="list-paddingleft-1"><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);">
      序列長度必須是塊大小的倍數，即 
     <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">seqlen % block_size = 0</code> 。你不必擔心，因為如果 batch 的序列長度不是 
     <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">block_size</code> 的倍數，🤗 transformers 會自動填充至最近的整數倍。 
    </section></li><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);">
      目前，Hugging Face 的實現 
     <strong style="color: black;">尚不支持 ETC</strong>，因此只有第一個和最後一個塊是全局的。 
    </section></li><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);">
      當前實現不支持 
     <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">num_random_blocks = 0</code> 。 
    </section></li><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);">
      論文作者建議當序列長度 &lt; 1024 時設置 
     <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">attention_type = "original_full"</code> 。 
    </section></li><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);">
      必須滿足: 
     <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">seq_length &gt; global_token + random_tokens + moving_tokens + buffer_tokens</code> ，其中 
     <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">global_tokens = 2 x block_size</code> 、 
     <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">sliding_tokens = 3 x block_size</code> 、 
     <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">random_tokens = num_random_blocks x block_size</code> 且 
     <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">buffer_tokens = num_random_blocks x block_size</code> 。如果你不能滿足這一點，🤗 transformers 會自動將 
     <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">attention_type</code> 切換為 
     <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">original_full</code> 並告警。 
    </section></li><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);">
      當使用 BigBird 作為解碼器 (或使用 
     <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">BigBirdForCasualLM</code> ) 時， 
     <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">attention_type</code> 應該是 
     <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">original_full</code> 。但你不用擔心，🤗 transformers 會自動將 
     <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">attention_type</code> 切換為 
     <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">original_full</code> ，以防你忘記這樣做。 
    </section></li></ul><span id="OSC_h2_12"></span><h2 data-tool="mdnice 編輯器" style="font-weight: bold;font-size: 22px;line-height: 1.2em;margin-top: 2em;margin-bottom: 35px;color: rgb(255, 157, 0);"><span style="font-size: 18px;color: rgb(255, 157, 11);padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;display: none;"></span><span style="color: rgb(255, 157, 11);visibility: visible;display: inline-block;border-left: 5px solid rgb(255, 157, 0);padding: 2px 13px;margin-right: 3px;height: 50%;font-size: 18px;">下一步</span><span style="font-size: 18px;color: rgb(255, 157, 11);display: inline-block;padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;"></span></h2><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">@patrickvonplaten 建了一個非常酷的，筆記本，以展示如何在 <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">trivia-qa</code> 數據集上評估 <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">BigBirdForQuestionAnswering</code> 。你可以隨意用這個筆記本來玩玩 BigBird。</p><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);"><strong style="color: black;">BigBird 版的 Pegasus</strong> 模型很快就會面世，你可將它們用於 <strong style="color: black;">長文檔摘要</strong> 💥。</p><span id="OSC_h2_13"></span><h2 data-tool="mdnice 編輯器" style="font-weight: bold;font-size: 22px;line-height: 1.2em;margin-top: 2em;margin-bottom: 35px;color: rgb(255, 157, 0);"><span style="font-size: 18px;color: rgb(255, 157, 11);padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;display: none;"></span><span style="color: rgb(255, 157, 11);visibility: visible;display: inline-block;border-left: 5px solid rgb(255, 157, 0);padding: 2px 13px;margin-right: 3px;height: 50%;font-size: 18px;">尾註</span><span style="font-size: 18px;color: rgb(255, 157, 11);display: inline-block;padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;"></span></h2><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">你可在，此處，找到 <strong style="color: black;">塊稀疏注意力矩陣</strong> 的原始實現。🤗 版的實現在，這兒。</p><blockquote data-tool="mdnice 編輯器" style="border-top: none;border-right: none;border-bottom: none;font-size: 0.9em;overflow: auto;color: rgb(106, 115, 125);padding: 10px 10px 10px 20px;margin-bottom: 20px;margin-top: 20px;border-left-color: rgb(255, 177, 27);background: rgb(255, 245, 227);"><p style="font-size: 16px;line-height: 26px;color: rgb(89, 89, 89);">🤗 寶子們可以戳 <strong style="color: black;">閲讀原文</strong> 查看文中所有的外部鏈接喲！</p></blockquote><hr data-tool="mdnice 編輯器" style="height: 1px;border-right: none;border-bottom: none;border-left: none;border-top-style: solid;border-top-color: rgb(249, 191, 69);margin-top: 20px;margin-bottom: 20px;"><blockquote data-tool="mdnice 編輯器" style="border-top: none;border-right: none;border-bottom: none;color: rgb(91, 91, 91);background: rgba(158, 158, 158, 0.1);padding-top: 1px;padding-bottom: 1px;padding-left: 5px;margin-top: 0px;margin-bottom: 0px;"><blockquote style="border-width: initial;border-style: none;border-color: initial;margin-top: 0px;margin-bottom: 0em;padding-top: 0px;padding-left: 0px;"><blockquote style="border-width: initial;border-style: none;border-color: initial;margin-top: 0px;margin-bottom: 0em;padding-top: 0px;padding-left: 0px;"><blockquote style="border-width: initial;border-style: none;border-color: initial;margin-top: 0px;margin-bottom: 0em;padding-top: 0px;padding-left: 0px;"><p style="color: rgb(63, 63, 63);line-height: 1.5;font-size: 14px;margin: 10px;">英文原文:&nbsp;<span style="color: rgb(136, 136, 136);letter-spacing: 0px;">https://hf.co/blog/big-bird</span></p><p style="color: rgb(63, 63, 63);line-height: 1.5;font-size: 14px;margin: 10px;">原文作者: Vasudev Gupta</p><p style="color: rgb(63, 63, 63);line-height: 1.5;font-size: 14px;margin: 10px;">譯者: Matrix Yao (姚偉峯)，英特爾深度學習工程師，工作方向為 transformer-family 模型在各模態數據上的應用及大規模模型的訓練推理。</p></blockquote></blockquote></blockquote></blockquote></section><p style="display: none;"><mp-style-type data-value="3"></mp-style-type></p></div><p style="color: #858585; font-size: 13px;">本文分享自微信公眾號 - Hugging Face（gh_504339124f0f）。<br>如有侵權，請聯繫 support@oschina.cn 刪除。<br>本文參與「<a href="https://www.oschina.net/sharing-plan" target="_blank">OSC 源創計劃</a>」，歡迎正在閲讀的你也加入，一起分享。</p></div>
                                    ]]>
            </description>
            <pubDate>Sun, 26 Nov 2023 02:08:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/HuggingFace/blog/10150964</guid>
            <link>https://my.oschina.net/HuggingFace/blog/10150964</link>
            <author>
                <![CDATA[原創]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[LibreOffice Viewer 重新上架 Google Play 商店]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><a href="https://www.oschina.net/news/268085/libreoffice-7-6-3-and-android-viewer-app">LibreOffice 7.6.3</a>&nbsp;於昨日更新，與其同時發佈的還有 Android 版 LibreOffice Viewer——已重新<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fplay.google.com%2Fstore%2Fapps%2Fdetails%3Fid%3Dorg.documentfoundation.libreoffice" target="_blank">上架至 Google Play 商店</a>。</p><p>LibreOffice Viewer 是 LibreOffice 的輕量級版本，專為 Android 智能手機和平板電腦設計，用於查看 OpenDocument 和 Microsoft Office 格式文檔。具體包括：</p><p>• 開放文檔格式（odt、ods、odp、odg）<br> • Microsoft Office 2007–365（docx、xlsx 和 pptx）<br> • Microsoft Office 97–2003（doc、xls 和 ppt）</p><p>它與適用於 Windows、macOS 和 Linux 的 LibreOffice 桌面基於相同的 LibreOffice 技術構建，因此它以完全相同的方式顯示文檔。</p><p><strong>LibreOffice Viewer&nbsp; 運行截圖</strong></p><p><img src="https://oscimg.oschina.net/oscnet/up-15b7f109e6f110504216473c4672024e086.png" referrerpolicy="no-referrer"></p><p><img src="https://oscimg.oschina.net/oscnet/up-3679fd58f40a452c8afc18ff4d22d3e811f.png" referrerpolicy="no-referrer"></p><p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.documentfoundation.org%2Fblog%2F2023%2F11%2F24%2Flibreoffice-viewer-app-for-android%2F" target="_blank">LibreOffice Viewer 此前曾上架 Google Play 商店</a>，但由於缺乏維護，於 2020 年被下架。此後，開發團隊通過 200 多項變更來改進該應用程序，提升其穩定性和可用性，支持當前的 Android 版本並更好地與系統集成。</p></div>
                                    ]]>
            </description>
            <pubDate>Sat, 25 Nov 2023 05:07:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/268087/libreoffice-viewer-app-for-android</guid>
            <link>https://www.oschina.net/news/268087/libreoffice-viewer-app-for-android</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[英偉達推遲發佈中國特供版 AI 芯片]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.reuters.com%2Ftechnology%2Fnvidia-delays-launch-new-china-focused-ai-chip-sources-2023-11-24%2F" target="_blank">根據路透社的獨家報道</a></u>，兩名知情人士透露，英偉達已通知中國客戶，<strong>其為遵守美國出口規定而設計的新款 AI 芯片將推遲到明年第一季度發佈</strong>。</p><blockquote><p>前情提要：<strong><em><u><a href="https://www.oschina.net/news/265728">英偉達或將推出針對中國區的最新改良版 AI 芯片</a></u></em></strong></p></blockquote><p>英偉達將特供三款 AI 芯片 <strong>HGX H20、L20 PCle 和 L2 PCle</strong>，它們全都由 H100 改良而來，<strong>推遲發佈的是其中最強大的 H20，有可能延遲到明年 2 月或 3 月</strong>。</p><p><img src="https://oscimg.oschina.net/oscnet/up-edecf0f4b0f979b064fa454bfd31a0ec4e3.png" referrerpolicy="no-referrer"></p><p>知情人士稱，推遲的原因被告知是服務器製造商在集成芯片上遇到問題。另外兩款芯片中 L20 不會延期， 按照原定計劃供貨，L2 情況未知。</p></div>
                                    ]]>
            </description>
            <pubDate>Sat, 25 Nov 2023 03:33:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/268075</guid>
            <link>https://www.oschina.net/news/268075</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[GNOME 拿到 100 萬歐元投資後，積極改進基礎設施]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>GNOME 基金會本月從「Sovereign Tech Fund」獲得了 <u><a href="https://www.oschina.net/news/265839/gnome-sovereign-tech-fund">100 萬歐元投資</a></u>，用於幫助 GNOME 實現平台現代化、改進工具和可訪問性，並支持符合公共利益的功能。</p><p>目前，圍繞 systemd-homed 和其他功能集成的新工作正在進行中，通過將 systemd-homed 集成到 GNOME 的 AccountService 中，用戶可以為他們的 Home 目錄創建加密卷，確保個人數據的安全性。</p><p>本週 GNOME 開發工作的部分亮點包括：</p><ol><li>通過 XDG Desktop Portal，使沙盒應用程序支持文件夾的拖放功能</li><li>改進 GNOME Shell 和合成器的性能，並集成 Tracy 分析器<br><img alt="" src="https://oscimg.oschina.net/oscnet/up-a4ae5a9624f158104c73a6cd332f2a7b75f.png" referrerpolicy="no-referrer"><p>&nbsp;</p></li><li>提升硬件加速屏幕錄製和改進 Linux 藍牙協議堆棧</li><li>正在開發 Mutter 中對 OpenGL KHR_robustness 擴展的支持，以幫助 GNOME 會話從 GPU 驅動程序崩潰中恢復</li><li>Fractal Matrix 消息應用程序在 Fractal 5 中進行了全面重寫，現在使用 GTK 4、libadwaita 和 Matrix Rust SDK。<br><img alt="" src="https://oscimg.oschina.net/oscnet/up-aa30c942344821d70d7dffa1d26d5fcf6bf.png" referrerpolicy="no-referrer"></li></ol><p>有關這些最新 GNOME 工作的更多詳細信息，請參見本週 GNOME 動態：<u><em><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fthisweek.gnome.org%2Fposts%2F2023%2F11%2Ftwig-123%2F" target="_blank">https://thisweek.gnome.org/posts/2023/11/twig-123/</a></em></u></p></div>
                                    ]]>
            </description>
            <pubDate>Sat, 25 Nov 2023 02:53:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/268167</guid>
            <link>https://www.oschina.net/news/268167</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Firefox 121 默認啓用 Wayland 支持]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>根據 Firefox 最近的提交信息，Firefox 121 計劃在現代 Linux 桌面上默認啓用 Wayland 支持，而不是回退到 XWayland。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-af58e5b492ff8f046886d946f3b112b8abc.png" referrerpolicy="no-referrer"></p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-9f1786452d74604703605a8963620fd4491.png" referrerpolicy="no-referrer"></p><p>來源：<em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fbugzilla.mozilla.org%2Fshow_bug.cgi%3Fid%3D1752398" target="_blank">https://bugzilla.mozilla.org/show_bug.cgi?id=1752398</a></u></em>、<u><em><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhg.mozilla.org%2Fmozilla-central%2Frev%2F5ea5f3e31d58" target="_blank">https://hg.mozilla.org/mozilla-central/rev/5ea5f3e31d58</a></em></u></p><p>本週發佈了 <u><a href="https://www.oschina.net/news/267557/firefox-120-0-released">Firefox 120 </a></u>穩定版，Firefox 121 現在處於測試階段 —— Wayland 支持已默認啓用，並且截至昨天的 beta 3 版本仍然開啓，有望在穩定版中保持該狀態。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-6256943e2a71993b6018e4b3e5f2199fa60.png" referrerpolicy="no-referrer"></p><p>原生 Firefox Wayland 支持可實現觸摸板和觸摸屏手勢、滑動導航、每個顯示器的 DPI 設置、更好的圖形性能等等。隨着時間的推移，Firefox Wayland 支持已經相當成熟，並且現在處於穩健狀態。用戶表示在 Firefox 121 beta 測試中，它的表現非常好。</p><p>Firefox 121 計劃於 12 月 19 日發佈，如果默認啓用 Wayland 支持，這將是一個很好的聖誕禮物。隨着 KDE Plasma 6.0 默認切換到 Wayland 會話，以及其他地方達到的 Wayland 採用里程碑，2024 年可能成為 Wayland 主導 Linux 桌面的一年。</p><hr><p>延伸閲讀</p><ul><li><a href="https://www.oschina.net/news/261201/gnome-mr-drop-x11-session">GNOME 移除對 X.Org 會話支持</a></li><li><a href="https://www.oschina.net/news/263917/linux-mint-wayland-progress">Linux Mint "Cinnamon" 開始支持 Wayland</a></li><li><a href="https://www.oschina.net/news/256249/intellij-based-ide-wayland-support">JetBrains 為基於 IntelliJ 的 IDE 提供 Wayland 支持</a></li><li><a href="https://www.oschina.net/news/241063/asahi-linux-stop-x-org">Asahi Linux 致用戶：停止使用 X.Org，Wayland 才是未來</a></li><li><a href="https://www.oschina.net/news/227050/xfce-4-20-wayland-support">Xfce 4.20 將正式支持 Wayland</a></li></ul></div>
                                    ]]>
            </description>
            <pubDate>Sat, 25 Nov 2023 01:26:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/268164/firefox-121-enable-wayland-support-by-default-on-linux</guid>
            <link>https://www.oschina.net/news/268164/firefox-121-enable-wayland-support-by-default-on-linux</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
    </channel>
</rss>
