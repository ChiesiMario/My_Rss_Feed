<?xml version="1.0" encoding="UTF-8"?>
<rss
    xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"


>
    <channel>
        <title>
            <![CDATA[開源中國-綜合資訊]]>
        </title>
        <link>https://www.oschina.net/news/industry</link>
        <atom:link href="https://rsshub.app/oschina/news/industry" rel="self" type="application/rss+xml" />
        <description>
            <![CDATA[開源中國-綜合資訊 - Made with love by RSSHub(https://github.com/DIYgod/RSSHub)]]>
        </description>
        <generator>RSSHub</generator>
        <webMaster>i@diygod.me (DIYgod)</webMaster>
        <language>zh-cn</language>
        <lastBuildDate>Tue, 21 Nov 2023 02:38:26 GMT</lastBuildDate>
        <ttl>120</ttl>
        <item>
            <title>
                <![CDATA[Zadig 推出環境睡眠，平均節省一半測試資源]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="text-align:center"><img alt="" height="386" src="https://oscimg.oschina.net/oscnet/up-27ced375dc5b1beb469bf36b2afaa8b1994.png" width="902" referrerpolicy="no-referrer"></p><p style="color:#333333; margin-left:0; margin-right:0; text-align:center"><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg4NDY0NTMyNw%3D%3D%26mid%3D2247491064%26idx%3D1%26sn%3D4bbe7bfe944feaa8b44a08e6156e04e2%26chksm%3Dcfb45158f8c3d84e40d44d2dd9228a844b9bcdeea1fe32a7b0ae41b9af982c11319a38f6675e%26token%3D481744823%26lang%3Dzh_CN%23rd" target="_blank">閲讀原文</a>&nbsp;/&nbsp;<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fkoderover%2Fzadig" target="_blank">Zadig 在 Github</a>&nbsp;/&nbsp;<a href="https://gitee.com/koderover/zadig">Zadig 在 Gitee</a></p><p style="color:#333333; margin-left:0; margin-right:0; text-align:center"><strong>推薦閲讀：</strong><a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg4NDY0NTMyNw%3D%3D%26mid%3D2247490415%26idx%3D1%26sn%3D1914c7fd25aac5d33b98663571bbb744%26chksm%3Dcfb457cff8c3ded9c02809aad88012fa802eac55222eebe70b8c637ca2c86a101045aa81e73a%26scene%3D21%23wechat_redirect" target="_blank">是時候和 Jenkins 説再見了</a>&nbsp;/&nbsp;<a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg4NDY0NTMyNw%3D%3D%26mid%3D2247490637%26idx%3D1%26sn%3D6e0498b37fb15f8b8903c4997e5611d8%26chksm%3Dcfb450edf8c3d9fb758d691081f09fd85d91dbb17534ba9c18c2300725462d3806581efbd237%26scene%3D21%23wechat_redirect" target="_blank">Zadig vs. Jenkins 詳細比對：時代的選擇與開發者之選</a>&nbsp;/&nbsp;<a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg4NDY0NTMyNw%3D%3D%26mid%3D2247489682%26idx%3D1%26sn%3Df4ac5ceb38547542061477a45d8dc86d%26chksm%3Dcfb45432f8c3dd24b727e0fb6db276b2d63b2751933e63a25b00b9d9fac2dd68efbd2cbd3863%26scene%3D21%23wechat_redirect" target="_blank">平台工程和 AI 時代的新 10 億開發者</a></p><p style="margin-left:0; margin-right:0">Zadig 起源於環境管理工具，逐漸演變成了全面的雲原生 CI/CD 平台，最終成為了綜合性的 DevOps 解決方案。社區小夥伴一致讚譽它為「中小型企業的得力助手，大型企業的利器」，它有眾多獨特優勢：</p><p style="margin-left:0; margin-right:0"><span><strong>· 現有服務接入<span style="color:#ff2968">姿勢多</span>：</strong></span>無論你的服務定義是 K8s YAML、Helm Chart 還是傳統的主機服務，Zadig 都提供了一鍵接入，實現高效統一的環境治理。</p><p style="margin-left:0; margin-right:0"><span><strong>· 運行時管理<span style="color:#ff2968">能力強</span>：</strong></span>不僅支持環境配置管理，還包括了服務的重啓、更新和配置管理功能，同時還為開發者提供了便捷的實時日誌查看和容器內調試工具。</p><p style="margin-left:0; margin-right:0"><strong><span>· 多環境管理<span style="color:#ff2968">負擔輕</span>：</span></strong>基於一份環境配置，Zadig 能夠秒級內創建多套完整的環境，一鍵複製已有環境到新環境，快速回溯到特定版本的環境，並且利用服務變量功能實現不同環境的個性化配置。</p><p style="margin-left:0; margin-right:0"><strong><span>· 環境更新<span style="color:#ff2968">效率高</span>：</span></strong>支持多服務多環境的並行更新，智能選擇空閒環境，避免資源浪費和低效堵塞。</p><p style="margin-left:0; margin-right:0"><strong><span>· 環境<span style="color:#ff2968">資源佔用少</span>：</span></strong>自測模式可快速創建僅包含部分服務的子環境，支持開發者快速開發和修改目標服務，從而顯著降低團隊協作時的多環境使用成本。</p><p style="margin-left:0; margin-right:0"><span>......</span></p><p style="margin-left:0; margin-right:0">過往社區也沉澱了大量的最佳實踐供大家參考：</p><p style="margin-left:0; margin-right:0"><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg4NDY0NTMyNw%3D%3D%26mid%3D2247486322%26idx%3D1%26sn%3Dbf80ef6f666a9f4d3baa1d1c43382004%26chksm%3Dcfb447d2f8c3cec4606c0370a2f4f885fbf51b97f1407e38a551a0128163c38dff4818cabe84%23rd" target="_blank">簡單極了：Zadig 託管項目支持上千開發者、多業務線、多環境協作</a></p><p style="margin-left:0; margin-right:0"><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg4NDY0NTMyNw%3D%3D%26mid%3D2247487967%26idx%3D1%26sn%3Dc50e4a2d2543ee5f771c139c85503abd%26chksm%3Dcfb45d7ff8c3d4690690b800f1f5640fac8d92e06465c9e99d7516960ff3d949a3d308c83ba9%23rd" target="_blank">多套環境的數據庫隔離，域名訪問，差異化配置，香！快解鎖！</a></p><p style="margin-left:0; margin-right:0"><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg4NDY0NTMyNw%3D%3D%26mid%3D2247487915%26idx%3D1%26sn%3D4719546f8f109733324124bd87c908f9%26chksm%3Dcfb45d0bf8c3d41d581db5e3d957feef9a3a121726bbf66b85eb3a82ded4a88fc98836f247da%23rd" target="_blank">寫代碼 5 分鐘，上線 2 小時？就離譜！來用用 Zadig 環境負載均衡</a></span></p><p style="margin-left:0; margin-right:0"><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg4NDY0NTMyNw%3D%3D%26mid%3D2247487124%26idx%3D1%26sn%3D062f9a269f16ff91e5e578a9f8456c15%26chksm%3Dcfb44234f8c3cb22d68b608c51327c91fcc06e2bb88d1da5d3f4e5237c9dffa1af9f668ee98e%23rd" target="_blank">在星雲科技，我們使用 Zadig 實現多環境並行發佈，上千次周部署</a></span></p><p style="margin-left:0; margin-right:0"><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg4NDY0NTMyNw%3D%3D%26mid%3D2247487033%26idx%3D1%26sn%3D645702bbe3e58b957ea960c4b231d819%26chksm%3Dcfb44299f8c3cb8fc664bb7de920eec0d3e587615b04d49cb59ed1b23fe40b83977068626f88%23rd" target="_blank">誰説 Zadig 只能複製環境？數百微服務一套環境實現高效協作</a></span></p><p style="margin-left:0px; margin-right:0px; text-align:center"><img alt="" src="https://oscimg.oschina.net/oscnet/up-c1b0440b31e72d76997ee520ad4540be287.png" referrerpolicy="no-referrer"></p><span id="OSC_h2_1"></span><h2><span style="color:#ff2968"><strong>一、降本增效：推出環境睡眠和喚醒功能</strong></span></h2><p>&nbsp;</p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify">隨着越來越多的企業深度採用 Zadig，我們關注着環境的易用性、變更效率以及維護負擔等基礎能力，同時積極努力降低環境資源成本。我們明白工程師並非 24 小時都需要使用環境，因此時刻在線的環境會導致資源浪費和企業成本增加。</p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify">在 Zadig 的新版本中，我們引入了環境睡眠/喚醒功能，使環境管理更具智能性。這一功能能夠自動縮減應用程序的大小以節省雲資源成本。環境睡眠/喚醒適用於多種場景，包括但不限於：</p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"><span><strong>1. 日常開發和測試：</strong></span><span>&nbsp;</span>工程師進行自測、聯調和集成驗收時，根據使用頻率，可以輕鬆設置環境的睡眠和喚醒，以合理利用資源。</p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"><span><strong>2. 不經常迭代的項目：</strong></span><span>&nbsp;</span>對於不經常迭代但仍提供在線服務的項目，需要保留多套完整可驗證的開發、測試和預發佈環境。通過定期設置睡眠，喚起使用時，可以及時釋放資源到公共資源池。</p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"><span><strong>3. 定時按需控制：</strong></span><span>&nbsp;</span>您可以設置環境的定時睡眠和喚醒，尤其適用於彈性節點資源。例如每天晚上自動睡眠，早上自動喚醒，或者在節假日休息時自動睡眠，工作日自動喚醒，以避免無人使用時仍然佔用資源。</p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify">這一新功能將使您能夠更智能地管理環境，更有效地利用資源，從而降低成本。</p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0px; margin-right:0px; text-align:center"><img alt="" src="https://oscimg.oschina.net/oscnet/up-059a61e53b3cb2a2033421b525584d8db96.png" referrerpolicy="no-referrer"></p><span id="OSC_h2_2"></span><h2><span style="color:#ff2968"><strong>二、關於環境使用的成本優化測算</strong></span></h2><p><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.5)">實際資源取決於應用本身的佔用及環境使用頻率，Zadig 環境睡眠主張從源頭減少浪費。</span></p><p>&nbsp;</p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify">以一個典型的微服務項目為例，該項目由 5 名前後端工程師協同，包含 10 個 Java 服務，平均資源 Request 1C2G；1 個 vue 前端服務，資源 Request 1C0.5G；項目迭代過程共包含開發環境 2 套，測試環境 1 套，預發環境 1 套。平均每個服務每人每天構建 2 次；構建時長 6 分鐘。</p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"><strong>· 正常使用資源消耗：</strong>研發階段大致需要消耗資源<span>&nbsp;</span><span style="color:#ff2968"><strong>44C82G</strong></span><span>&nbsp;</span>(前端 4C2G，後端 40C80G)。</p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"><strong>· 配置環境睡眠策略後：</strong>該項目在不同迭代頻率下，平均節約<span>&nbsp;</span><strong><span style="color:#ff2968">22C41G</span></strong><span>&nbsp;</span>約一半資源。</p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0px; margin-right:0px; text-align:center"><img alt="" src="https://oscimg.oschina.net/oscnet/up-99d72eb1139570e2b7bf667fd8ddd2d855b.png" referrerpolicy="no-referrer"><img alt="" src="https://oscimg.oschina.net/oscnet/up-8452cd8960943c012f669980244501130a7.png" referrerpolicy="no-referrer"></p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0px; margin-right:0px; text-align:center"><img height="1278" src="https://oscimg.oschina.net/oscnet/up-54779359f43a9840cdac2ba5ac23b7e5af5.png" width="2346" referrerpolicy="no-referrer"></p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0px; margin-right:0px"><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)">下面將展開介紹如何配置環境睡眠及效果的展示。</span></p><span id="OSC_h3_3"></span><h3><span style="color:#ff2968">01-</span><span style="color:#ff2968">如何啓用環境睡眠能力</span></h3><p>&nbsp;</p><p style="color:#ff7faa; margin-left:0; margin-right:0; text-align:justify"><span style="color:rgba(0, 0, 0, 0.5)">前提條件：安裝 Zadig v1.7.0 版本，系統中存在正在使用的環境。</span></p><p style="color:#ff7faa; margin-left:0; margin-right:0; text-align:justify"><span><strong>•<span>&nbsp;</span></strong></span>安裝 Zadig v2.0.0</p><p style="color:#ff7faa; margin-left:0; margin-right:0; text-align:justify"><span><strong>•<span>&nbsp;</span></strong></span>Zadig 環境管理</p><span id="OSC_h3_4"></span><h3><span style="color:#ff2968">02-配置一鍵睡眠/喚醒</span></h3><p><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)">進入環境，點擊睡眠與喚醒 -&gt; 立即睡眠即可將環境一鍵睡眠。</span></p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-a23a8cfb642b3eec757e317f8bf162ebd9d.png" referrerpolicy="no-referrer"><img alt="" src="https://oscimg.oschina.net/oscnet/up-c9dfbdcb488595269fcafbfe331e1bc7e44.png" referrerpolicy="no-referrer"></p><p><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)">需要使用環境時，進入睡眠的環境，點擊睡眠與喚醒 -&gt; 立即喚醒即可將環境喚醒恢復可用。</span></p><p><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"><img alt="" src="https://oscimg.oschina.net/oscnet/up-2ebf5b3eb9aca3d21beba63bb63497d7e17.png" referrerpolicy="no-referrer"></span></p><span id="OSC_h3_5"></span><h3><span style="color:#ff2968">03-配置定時睡眠/喚醒</span></h3><p><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)">進入環境，點擊睡眠與喚醒 -&gt; 配置定時睡眠和喚醒 Cron 表達式即可。比如，下圖示例中每天 22:00 定時睡眠環境，每天 8:00 環境將定時喚醒恢復可用。</span></p><p><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"><img alt="" src="https://oscimg.oschina.net/oscnet/up-db2e0c10ffc9d063b4a59de5fe8a9d09b0c.png" referrerpolicy="no-referrer"><img alt="" src="https://oscimg.oschina.net/oscnet/up-4f4226bd32cc075241b7d87451ab3fb23be.png" referrerpolicy="no-referrer"></span></p><span id="OSC_h3_6"></span><h3><span style="color:#ff2968">04-使用效果一覽</span></h3><p><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)">睡眠後，環境中所有服務實例副本數將會自動調整為 0，CronJob 會被掛起，節省環境所使用雲資源成本。</span></p><p><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"><img alt="" src="https://oscimg.oschina.net/oscnet/up-45cb0a823997e3471d8dfe59e755369a6aa.png" referrerpolicy="no-referrer"></span></p><p>&nbsp;</p><p style="margin-left:0; margin-right:0">喚醒後，環境中的所有服務會根據服務編排順序恢復到睡眠之前的狀態。</p><p style="margin-left:0; margin-right:0"><img alt="" src="https://oscimg.oschina.net/oscnet/up-d899a41dcd4f828dbfc32a19cfa534dd94c.png" referrerpolicy="no-referrer"></p><p style="margin-left:0; margin-right:0">&nbsp;</p><span id="OSC_h4_7"></span><h4><strong>參考資料</strong></h4><p style="margin-left:0; margin-right:0; text-align:left"><span>[1] 安裝 Zadig v2.0.0</span></p><p style="margin-left:0; margin-right:0; text-align:left">https://docs.koderover.com/zadig/Zadig%20v2.0.0/stable/quick-install</p><p style="margin-left:0; margin-right:0; text-align:left"><span>[2] Zadig 環境管理</span>https://docs.koderover.com/zadig/Zadig%20v2.0.0/project/env/k8s</p><p style="margin-left:0px; margin-right:0px; text-align:center"><img alt="" src="https://oscimg.oschina.net/oscnet/up-187186c2b990f912cf841796017d7e8ce6f.png" referrerpolicy="no-referrer"></p><p style="color:#333333; margin-left:0px; margin-right:0px"><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg4NDY0NTMyNw%3D%3D%26mid%3D2247491064%26idx%3D1%26sn%3D4bbe7bfe944feaa8b44a08e6156e04e2%26chksm%3Dcfb45158f8c3d84e40d44d2dd9228a844b9bcdeea1fe32a7b0ae41b9af982c11319a38f6675e%26token%3D481744823%26lang%3Dzh_CN%23rd" target="_blank">閲讀原文</a>&nbsp;/&nbsp;<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fkoderover%2Fzadig" target="_blank">Zadig 在 Github</a>&nbsp;/&nbsp;<a href="https://gitee.com/koderover/zadig">Zadig 在 Gitee</a></p><p style="color:#333333; margin-left:0px; margin-right:0px"><strong>推薦閲讀：</strong><a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg4NDY0NTMyNw%3D%3D%26mid%3D2247490415%26idx%3D1%26sn%3D1914c7fd25aac5d33b98663571bbb744%26chksm%3Dcfb457cff8c3ded9c02809aad88012fa802eac55222eebe70b8c637ca2c86a101045aa81e73a%26scene%3D21%23wechat_redirect" target="_blank">是時候和 Jenkins 説再見了</a>&nbsp;/&nbsp;<a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg4NDY0NTMyNw%3D%3D%26mid%3D2247490637%26idx%3D1%26sn%3D6e0498b37fb15f8b8903c4997e5611d8%26chksm%3Dcfb450edf8c3d9fb758d691081f09fd85d91dbb17534ba9c18c2300725462d3806581efbd237%26scene%3D21%23wechat_redirect" target="_blank">Zadig vs. Jenkins 詳細比對：時代的選擇與開發者之選</a>&nbsp;/&nbsp;<a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg4NDY0NTMyNw%3D%3D%26mid%3D2247489682%26idx%3D1%26sn%3Df4ac5ceb38547542061477a45d8dc86d%26chksm%3Dcfb45432f8c3dd24b727e0fb6db276b2d63b2751933e63a25b00b9d9fac2dd68efbd2cbd3863%26scene%3D21%23wechat_redirect" target="_blank">平台工程和 AI 時代的新 10 億開發者</a></p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 21 Nov 2023 02:34:22 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/koderover/blog/10149325</guid>
            <link>https://my.oschina.net/koderover/blog/10149325</link>
            <author>
                <![CDATA[原創]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[OpenAI 超 700 名員工簽署聯名信，要求董事會集體辭職]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>據紐約時報等媒體統計數據，目前 OpenAI 至少有 743 名員工已簽署聯名信逼迫董事會集體辭職，同時恢復 Sam Altman 和 Greg Brockman 在董事會的職位。<strong>否則所有簽名者集體跳槽微軟</strong>，而且這一人數正在持續增加中（昨晚還只有&nbsp;500 人左右）。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-3b5ce54499e3d9390d7173b0cacee47dfbc.png" referrerpolicy="no-referrer"></p><p>出乎意料的是，被認為是 OpenAI&nbsp;此次「政變」組織者的首席科學家 Ilya Sutskever 也簽署了這一聯名信。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-08e0a2b4d71953d511d7c02b0bc333b91bf.png" referrerpolicy="no-referrer"></p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-65a525945aa136b1379d133093172eaa368.png" referrerpolicy="no-referrer"></p><p>同時，多位消息人士告訴 The Verge，<strong>如果解僱他的其餘董事會成員下台，Sam Altman&nbsp;和聯合創始人&nbsp;Greg Brockman&nbsp;仍然願意重返 OpenAI。</strong></p><p>公開資料顯示&nbsp;OpenAI 員工人數為 770 名，這批「逼宮」的人佔據了員工總數超 96% 之多。</p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 21 Nov 2023 02:18:22 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/267364</guid>
            <link>https://www.oschina.net/news/267364</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[修完這個 Bug 後，MySQL 性能提升了 300%]]>
            </title>
            <description>
                <![CDATA[這個 bug 是由 Mark Callaghan 發現的。Mark 早年在 Google MySQL 團隊，後來去了 Meta MySQL，也主導了 RocksDB 的開發。]]>
            </description>
            <pubDate>Tue, 21 Nov 2023 02:09:22 GMT</pubDate>
            <guid isPermaLink="false">修完這個 Bug 後，MySQL 性能提升了 300%</guid>
            <link></link>
        </item>
        <item>
            <title>
                <![CDATA[目標導向主義失效了？前 OpenAI 科學家現身説法]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div>
  「目標感很強」常常被我們用來誇讚一個職場人，並被當作是成功的一大原因。然而，兩位前 OpenAI 科學家——Kenneth Stanley、Joel Lehman 在多年的 AI 研究中發現，目標導向論對於成就偉大的事情並無助益，反而抱着探索的心態去嘗試做有趣的事情更能帶來意想不到的成果。 
</div><div>
  &nbsp; 
</div><div>
  尤其是在人工智能的算法研究中，比如讓機器人通過一條走廊，最終從走廊盡頭的大門中出去。最終實驗證明，在不設定「出門」目標的情況，機器人可以純粹嘗試一些與以往不同的事情，反而最終能找到出門的方法。類似原理的還有 Kenneth Stanley 曾參與的圖片繁育網站的工作，在這個圖片繁育網站上，用戶可以從一個簡單的圓點圖形，疊加其他圖形圖片，最終生成出類似汽車、動物等「有用」的圖片，但如果用戶開局就抱着」我要生成一張汽車圖片「的目標，反而很難成功。 
</div><div>
  &nbsp; 
</div><div>
  由於認知理念上的轉變，在 ChatGPT 發佈前幾個月，Kenneth 離開 OpenAI 去創業，研究新產品——開放式、偶然性社交網絡 Maven，Joel 離開後到了 Stability，領導 Carper 開放性研究團隊，同時他也在研究機器之愛。Kenneth 和 Joel 也合作創作了一本書《為什麼偉大無法被計劃》，書中認為，許多時候，哪怕我們的探索漫無目的，在前方位置的道路上依然埋藏着無數寶藏。從「目標」中解放出來，或許能成為發現意外之喜的「尋寶者」。 
</div><div>
  &nbsp; 
</div><div>
  「 
 <strong>在我看來，研究工作最重要、最實用的方面之一是開發對於可能性的直覺。」</strong>&nbsp;正如 Joel 現在去研究機器之愛的歷程，在接觸心理學之後，他將對心理學和機器學習的興趣結合起來，找到了更加熱愛的事情，「 
 <strong>我們的生活沒有統一的目標，我們的興趣和心理發展往往是偶然進行的——於是，一個新的研究方向為我打開了。」</strong>在他看來，在機器時代，我們越來越需要人類代理的提醒，技術的目的是為人類的利益服務，而人類是構建和設計這項技術的人。 
</div><div>
  &nbsp; 
</div><div>
  同樣，對於人工智能的看法，Ken 也從人文的角度給出觀點：「一種哲學見解認為，好的人工智能實驗不僅應該帶來強大的系統，還應該帶來對我們人類自身的洞察。畢竟，對智能的任何偉大洞察實際上都是對人類的洞察，因為智能是我們的決定性特徵。」 
</div><div>
  &nbsp; 
</div><div>
  Kenneth 和 Joel 提出的哲學態度與常規認知相反，或許能給我們在這個混亂時刻一些新的啓示，因此，OSCHINA 特別邀請 Kenneth 和 Joel 聊了聊他們理念、觀點和故事。 
</div><div>
  &nbsp; 
</div><p><span style="color:#2ea121"><strong>OSCHINA：Ken 可以詳細介紹下偶然性社交網絡 Maver 的玩法、原理、以及目前的成長狀態嗎？</strong></span></p><div><span style="color:#245bdb"><strong>ken：</strong></span></div><div>
  Maven 是一種新奇的社交網絡，我創辦了一家新公司來開發它。它基於我們《為什麼偉大不能被計劃》一書中的原則，專注於將人們與個性化的偶然發現聯繫起來，而不是增強病毒式傳播。我們從 2023 年開始開發它，所以它還很新。 
</div><div><img height="373" src="https://oscimg.oschina.net/oscnet/up-ea180ad51144df638c6a6b631f4e68e7054.jpg" width="700" referrerpolicy="no-referrer"></div><div><span style="background-color:#ffffff; color:#888888">Kenneth Stanley</span></div><div>
  &nbsp; 
</div><p><span style="color:#2ea121"><strong>OSCHINA：Stability 現在在全球市場也備受關注，但很多人都不太瞭解開放性研究，能否請 Joel 介紹下正在做的開放性研究是指什麼？</strong></span></p><div><span style="color:#245bdb"><strong>Joel：</strong></span></div><div>
  創建生成式 AI 大模型的公司之間的一個主要理念分歧是專有模型與開源模型。 
</div><div>
  &nbsp; 
</div><div>
  例如，現在 OpenAI 和 Anthropic 沒有公開他們最大的模型，以便其他人可以修改或在其基礎上構建 (尤其是對他們來説有商業價值的模型)，而是隻提供一個 API，用戶可以在有限範圍內使用模型。支持這種模式的理由通常是：如果大模型被濫用可能造成危險，而 API 可以實現更好的監控，並且訓練大模型成本很高，公司需要一種賺錢的方法。 
</div><div>
  &nbsp; 
</div><div>
  相比之下，由 Stability 和 HuggingFace 等公司採用開源的方式訓練模型、發佈代碼和模型 (通常比閉源模型的模型小)，這樣其他公司和研究人員可以直接在其基礎上進行構建，並根據自己的目的靈活調整。這些公司通常不太關心模型被濫用的危險，而是更關心創建一個蓬勃發展的研究和模型生態系統。但由於他們免費發佈模型，其他人現在可以運行他們的模型，而無需向訓練模型的公司付費，因此他們需要一種不同的商業模式來保持財務上的可行性。 
</div><div>
  &nbsp; 
</div><div>
  這兩種理念都有蓬勃發展的空間，儘管未來存在關鍵的不確定性。例如，如果開源模型在未來變得非常強大，並且不良行為者最終利用這些模型造成了社會問題，則可能會產生負面影響。反之，如果專有大模型的 API 對於大多數希望使用生成式 AI 的公司來説限制過多或是成本過高，也許也導致更多人選擇開源路徑。 
</div><div>
  &nbsp; 
</div><div>
  當然，隨着開源運動模式與方法的日益多樣化，開源似乎更符合 Ken 和我的書中所傳遞的理念。我可以想象，許多有趣的發現將由此產生。但我擔心，如何在開源社羣中加入安全約束和規範引入，使得這些模型在造福社會的同時，也能儘量避免可能的負面影響？以及如何在鼓勵這些規範和約束的同時不必放慢創新速度？這是一個有趣而微妙的問題。 
</div><div><img height="592" src="https://oscimg.oschina.net/oscnet/up-f738a9b408fbacdee21e45d537991e8c562.png" width="700" referrerpolicy="no-referrer"></div><div><span style="background-color:#ffffff; color:#888888">Joel Lehman</span></div><span id="OSC_h3_1"></span><h3>從「繁育」到「提示」，我們該如何對話機器</h3><p><span style="color:#2ea121"><strong>OSCHINA：當年「繁育圖片」的孵化器網站後面的故事是怎樣的？是否還在運行？</strong></span></p><div><span style="color:#245bdb"><strong>ken：</strong></span></div><div>
  你指的是 Picbreeder。它是在我在中佛羅裏達大學 (University of Central Florida) 的實驗室開發的 (該實驗室名為 EPlex-Evolutionary Complexity Research Group)。Jimmy Secretan(當時是一名博士生) 領導了這項工作。這是一個允許互聯網用戶培育圖像的網站，就像你培育狗或馬一樣。更深層次地説，其實這是一次開放性實驗。它使我們能夠觀察到在人工環境中發生的大規模開放式搜索過程 (讓人聯想到自然進化)。看到這一過程的展開，我們得到了許多深刻的教訓，其中包括新奇性搜索算法背後的理念，以及《為什麼偉大無法被計劃》一書中的見解。 
</div><div>
  &nbsp; 
</div><p><span style="color:#2ea121"><strong>OSCHINA：「繁育」原理和現在火爆的「輸入 prompt 生成圖片」這類網站可以做比較嗎，二者背後的運行原理有什麼相似得地方，有什麼不同的地方？</strong></span></p><div><span style="color:#245bdb"><strong>ken：</strong></span></div><div>
  它們都是生成藝術的一種形式，但工作方式截然不同。基於提示的現代圖像生成技術之所以有效，是因為生成圖像的模型已經過數百萬或數十億個示例圖像的訓練。所以當它生成圖像時汲取了豐富的經驗。在協議中，Picbreeder 沒有任何訓練數據，用戶只是簡單地開始隨機繁育圓點，經過幾代的繁育，就能產生進化，產生更多我們更熟悉的圖像，比如如汽車和蝴蝶。一個一開始並不明顯的巨大差異是，繁育遠沒有那麼密集：像 Picbreeder 頭骨這樣的繁育圖像只需要幾十次迭代搜索，而現代圖像模型已經經過數百萬或數十億次迭代進行優化。 
</div><div>
  &nbsp; 
</div><div><span style="color:#245bdb"><strong>Joel：</strong></span></div><div>
  抽象地説，繁育原理是指人們以發散和協作的方式探索思想空間，是取得新發現和有用發現的關鍵。「輸入提示生成圖片」的方法，在某種意義上與繁育原則是正交關係，因為你可以發散地與他人寫作探索提示空間，也可以自己探索。 
</div><div>
  &nbsp; 
</div><div>
  換句話説，許多人確實分享了他們的提示技巧，展示如何讓模型生成圖像獲得有趣成果。例如，在一些模型中，添加「Trending on Artstation」這一文本將有助於提高質量。所以，人們越能看到他人制作的圖片和提示，就越能從圖片和他人的提示中得到啓發，製作自己的圖像，從而更全面地用擁抱繁育原則。 
</div><div>
  &nbsp; 
</div><p><span style="color:#2ea121"><strong>OSCHINA：Prompt 背後的原理，是更接近目標函數原理，還是無目標探索</strong></span><span style="color:#2ea121"><strong>系統理論</strong></span><span style="color:#2ea121"><strong>？如何解釋？</strong></span></p><div><span style="color:#245bdb"><strong>Ken：</strong></span></div><div>
  因為 prompt 可以傳達任何想法，所以它可以用來表達客觀或非客觀的過程。大多數人可能會客觀地使用它們，因為這是我們大多數人被教導的思考方式，但仍然有可能有人非客觀地使用它們。例如，如果我讓它為我解決一個問題，這是一個客觀使用。但如果我讓它想給出一些有趣的東西，那就更接近於非客觀。然而，重要的是要注意，你可以向 LLM 表達一個非客觀的概念並不意味着它能表現得很好，或像人類一樣。我認為現在的 LLM 通常無法很好地獨立實現非客觀的表達。 
</div><div>
  &nbsp; 
</div><div><span style="color:#245bdb"><strong>Joel：</strong></span></div><div>
  Prompt 原則既可以兼容目標函數原則，又可以兼容探索系統理論。有時，人們會 prompt 進行大量優化，試圖在特定任務中獲得最佳性能。還有一些時候，人們以一種更不定向的方式利用 prompt 進行探索，以找到不同尋常的有趣方法來產生新的輸出——探索特定語言模型或圖像生成模型的邊界。 
</div><div>
  &nbsp; 
</div><div>
  以「思維鏈」提示的驚人發現為例，只需要給模型舉幾個例子，説明如何推理一個問題，最終就能幫助模型更好地完成任務 (即告訴模型「一步步思考」)。模型本身有意想不到的優勢，需要研究人員去發現，而發現方法往往是遵循他們的直覺，並以其他人發現和其他共享出來的 prompt 為基礎。 
</div><div>
  &nbsp; 
</div><p><span style="color:#2ea121"><strong>OSCHINA：現在很多培訓教學，教大家如何使用 Prompt，如果遵循用無目標探索</strong></span><span style="color:#2ea121"><strong>系統理論</strong></span><span style="color:#2ea121"><strong>，採用尋寶原則，我們該如何學習使用 prompt 和機器對話？</strong></span></p><div><span style="color:#245bdb"><strong>Ken：</strong></span></div><div>
  我認為以這種方式探索 prompt 是一個好主意。當你和 LLM 交談時，嘗試去做一些沒有目標的事情，看看當你嘗試一些有趣的事情時會發生什麼。當你發現它以一種有趣的方式響應時，請進一步探索這條路徑。這種方法可能會帶來對模型的更深入的理解，而不是簡單地嘗試實現特定的目標。就像對待一個人一樣，與系統一起探索，以更好地瞭解它是很有價值的。 
</div><div>
  &nbsp; 
</div><div><span style="color:#245bdb"><strong>Joel：</strong></span></div><div>
  一個原則是花一些時間玩這個系統，做你認為有趣的探索。也許你想看看模型有多善於諷刺，或者扮演你最喜歡的名人。你可以通過修改 prompt，或者嘗試他人創建的 prompt 來開發直覺。你可以對意外發現持開放態度，注意到模型以一種本身有趣的方式作出響應——也許你試圖讓語言模型進行諷刺，但它卻以巧妙的雙關語做出了反應。那麼，也許你可以探索它擅長哪種雙關語，以及它何時會犯奇怪的錯誤。很有可能，當你嘗試將模型應用到實際事物中時，你在親手操作模型的過程中形成的直覺最終會對你有用，或者你可能會發現一種新的提示方法，或者至少你可能會在學習提示的過程中獲得樂趣。 
</div><div>
  &nbsp; 
</div><span id="OSC_h3_2"></span><h3>哲學與技術，開發對於可能性的直覺</h3><p><span style="color:#2ea121"><strong>OSCHINA：在開發者羣體中，roadmap、里程碑文化非常盛行，這是典型的目標導向。事實上，我們能看到很多知名軟件都早已偏離最初的預設目標，但很多時候，時候軟件標準、里程碑也能很好地指引開發團隊做事。這個現象可以怎麼理解？對於開發者該如何選擇自己的「開發哲學」，你們有什麼建議？</strong></span></p><div><span style="color:#245bdb"><strong>Ken：</strong></span></div><div>
  目標並不總是壞的。當通往目標的路徑是已知的，設定目標就會有成效。在軟件開發中，完成項目的步驟通常是已知的，所以遵循目標是有意義的。然而，如果項目的目標是創新、發現或創造力，那麼目標就有問題了。這樣的項目可能會被目標扼殺，最終只做了很少有創造性的事情。 
</div><div>
  &nbsp; 
</div><div><span style="color:#245bdb"><strong>Joel：</strong></span></div><div>
  首先我要説明的是，我在大型軟件工程方面沒有太多的個人經驗。但一般來説，里程碑和標準可能非常適合在已知如何做的範圍內進行的工作。距離成功可能只是一步之遙，不需要廣泛探索。將軟件從版本 1 升級到版本 1.1，修復一些現有的 bug 或添加一些有限的功能，可能是非常適合目標的思維的地方。但是從更長遠的角度來看，如果目標是完全重新構想一個軟件，或者創建一個軟件來實現其他軟件從未實現過的功能，那麼就需要更多的探索和墊腳石思維。 
</div><div>
  &nbsp; 
</div><div>
  有時，墊腳石現象發生在更高的層面上。例如，當一個團隊開發併發佈一個開源庫時，一個對他們的目的有用的庫，一個構建在以前存在的庫上的庫，並且將使其他人能夠創建他們自己的新庫——這就是在玩尋寶遊戲。因此，開發人員的哲學中，與尋寶有關的方式是，瞭解目前有哪些軟件墊腳石，這些墊腳石可能使哪些以前沒有的東西成為可能，並向世界推出新的軟件，讓別人能夠以你無法預料的方式去使用的新軟件。 
</div><div>
  &nbsp; 
</div><p><span style="color:#2ea121"><strong>OSCHINA：哲學思想可以如何作用於 IT 領域的研究，可以結合實際的事情來聊一聊嗎？</strong></span></p><div><span style="color:#245bdb"><strong>Ken：</strong></span></div><div>
  我不確定這裏指的是一般哲學還是這本書的哲學。當然，這本書的哲學也可以應用於其中。因為它只是贊同有時走一些有趣的路，即使你不知道它們通向何方。這在信息技術領域是絕對可行的。 關於一般哲學能否應用於 IT 的問題，我認為是可以的。 我認為哲學是對世界可能存在的方式的研究（與研究世界存在方式的科學相對）。 
 <strong>對「可能是什麼 」的理解可以幫助你在做出選擇之前看到眼前的各種可能性。</strong></div><div>
  &nbsp; 
</div><div><span style="color:#245bdb"><strong>Joel：</strong></span></div><div>
  這很有趣——有些人把哲學和實用性對立起來。我能理解這種觀點，因為我們接觸到的哲學往往是抽象的、象牙塔式的。但在我看來，最重要的哲學是非常實用的。在進行包括 IT 在內的任何領域研究時，掌握一些關於如何進行發現的哲學是非常重要的。你可以通過自己的經驗和觀察發展出自己的個人哲學，但我們這本書的一個貢獻就是強調了雄心勃勃的發現通常是如何發生的。 
</div><div>
  &nbsp; 
</div><div><strong>在我看來，研究工作最重要、最實用的方面之一是開發對於可能性的直覺。</strong>我的意思是，去理解什麼樣的事情是容易完成的，哪些事情是在可能性的邊緣，哪些事情你不清楚你是否能夠解決它們。當一個人剛進入一個領域時，當涉及到可能性時，他們的直覺通常會很差。但是，當你對可能性的直覺很好 (你大致知道一個問題有多難)，並且你的探索哲學也很合理 (如果一個問題很容易，就可以直接攻克；如果一個問題非常困難，可能無法解決，或者至少需要大量耐心的發散性探索)，那麼你成功的機會就會大得多。 
</div><div>
  &nbsp; 
</div><p><span style="color:#2ea121"><strong>OSCHINA：無目標，新奇性搜索等哲學思想對你們的日常生活產生了哪些影響？</strong></span></p><div><span style="color:#245bdb"><strong>Ken：</strong></span></div><div>
  這對我的日常生活很有幫助，因為我對僅僅因為有趣而去做某事的疑慮減少了。我知道它可能會成為一個有趣的墊腳石，即使我還不知道它最終將如何有用。我還把它來對待我的孩子。例如，我 9 歲的兒子有時會選擇一些沒有明顯好處的事情，但我鼓勵他去做，因為我看到他對這些項目很感興趣，所以我相信這些項目可以引導他發現自我。 
</div><div>
  &nbsp; 
</div><div><span style="color:#245bdb"><strong>Joel：</strong></span></div><div>
  寫這本書，以及多年來對新奇性搜索的研究，這種理念不可避免地滲透到一個人的生活中。我比大多數人更樂於改變職業方向 (我目前正處於改變職業方向的過程中)，我努力保持求知慾，樂於看到意想不到的新機會，並努力在生活的不同方面之間找到廣泛的聯繫。 
</div><div>
  &nbsp; 
</div><p><span style="color:#2ea121"><strong>OSCHINA：多年前你們因為圖片產品的啓示，開始研究「無目標」相關的哲學，這些年有沒有一些實踐體驗帶來新的哲學感悟？</strong></span></p><div><span style="color:#245bdb"><strong>Ken：</strong></span><strong>一種哲學見解認為，好的人工智能實驗不僅應該帶來強大的系統，還應該帶來對我們人類自身的洞察。畢竟，對智能的任何偉大洞察實際上都是對人類的洞察，因為智能是我們的決定性特徵。</strong></div><div>
  &nbsp; 
</div><div><span style="color:#245bdb"><strong>Joel：</strong></span></div><div>
  這些年來，我有很多頓悟的時刻，事情以一種意想不到的方式突然發生。這些經歷往往發生在閲讀與我正在研究的課題有着抽象聯繫的有趣內容時，一種新的聯繫突然出現，或者當我的兩個看似獨立的興趣突然聯繫在一起時，就達到更深層次的統一。 
</div><div>
  例如，我最近關於「機器之愛」的研究就是將我對心理學和機器學習的興趣結合在一起。起初，這些興趣似乎是完全分開的。但後來，隨着我不斷深入研究心理學， 
 <strong>我開始意識到，人類個體的生活在某種程度上是開放式的，就像生物進化一樣——我們的生活沒有統一的目標，我們的興趣和心理發展往往是偶然進行的——於是，一個新的研究方向為我打開了。 </strong></div><div>
  &nbsp; 
</div><span id="OSC_h3_3"></span><h3><strong>ChatGPT</strong><strong>：或許是目標與非目標導向的產物</strong></h3><p><span style="color:#2ea121"><strong>OSCHINA：當下火熱的 </strong></span><span style="color:#2ea121"><strong>ChatGPT</strong></span><span style="color:#2ea121"><strong>，或者其他</strong></span><span style="color:#2ea121"><strong>人機互動</strong></span><span style="color:#2ea121"><strong>問答產品，其背後的搜索符合新奇性搜索原則嗎？</strong></span></p><div><span style="color:#245bdb"><strong>Ken：</strong></span></div><div>
  這取決於這裏所説的「搜索」是什麼意思。假設是研究人員，確實有一個搜索的組成部分反映了新奇性搜索的各個方面，即使它不是明確的新奇性搜索算法。尤其是，沒有人知道 ChatGPT 會成為一個世界性的現象——相反，他們決定研究它，是因為它既有趣又新奇。 
</div><div>
  &nbsp; 
</div><div><span style="color:#245bdb"><strong>Joel：</strong></span></div><div>
  如果我們回顧一下 OpenAI 的研究歷程，就會發現 ChatGPT 並不是該公司的長期目標。他們一開始就做了很多不同類型的研究，與 ChatGPT 似乎沒有什麼聯繫 (例如，機器人實驗，以及教 AI 玩電子遊戲的實驗)。因此，創建一個功能非常強大的問答系統的道路是出乎意料的，沒有計劃，它取決於並建立在許多其他人鋪設的墊腳石的上。 
</div><div>
  &nbsp; 
</div><p><span style="color:#2ea121"><strong>OSCHINA：</strong></span><span style="color:#2ea121"><strong>OpenAI</strong></span><span style="color:#2ea121"><strong> 或者 </strong></span><span style="color:#2ea121"><strong>ChatGPT</strong></span><span style="color:#2ea121"><strong> 可以稱得上是一項偉大的實驗 OpenAI 現在在做的事情是符合「目標導向」還是「自由探索」路徑？如何解釋？</strong></span></p><div><span style="color:#245bdb"><strong>Ken：</strong></span></div><div>
  因為我已經不在 OpenAI 工作了，所以很難説他們現在正在遵循什麼樣的流程。但我想説的是，這很可能是一個混合體，既要努力優化以獲得更好的性能（這是以目標為導向的），又要嘗試其他有趣的想法（這是以新奇為導向的）。這種混合反映出，他們既需要改進現有的東西，也需要尋找下一個新事物。 
</div><div>
  &nbsp; 
</div><div><span style="color:#245bdb"><strong>Joel：</strong></span></div><div>
  我不代表 OpenAI 發言，也不太瞭解他們目前的計劃 (我一年前離開那裏)。但我認為這兩者兼而有之——既有「自由探索」，也有「目標導向」。這家公司已經不像剛成立時那樣進行純粹的原始探索，但他們仍在繼續做許多有趣的研究。 
</div><div>
  &nbsp; 
</div><span id="OSC_h3_4"></span><h3>關於探索嘗試、關於機器之愛</h3><p><span style="color:#2ea121"><strong>OSCHINA：你們提到一句話：「如果你想在有遠見的人身上投資，就看看那些在附近的不確定性領域中徘徊和探索的人。」這句話裏「附近的不確定性領域」是容易被發現的嗎？</strong></span></p><div><span style="color:#245bdb"><strong>Ken：</strong></span></div><div>
  不，我覺得這不容易發現。這就是為什麼發現這些變革性機會的人如此罕見。我們經常假設世界運行的方式，這讓我們對仍然存在的問題視而不見。然而，一旦有人指出了其中的一點，那麼其他人就很容易看到了。但首先看到它就是一件不平凡的事情。 
</div><div>
  &nbsp; 
</div><div><span style="color:#245bdb"><strong>Joel：</strong></span></div><div>
  一開始不容易發現，但這是一種可以培養的技能。這是一種識別當前存在哪些墊腳石以及這些墊腳石可能帶來什麼的技能。通過一些專業領域知識，更容易識別「鄰近的不確定性區域」。例如，我對量子物理知之甚少，我很難理解什麼是已知的，什麼是未知的，或者當前的墊腳石是什麼樣的。但在我工作多年的人工智能領域，我確實對該領域中有趣的不確定性有豐富的直覺。 
</div><div>
  &nbsp; 
</div><p><span style="color:#2ea121"><strong>OSCHINA：現在的 </strong></span><span style="color:#2ea121"><strong>AI</strong></span><span style="color:#2ea121"><strong> 世界，有哪些很酷的嘗試？</strong></span></p><div><span style="color:#245bdb"><strong>Ken：</strong></span></div><div>
  我認為計算機輔助創作很有趣，多模態 (如文本與圖像) 以及新型音樂的可能性也很有趣。比這些更酷的是幻覺的解決方案或產生真正開創性想法的能力。然而，據我所知，這些問題的解決方案還不存在。 
</div><div>
  &nbsp; 
</div><div><span style="color:#245bdb"><strong>Joel：</strong></span></div><div>
  一個很酷的現象是，大模型正在重塑、重新想象舊算法。例如，一個大語言模型可以通過指令來創建一個計算機程序或一段文本的新變體，這將不僅僅是隨機變體，而是智能變體——因為大模型是在大量計算機程序和文本中訓練出來的。因此，你可以使用語言模型作為智能變化的引擎，從而使新型進化算法成為可能。通常，進化算法使用隨機變化——但使用語言模型的進化算法更接近人類發明新想法的方式，即對其進行智能的探索性修改。 
</div><div>
  &nbsp; 
</div><div>
  這只是大模型如何重新發明算法的一個例子，但總的來説，它們是有趣的新工具——令人興奮的新跳板——併為構建以前不可能構建的東西開闢了許多新的有趣的可能性。 
</div><div>
  &nbsp; 
</div><p><span style="color:#2ea121"><strong>OSCHINA：機器之愛真的能實現嗎？個性化推薦、信息繭房、偏見、制度、思想、等等各種有形或事無形的阻礙充斥在各個地方，目之所及似乎都是困難。如果把「美好的人與機器的世界」做為目標，我們大概率會踩到錯誤的墊腳石上。如果用「尋寶原則」做導向，放任當下的機器研究自由發展，會不會使得情況更為糟糕？而現在要做的事情又是什麼呢？</strong></span></p><div><span style="color:#245bdb"><strong>Joel：</strong></span></div><div>
  我相信，機器之愛的某些方面是可以實現的——這似乎是一個簡單的事實，語言模型確實可以使機器開始處理定性和心理方面的工作，這可以讓我們設計出關係自身成長和發展的算法，而這正是機器之愛的核心理念。在我看來，這是一塊值得關注的有趣墊腳石，儘管目前還不清楚它會通向哪裏——我們有理由懷疑，機器之愛的完整願景是否會實現，它想要改變我們的世界確實還有很多障礙。但它可能會帶來其他的墊腳石，以及應對這些障礙的方法——我們還不知道。 
</div><div>
  &nbsp; 
</div><div><strong>除了「機器之愛」（這只是改善機器對我們的影響的一個想法）之外，我們應該大膽地探索機器如何幫助我們人類過上更好的生活的許多不同願景，也許這些願景中的一個可以實現。我們永遠不可能完全知道一塊墊腳石會把我們帶到哪裏，但我們會盡最大努力，在不確定性和希望解決世界難題之間取得平衡。</strong></div><div>
  &nbsp; 
</div><div>
  我堅信， 
 <strong>在開發新技術時，尋寶原則不是我們應該遵循的唯一原則，讓當前的機器學習不受阻礙地發展，可能會給社會帶來許多負面的外部影響。</strong>一種觀點認為，對社會安全的搜索也是一個開放式的搜索過程，就像對更強大的技術 (如大模型) 的探索一樣。在尋找安全的過程中，就像在尋找技術一樣，墊腳石的結構是不明確的，因此我們需要廣泛而好奇地探索可能的幹預空間 (例如，政府政策、新算法、公共教育、文化運動)，同時要知道，安全無法得到完全保證。在鼓勵創新的同時，我們仍應盡最大努力維護社會，這可能需要智慧、剋制和創造力。 
</div><div>
  &nbsp; 
</div><div>
  更具體地説， 
 <strong>在機器時代，我們越來越需要人類代理的提醒。技術的目的是為人類的利益服務，而人類是構建和設計這項技術的人。除了我們自己，還有什麼能讓我們保持謹慎呢?</strong></div><div>
  &nbsp; 
</div><div><hr></div><div>
  👍 為什麼偉大不能被計劃：OpenAI 科學家跨界撰寫的思維奇書，源自人工智能研究的意外發現，找到人類偉大發明的真正入口，顛覆傳統目標理論，重塑認知與思維模型，向普通人描繪一幅不同的成功圖景 。 
</div><div><hr></div><div>
  【💰售價】39.50 元 
</div><div>
  👉購買鏈接：https://j.youzan.com/TTuo6A 
</div></div>
                                    ]]>
            </description>
            <pubDate>Tue, 21 Nov 2023 01:55:22 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/4489239/blog/10149295</guid>
            <link>https://my.oschina.net/u/4489239/blog/10149295</link>
            <author>
                <![CDATA[原創]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Intel SIG 成立！攜手打造 openKylin-Intel 技術生態]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="color:#222222; margin-left:0px; margin-right:0px; text-align:justify"><span><span style="color:#000000">2023 年 11 月，經 openKylin 社區技術委員會審議通過，</span><strong><span style="color:#000000">Intel SIG</span></strong><span style="color:#000000">正式成立。</span></span></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000">Intel SIG 由</span><strong><span style="color:#000000">英特爾中國</span></strong><span style="color:#000000">發起成立，負責 openKylin 社區中桌面操作系統上 Intel 最新平台支持、適配與優化等技術相關的開發工作。</span></span></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify">&nbsp;</p><p style="color:#222222; margin-left:0; margin-right:0; text-align:center"><em><span><strong><span style="color:#ffae28">01&nbsp;</span></strong></span></em><span><strong><span style="color:#0b43d1">SIG 目標</span></strong></span></p><ul><li><span>創建並維護 openKylin Intel 新平台的規劃和升級，建設更完善的 openKylin-Intel 技術生態；</span></li><li><span>充分利用 openKylin 提供的平台，把最新的 Intel 技術基礎軟件棧融入 openKylin 操作系統，為未來社區的創新和發展提供更廣闊的空間，為推動 Intel 產品的落地提供生態支撐。</span></li></ul><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify">&nbsp;</p><p style="color:#222222; margin-left:0; margin-right:0; text-align:center"><em><span><strong><span style="color:#ffae28">02&nbsp;</span></strong></span></em><span><strong><span style="color:#0b43d1">SIG 職責</span></strong></span></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><strong><span style="color:#0052ff">1、Intel 新平台</span></strong></span></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000">根據 openKylin 社區的規劃，並且結合上遊內核的開發，Intel SIG 會對 Intel 最新的平台在下游社區進行全面支持。</span></span></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><strong><span style="color:#0052ff">2、Intel 新技術</span></strong></span></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000">根據客戶的需求，引入 Intel 優勢技術，更好的提供可行性方案；拓展更廣的技術和商業合作空間。</span></span></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><strong><span style="color:#0052ff">3、OEM 的支持</span></strong></span></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000">根據桌面平台的生產商 (OEM)，Intel 可以根據 OEM 的需求以及 openKylin 的要求，合作支持 OEM。</span></span></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><strong><span style="color:#0052ff">4、與 openKylin 共贏</span></strong></span></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000">Intel SIG 願意與 openKylin 各方合作，共同構建面向未來的良性合作生態環境，為 openKylin 開源桌面操作系統的發展提質提速。</span></span></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify">&nbsp;</p><p style="color:#222222; margin-left:0; margin-right:0; text-align:center"><em><span><strong><span style="color:#ffae28">03&nbsp;</span></strong></span></em><span><strong><span style="color:#0b43d1">歡迎加入 SIG</span></strong></span></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000">Intel SIG 負責 openKylin 社區中 Intel 技術相關的開發和信息交流，本小組擁有國內外頂尖的 Intel 平台研究技術團隊，為拓展 openKylin 的生態提供有力支撐，期待各位感興趣的小夥伴們的加入！</span></span></p><ul><li><span>郵件列表：</span></li><li><span><span style="color:#0052ff">intel@lists.openkylin.top</span></span></li><li><span>SIG 主頁：</span></li><li><span><span style="color:#0052ff">https://gitee.com/openkylin/community/tree/master/sig/Intel-SIG</span></span></li></ul></div>
                                    ]]>
            </description>
            <pubDate>Mon, 20 Nov 2023 01:35:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/267352</guid>
            <link>https://www.oschina.net/news/267352</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[雲原生週刊：Istio 1.20.0 發佈]]>
            </title>
            <description>
                <![CDATA[<div class="content"><h2>開源項目推薦</h2><h3><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Floft-sh%2Fdevpod" target="_blank">DevPod</a></h3><p>DevPod 是一款純客戶端工具，可在任何後端基於 devcontainer.json 創建可重現的開發人員環境。每個開發者環境都在一個容器中運行，並通過 devcontainer.json 進行指定。通過 DevPod 提供商，這些環境可以在任何後端創建，如本地計算機、Kubernetes 集羣、任何可訪問的遠程機器或雲中的虛擬機。</p><h3><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FFairwindsOps%2Fgemini" target="_blank">Gemini</a></h3><p>Gemini 是用於管理卷快照的 Kubernetes CRD 和 operator。可以定期為 PersistentVolumes 上的數據創建快照，清空舊快照，並以最少的停機時間恢復快照。</p><h3><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fr0binak%2FMTKPI" target="_blank">MTKPI</a></h3><p>MTKPI - 多工具 Kubernetes 滲透測試鏡像。該 docker 映像包含 Kubernetes 滲透測試所需的所有最常用工具。</p><h2>文章推薦</h2><h3><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcollabnix.com%2Ftop-5-alert-and-monitoring-tools-for-kubernetes%2F" target="_blank">Kubernetes 的 5 個最佳告警和監控工具</a></h3><p>這篇文章介紹了針對 Kubernetes 的前五個告警和監控工具。文章指出，Kubernetes 作為容器運行應用程序的首選選擇，具有可伸縮性、靈活性和彈性等優勢。然而，管理和監控 Kubernetes 可能會相當困難。因此，對於保證應用程序平穩可靠運行的關鍵是監控和告警。監控和告警是有效運營 Kubernetes 集羣的實踐方法，它們使您能夠收集集羣、節點、Pod、容器、服務和應用程序的指標、日誌和跟蹤數據，並使用儀錶板、圖表和表格對數據進行可視化和分析。通過規則、閾值和通知對異常、錯誤、故障和 SLA 違規進行告警，並通過調查根本原因、解決問題或升級到適當的團隊來採取行動。</p><h3><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcollabnix.com%2Ftop-5-machine-learning-tools-for-kubernetes%2F" target="_blank">Kubernetes 的 5 大機器學習工具</a></h3><p>這篇文章介紹了在 Kubernetes 上進行機器學習的五個頂級工具。文章介紹了每個工具的特點、優勢和使用案例，以及選擇這些工具的標準，如功能性、易用性、流行度和創新性。通過使用這些工具，用戶可以更輕鬆地在 Kubernetes 上進行機器學習任務，並提高其工作流程的效率和可靠性。</p><h3><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fspacelift.io%2Fblog%2Fkubernetes-deployment-strategies" target="_blank">8 種不同類型的 Kubernetes 部署策略</a></h3><p>這篇文章介紹了 Kubernetes 的八種不同部署策略，包括 Recreating、Rolling、Blue/Green、Canary、A/B、Ramped Slow Rollout、Best-Effort Controlled Rollout 和 Shadow Deployment。它解釋了每種策略的優點和用途，幫助讀者在應用程序部署和升級時做出明智的選擇。</p><h2>雲原生動態</h2><h3><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fkubescape.io%2Fblog%2F2023%2F09%2F19%2Fintroducing-kubescape-3%2F" target="_blank">Kubescape 3.0 發佈</a></h3><p>Kubescape 是 CNCF Kubernetes 安全姿態管理工具的下一代，日前發佈了 v3.0。</p><p>Kubescape 3.0 新增以下功能：</p><ul><li>將合規性和容器掃描結果存儲為 Kubernetes 集羣內的資源</li><li>通過命令行界面掃描容器鏡像的漏洞</li><li>報告集羣中所有鏡像的漏洞情況</li><li>全新的概覽安全掃描，幫助你為集羣安全設置基線</li><li>突出顯示高風險工作負載：那些如果受到損害可能造成最大危害的工作負載</li><li>改進的顯示輸出</li><li>新的基於能力的 Helm chart</li><li>每個工作負載、命名空間和集羣的 Prometheus 指標</li><li>通過 Prometheus Alertmanager 進行告警</li><li>將數據發送到集羣外的託管服務</li></ul><h3><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.opencost.io%2Fblog%2Faks-cost-analysis" target="_blank">OpenCost 宣佈與 Microsoft AKS 成本分析工具集成</a></h3><p>OpenCost 正在與 Microsoft 的新 Azure Kubernetes Service（AKS）成本分析工具集成，以實現使用度量收集。Microsoft Azure 的客戶現在可以根據 Kubernetes 特定的結構，原生地瞭解成本分配的可見性。</p><p>AKS 成本分析是針對標準和高級 AKS 羣集的附加組件，向客戶提供免費的服務。它直接在 Azure 門戶中提供成本分配報告。AKS 客戶現在可以輕鬆地可視化其 Kubernetes 成本分配，作為進一步優化和異常檢測的基礎。</p><h3><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fistio.io%2Flatest%2Fnews%2Freleases%2F1.20.x%2Fannouncing-1.20%2F" target="_blank">Istio 1.20.0 發佈</a></h3><p>Istio 1.20.0 發佈，這是 2023 年最後一個 Istio 版本，以下是該版本主要變化：</p><ul><li>網關 API</li><li>改進的外部名稱服務支持</li><li>一致的 Envoy 過濾器排序</li><li>對網絡 WasmPlugin 的擴展支持</li><li>TCP 元數據交換增強</li><li>插入根證書輪換</li><li>流量鏡像現在支持多個目標</li><li>...</li></ul><blockquote><p>本文由博客一文多發平台 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopenwrite.cn%3Ffrom%3Darticle_bottom" target="_blank">OpenWrite</a> 發佈！</p></blockquote></div>
                                    ]]>
            </description>
            <pubDate>Sun, 19 Nov 2023 10:20:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/4197945/blog/10149219</guid>
            <link>https://my.oschina.net/u/4197945/blog/10149219</link>
            <author>
                <![CDATA[原創]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[運營商神操作：後台斷網、停用寬帶賬號，強迫用戶更換光貓]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>近日，河南電視台都市頻道節目報道稱，河南周口聯通為了強迫用戶更換光貓，<strong>公司在後台停掉用戶的寬帶賬號，導致用戶無法上網，然後讓工程師上門「維修」，謊稱光貓損壞，需要花 299 元換新</strong>。<strong>更換完後，聯通再在後台恢復用戶的網絡</strong>。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-6bca55961849d5db6bafd2b8cf31a04abc6.png" referrerpolicy="no-referrer"></p><p>聯通公司不僅對老用戶進行這種強制更換光貓的行為，還會在給新用戶裝機的時候，故意使用破舊光貓，也就是之前強迫用戶換新留下的，而再過一段時間之後，又會告訴用戶使用的是舊光貓無法匹配，必須換新。聯通公司還會故意關掉用戶的短信服務，在後台增加增值業務，之後再把短信功能打開，以此牟利。</p><p><img height="826" src="https://static.oschina.net/uploads/space/2023/1120/163843_Utox_2720166.png" width="1518" referrerpolicy="no-referrer"></p><p><img src="https://static.oschina.net/uploads/space/2023/1120/164043_bGMp_2720166.png" referrerpolicy="no-referrer"></p><p>周口聯通迴應稱，全力配合省公司調查組進行調查覈實。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-5af067ca7f5336640898e328da5adc6109b.png" referrerpolicy="no-referrer"></p><p>來源：<em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fnews.sina.com.cn%2Fs%2F2023-11-20%2Fdoc-imzvfrzw9582625.shtml" target="_blank">https://news.sina.com.cn/s/2023-11-20/doc-imzvfrzw9582625.shtml</a></u></em></p></div>
                                    ]]>
            </description>
            <pubDate>Sun, 19 Nov 2023 08:31:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/267276</guid>
            <link>https://www.oschina.net/news/267276</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[阿里雲開源大數據產品年度發佈]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>本文根據 2023 雲棲大會演講實錄整理而成，演講信息如下：</p><p><strong>演講人</strong>：陳守元 | 阿里雲計算平台事業部開源大數據產品總監</p><p><strong>演講主題</strong>：阿里雲開源大數據產品年度發佈</p><p>隨着雲計算的不斷髮展，未來數據處理和應用的趨勢將圍繞 Cloud Native、Severless 和 Data+AI 展開。其中，雲原生架構已成為主流趨勢，因為它可以提高數據處理和應用程序的可伸縮性和靈活性，支持大規模部署和更快的響應時間。同時，Serverless 作為一種新型計算模式，可以提高處理效率、降低運營成本並減少資源浪費，其獨特的特點使得其成為處理大規模數據的理想選擇。此外，Data 與 AI 融合正在快速發展，不斷提高智能化和自動化程度，同時需要高質量的數據來支撐算法的準確性和有效性。</p><p><img src="https://oscimg.oschina.net/oscnet/up-a48d65a7b7035e480f3276674b7f31f68a3.png" alt="" referrerpolicy="no-referrer"></p><h2>EMR：面向下一代湖倉和全面 Serverless 化</h2><p>下面進入產品發佈環節，我們將圍繞上面三個點&nbsp;做哪些事情、有哪些發佈更好地服務用戶上雲&nbsp;來講述我們產品的重點發布。</p><p><img src="https://oscimg.oschina.net/oscnet/up-4026c36c77d94f189e70fb9fe1cb0464515.png" alt="" referrerpolicy="no-referrer"></p><p>首先，我們來看 EMR。EMR 是一個雲原生開源大數據平台系統。對於 EMR 而言，線下 IDC 大量基於開源 Hadoop 生態構建的線下用戶搬站上雲第一站就會選擇 EMR，因為改造代價特別地小，幾乎可以無縫平遷上雲。這對用戶來説是具有巨大的人力資本和機器資本的節省。&nbsp;我們將阿里雲 EMR 定位為&nbsp;用戶搬站上雲的第一站。</p><p>今年我們的產品矩陣做了升級，我們希望在雲上基於更多樣化的 IaaS 提供多樣化的 EMR 產品形態。EMR 通用版，核心解決的用戶問題就是幫助用戶的大數據系統平遷上雲，這也是和用戶線下部署兼容度最高的方案。第二個是 EMR 容器版，即 EMR ACK 版。現在 IT 基礎設施的雲原生容器化基本上都深入人心，我們大量客戶在雲上基於 IT 系統的構建都會選擇容器化的平台，例如阿里雲的 ACK。用戶自然而然會聯想到如何把 Data 和 AI 的 workload 遷移到 IT 基礎設施的同一個集羣裏，完成 Data&amp;AI 的負載&nbsp;與 IT 設施負載混用，EMR 容器版，或者説 EMR onACK 就是幫用戶解決這類問題的產品。</p><p>最後也是我們今天想強調的重點就是 EMR Serverless 版。對於 EMR Serverless 子產品線而言，內部有些 feature 或者功能&nbsp;在之前雲棲中已做了發佈。今天對於 EMR Serverless 產品線是一個更加完整的矩陣呈現，今天會重點講一下 Serverless Spark、Serverless StrarRocks 兩大主流 EMR 計算引擎的 Serverless 化，今天也是我們正式對外提出一個完整的 EMR Serverless 化的產品線矩陣。</p><p>EMR Serverless 版是 EMR 產品線形態中誕生最晚、發佈最新的一代產品和技術，其實 EMR 圍繞 Serverless 的佈局在一年前、兩年前都在緊鑼密鼓地進行。前面 OSS-HDFS、Serverless HDFS 這一塊其實在去年、前年已有發佈，但是今年我們做了更多的嘗試努力，我們希望把 EMR 上面主流的大數據計算引擎、存儲引擎、開發平台、元數據管理全都 Serverless 化，只有這樣方才能夠更好地滿足雲原生用戶更好地利用大數據。Serverless Spark，更好地解決了湖倉場景下 Data ETL 的處理能力，Serverless StrarRocks 更好地解決了湖倉場景下 Data analytic 能力，Serverless HDFS 更好解決了湖倉場景下數據存儲能力，最後 EMR Stutio 幫助用戶線下可以平遷體驗上雲，讓用戶能夠更好使用雲上大數據基礎設施，同時還能免運維。所以 EMR 今年從計算，到存儲，到開發環境&nbsp;幾乎全部實現了 EMR 主力引擎和平台都能夠做到 Serverless 化，我們希望能夠把整個大數據開發運維閉環，從而進一步幫助雲原生上的開發者更好地把大數據用起來。</p><p><img src="https://oscimg.oschina.net/oscnet/up-e0e494088f0e316e87a203fb7a7b147a1c7.png" alt="" referrerpolicy="no-referrer"></p><p>下面仍然回到 EMR 主力場景， EMR 通用版，圍繞湖倉場景做了大量更新。EMR 主力場景仍然圍繞着湖倉處理，圍繞在湖倉計算、存儲、運維、開發做了大量的更新。在計算層面，我們核心還是降本提效，IaaS 層適配了新的倚天 CPU，PaaS 層做了 Native Spark RunTime，這些都是從 IaaS 層和 PaaS 層更好地幫助用戶降本提效。存儲部分，Serverless HDFS (同時也稱之為 OSS-HDFS)&nbsp;很早已有發佈，但是在這一年希望讓 Serverless HDFS 和&nbsp;本地 HDFS 在使用層面給用戶體驗完全一致，包括&nbsp;在&nbsp;文件性能、數據訪問、源數據獲取等方案&nbsp;做到幾乎完全一致。為上述目標，我們因此做了大量有關係統性能優化&nbsp;以及&nbsp;系統安全性優化。我們的 Open 文件性能的提升、DU 訪問源數據的提升，這些都是今年的成果。</p><p><img src="https://oscimg.oschina.net/oscnet/up-00bfea3732092d7e26b3743ad341b1f080a.png" alt="" referrerpolicy="no-referrer"></p><p>EMR 運維，這主要體現在兩個方面。在雲上來説 EMR 能結合到雲原生上面給用戶創造比較大的平台價值就在於彈性，今年我們做到大量的彈性優化。我們大量客戶給我們反饋説 EMR 的平台彈性越來越穩定；另外一個運維重點，即 EMR Doctor，我們希望通過 AI 的方式、自動化、智能化的運維平台方式幫助用戶去解決開源大數據運維的問題。從社區開源大數據用戶反饋來看，開源大數據使用最大的、最痛的點就是系統運維。如何長期有效地保證我們的業務在雲上健康地運行，這是很多用戶上雲和雲下使用開源大數據非常大的痛點，EMR Doctor 就是解決這個問題。EMR 開發，即 EMR Studio，我們希望雲原生 Serverless 化託管了我們的開發平台、調度平台，幫助用戶從線下的體驗完全平遷到雲上的一套體驗。以上均是 EMR 圍繞湖倉場景的重大更新。</p><p>最後仍然回到 EMR For AI，我們每個產品都在擁抱積極的變化，這裏分為三部分：EMR DataScience、EMR Doctor、EMR+DataWorks 的 Code Pilot。EMR DataScience 是在 EMR 的容器版裏面，我們提供了一個新的集羣叫 EMR DataScience，裏面內置了不少 AI 最流行的組件，包括 Pytorch、TF。我們希望用戶在一個平台上既能夠處理大數據，同時還能夠雲原生地處理 AI 的工具，這是 EMR DataScience 幫助用戶做的相關工作。EMR Doctor，這個工作前面提到希望用 AI 化、智能化的方式幫助用戶實現 AIOps，能夠用自動化的手段定位問題、診斷問題、及早發現問題。EMR+Dataworks，今年 DataWorks 重磅的發佈就是 code pilot 的發佈，但是那上面作為一個平台實際上底下也對接了 EMR 等等，正好實際上 code pilot 也是平台引擎無關的 Feature，可以生成 EMR 裏面的 HIVE 代碼，用戶就可以用 DataWorks 上面開發平台能夠通過自然語言生成 MaxCompute 的 SQL，能夠操作業務，這樣能夠極大地減少用戶開發代碼的成本，這在 DataWorks 對外提供公測的時候歡迎去試用一下。</p><h2>Flink Streaming Lakehouse：新一代的流式湖倉新方案</h2><p>下面我們看一下 Flink Streaming Lakehouse。Lakehouse 這個概念其實在前幾年很火，原因就是對於一個 Lakehouse 的系統來説，既兼具了 Data Warehouse 的嚴謹，包括 ACID、版本的管理、數據格式的校驗等等；同時它還有 Data Lake 的靈活性，能夠放很多大量非結構化的文本，包括圖片、視頻、音頻、圖像等等。而 Lakehouse 同時能夠承載結構化的數據和非結構化的數據，這對用戶來説是非常好的 AI 和大數據融合的底層存儲方案。但是我們看 Lakehouse 的過程中發現 Lakehouse 在時效性方面有非常大的問題，Flink 核心使命和價值就在幫助我們的客戶解決大數據實時化轉型和升級。所以 Flink 社區&nbsp;和&nbsp;我們&nbsp;一起發佈了 Streaming Lakehouse 方案。</p><p><img src="https://oscimg.oschina.net/oscnet/up-37eae0cedf4dbaf6356c5188b319f6e8a02.png" alt="" referrerpolicy="no-referrer"></p><p>回到 Streaming Lakehouse 我主要從產品方向&nbsp;講三個場景要點。前面已經提到 Lakehouse 在 AI 時代下 Lakehouse 的方案會越來越重要，因為它既能存儲結構化的數據又能存儲非階段的數據，這個是大數據和 AI 一體化存儲的重要承載點。但是 Lakehouse 在實踐的過程中仍然遇到時效性的問題，整個 Lakehouse 的 Data Pipeline 串聯起來可能達到小時級別的延遲，從最開始的數據進入到數據價值的發揮，比如 BI、AI，能夠看到整個數據鏈路到小時級別，這其實對於用戶來説要構建一個實時湖倉面臨很大的延遲。所以 Flink 希望一起幫助用戶做到 Lakehouse 的實時化，通過流式、實時幫助用戶做很大的提升。</p><p>最後是 Unified，其實 Flink 社區在前幾年一直主打 Unified Batch &amp; Streaming。我們希望在計算層面做到融合，就是流批一體。我們在開源社區推廣流批一體的方案時，發現如果用戶只是計算層面的融合對於用戶只能解決一半的問題。還有一半問題在於存儲，存儲仍然是兩套的存儲方案，兩套存儲和兩套數據因此會導致的離線和實時的數據不一致性對於用戶來説是非常大的問題，所以 Flink 團隊和社區一起構建了 Paimon。Paimon 基於底層的分佈式文件系統，比如説 OSS 會構建一個 Unified 的 storage，既可以做流，也可以做批，我們稱之為批流一體的存儲。所以 Flink+Paimon 構成 Lakehouse 的方案，既具備 Unified 的 process，也可以具備 Unified 的 Storage，這一層合併在一起能夠真正完整地幫助用戶實現流批一體的解決方案。這是我們 Streaming Lakehouse 的價值點，最終我們希望幫助用戶在 Data+AI 時代下提供實時化、流式化和 Serverless 化的湖倉方案。</p><p>回到 Flink 主線，我們一直以來的使命就是希望幫助用戶做到大數據的升級和轉型，所以追求實時場景下的性價比一直是 Flink 團隊一直以來努力的方向。追求實時化的性價比今年有兩個重要的點，一個是 Flink 全面擁抱了倚天，結合到倚天&nbsp;整個實時計算 Flink 綜合的性價比有 50% 的提升，這是 Flink 團隊結合 IaaS 層面做了大量優化。同時在 PaaS 層 Flink 企業級內核&nbsp;我們仍然在做大量優化，這其中包括算子的優化，以及未來我們會公佈 native runtime 的優化。這部分優化相比於開源 Flink 引擎，我們實時計算 Flink 版&nbsp;會有兩倍的提升，特別是在吞吐部分可以解決很多用戶高吞吐量或者大流量的實時計算場景。</p><p><img src="https://oscimg.oschina.net/oscnet/up-93711ed92a4488a619f2f0cfa9e51e70d03.png" alt="" referrerpolicy="no-referrer"></p><h2>Elasticsearch:Serverless 和 Search for Data &amp; AI</h2><p>接下來講一下 Elasticsearch，這也是開源大數據很重要的組成部分。説到 Elasticsearch 可能大家更多仍然停留在比較早期 for data 的 search，就是全文的檢索，類似於搜索引擎要做全文的檢索。但今天我想告訴大家這個思想需要刷新一下，Elasticsearch 不僅是 for data 的 search，也是 for AI 的 search。我今天給大家重點會講一下 ES 如何從 Data 轉變成 Data+AI 的 search 系統。</p><p>第一個是我們的 Elasticsearch 的版本發佈。坦白地説，當前產品形態，即 ES on PaaS 的獨立集羣版本已經非常好地滿足我們中國公有云和專有云客戶很多的市場需求，不少中大型公司都非常認可阿里雲的 ES 產品形態，產品客戶受眾無論在基數以及未來增長都很不錯。但實際上隨着最近這一兩年客戶在降本提效上提上了日程之後，發現有一批非常大的潛在客戶以及中長尾的客戶其實仍然對雲上的獨立集羣版本所帶來的成本仍然認為是比較大的上雲入門門檻。他們非常希望以低門檻甚至零門檻的方式開啓雲上的 ES，這就是我們 ES Serverless 要做的初衷，我們希望以一個零門檻的方式能夠幫助用戶開啓雲上 Elasticsearch 的使用。</p><p><img src="https://oscimg.oschina.net/oscnet/up-dda1df3c99a6593d14261aabceb742084c0.png" alt="" referrerpolicy="no-referrer"></p><p>同時 Elasticsearch Serverless 也是我們國內首家支持通用場景的 ES 版本。去年我們也發佈了一個 Elasticsearch Serverless 版本，但更多解決日誌 ELK 場景的需求。但是該版本在數據一致性上會存在問題，所以今年我們進行大量的產品技術架構重構。本次 ES Serverless 的發佈是一個面向通用場景的升級發佈，這裏面不僅支持包括日誌場景，還支持訂單、金融等等場景，這裏面的數據一致性都可以得到很好的保障。這是我們今年發佈相比於去年發佈升級很不一樣的點。針對 ES Serverless 可以真正按量付費、秒級彈性、簡單運維，同時可以完全兼容開源的 ES，這是很多其他的廠商不一定能做到的。</p><p>下面重點強調 ES for AI 和 Data 的部分，標誌着 ES 真正從 Data 面向 Data&amp;AI 的搜索引擎。雲棲會場外面有很大的廣告欄，主打的是 ESRE 的發佈，這是 ES 公司重大的發佈。發佈的核心簡單跟大家説一下，就是支持 AI 相關檢索，包括向量檢索，包括多路並規的查詢優化，這些東西都是在 ES 內核重點打的點，幫助用戶做 AI 檢索。阿里雲 ES 圍繞着 ES 最新的 AI 能力進行了大量方案集成，就是右邊的增強方案。我們跟達摩院 AI 方案做聯合，和 PAI—EAS 方案聯合，甚至會和社區一起做更多的聯合方案，這些方案能夠幫助我們的用戶更好地在雲上用上阿里雲、達摩院 AI 的技術，和社區的 ES 更好地結合起來。所以我們希望通過 ES8.9 這個版本能夠幫助用戶構建下一代面向 Data+AI 的檢索系統。</p><p><img src="https://oscimg.oschina.net/oscnet/up-47305474e3702aae7f01185fc4b3c7a7d65.png" alt="" referrerpolicy="no-referrer"></p><p>圍繞 ES 自研能力的升級，阿里雲 ES 是和 ES 公司一起合作，也是基於開源的 ES 做更多的優化孵化，其實是完全基於開源，也是完全兼容開源的，我們做了大量的增強。而這裏面做了三個升級，包括場景的升級，也就是日誌場景向通用場景的升級和改造。去年 ES 更多是做日誌場景、ELK 場景，今年的 ES Serverless 面向通用場景進行完全開放。另外就是有關搜索內核引擎的優化，包括讀寫分離、存算分離，這些更好地解決集羣穩定性問題、成本流控問題、資源彈性的問題。最後我們在購買鏈路和相關控制枱上做了比較大的體驗升級，我們非常推薦大家去用一用阿里雲 ES Serverless 版本，感受一下完全 Serverless 化的 ES。</p><h2>Milvus：AI 時代的搜索引擎</h2><p>今天最後一個，也是今年完全新的產品。前面全部是我們現有的功能、現有產品線的疊加，Milvus 這部分是我們今年要發佈的 AI 時代新的搜索引擎。目前，在向量檢索部分 Milvus 幾乎是全球最火、最亮眼的技術。我們會在 12 月份開啓向量檢索 Milvus 版本對外測試，相比於開源的 Milvus 來説會做相應產品企業級的增強。同時在兼容開源的 Milvus 之上，我們還會去結合達摩院的技術能夠提供更好的企業級向量檢索能力。同時在雲上肯定會做大量的產品聯合工作，包括和我們的存儲上有大量非結構化的數據可供用戶檢索查詢。同時我們會跟 PAI 平台、達摩院 AI 模型做更多的深度集成，做 AI 向量檢索能力、做大模型向量支撐，這些方案未來都會在我們的產品之上構建。所以我們最終是希望能夠幫助雲上使用 Milvus 的用戶更快、更方便、更低門檻構建 AI 時代下的搜索系統。</p><p><img src="https://oscimg.oschina.net/oscnet/up-684d85b432854ecd04eafd9cad2a5a50df8.png" alt="" referrerpolicy="no-referrer"></p><p>回顧一下我們講了大數據的三個趨勢。Cloud Native，整個 IT 投資都在往雲上加速轉型。Serverless 化，我們認為未來的 PaaS 平台最終全部都會歸到 Serverless 化，所有 AI 產品、大數據產品和其他 PaaS 產品都會歸到 Serverless 化。最後是 Data+AI，未來 AI 和大數據會做徹底的融合打通，這也是我們整個開源大數據一直以來在積極圍繞這三個點做佈局。</p><p>最後希望大家多多關注阿里雲，關注阿里雲的開源大數據，謝謝大家！</p></div>
                                    ]]>
            </description>
            <pubDate>Sun, 19 Nov 2023 08:00:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/5583868/blog/10149103</guid>
            <link>https://my.oschina.net/u/5583868/blog/10149103</link>
            <author>
                <![CDATA[原創]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[OpenAI 前 CEO 和總裁 Sam Altman & Greg Brockman 加入微軟]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>微軟 CEO Satya Nadella 剛剛<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftwitter.com%2Fsatyanadella%2Fstatus%2F1726509045803336122" target="_blank">發佈推特稱</a></u>，OpenAI 前 CEO 和總裁 Sam Altman &amp; Greg Brockman 將加入微軟，他們負責領導新的 AI 研究團隊。</p><p><img height="1176" src="https://static.oschina.net/uploads/space/2023/1120/155839_imd2_2720166.png" width="1264" referrerpolicy="no-referrer"></p><p>Sam Altman 轉發了這條推文，<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftwitter.com%2Fsama%2Fstatus%2F1726510261509779876" target="_blank">並説道</a></u>：不忘使命，砥礪前行。</p><p><img height="678" src="https://static.oschina.net/uploads/space/2023/1120/161424_UZuO_2720166.png" width="1272" referrerpolicy="no-referrer"></p><p>Satya Nadella <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftwitter.com%2Fsatyanadella%2Fstatus%2F1726516824597258569" target="_blank">評論了 Sam 的推文</a>：</p><blockquote><p>Sam，我對你以首席執行官身份加入新團隊感到無比激動，你將為我們的創新工作開闢新的道路。</p><p>多年來，我們學會瞭如何為創始人和創新者提供空間，讓他們在微軟內部發展獨立的身份和文化，這一點從 GitHub、Mojang Studios 到 LinkedIn 的發展中可見一斑。我迫不及待想看到你也能做到。</p></blockquote><p><img height="1372" src="https://static.oschina.net/uploads/space/2023/1120/164746_aILD_2720166.png" width="1286" referrerpolicy="no-referrer"></p></div>
                                    ]]>
            </description>
            <pubDate>Sun, 19 Nov 2023 08:00:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/267272</guid>
            <link>https://www.oschina.net/news/267272</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Altman 迴歸失敗，OpenAI 董事會聘請 Twitch 前高管擔任 CEO]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">據</span>&nbsp;<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.theinformation.com%2Farticles%2Fbreaking-sam-altman-will-not-return-as-ceo-of-openai" target="_blank">The Information</a>&nbsp;<span style="color:#000000">和</span>&nbsp;<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.bloomberg.com%2Fnews%2Farticles%2F2023-11-20%2Fopenai-s-board-hires-former-twitch-executive-shear-as-ceo" target="_blank">Bloomberg</a>&nbsp;<span style="color:#000000">消息稱，經過一個週末的談判，OpenAI 董事會決定不顧投資者要求 Sam Altman 復職的呼聲，聘請前 Twitch 首席執行官 Emmett Shear 來擔任該公司的臨時首席執行官。</span></p><p><span style="color:#000000">OpenAI 聯合創始人兼董事會董事 Ilya Sutskever 向員工表示，公司高管有嘗試努力挽回 Sam Altman，但沒有成功，Altman</span>&nbsp;<span style="color:#000000">將不會回到 OpenAI。</span></p><p><img alt="" height="300" src="https://static.oschina.net/uploads/space/2023/1120/153143_G4mc_4252687.png" width="300" referrerpolicy="no-referrer"></p><p><span style="color:#000000">Emmett Shear 將從 Mira Murati 手中接過這一職位，這也意味着 OpenAI 在三天內迎來了第三任首席執行官。此前，在 Sam Altman 被突然解僱後，曾有大批 OpenAI 員工開始在社交媒體上表達了對 Altman 的支持，Mira Murati 也在此列。</span></p><p><span style="color:#000000">Shear 在 2006 年幫助推出了遊戲流媒體網站 Twitch，並於 2014 年以近 10 億美元的價格將其出售給亞馬遜。今年早些時候，Shear 辭去了 Twitch 的首席執行官一職。</span></p><p><span style="color:#000000">有知情人士表示，Shear 之所以能贏得 OpenAI 董事會的青睞，是因為他能意識到人工智能所帶來的生存威脅。此外，<span style="background-color:#ffffff">Open AI 的董事會已經至少聯繫了兩名科技行業的知名高管，希望其中一位可以擔任公司董事長的職位。</span></span></p><p><span style="color:#000000">OpenAI 及其最大投資者微軟的發言人目前暫未迴應相關置評請求。</span></p></div>
                                    ]]>
            </description>
            <pubDate>Sun, 19 Nov 2023 07:17:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/267256/openai-twitch-ceo-shear</guid>
            <link>https://www.oschina.net/news/267256/openai-twitch-ceo-shear</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[🔥 周熱點 | OpenAI 內訌，奧特曼被驅逐；俄羅斯操作系統 Aurora OS 5.0 全新 UI 亮相；.NET 8 正式 GA.....]]>
            </title>
            <description>
                <![CDATA[回顧一週熱門資訊。2023.11.13-2023.11.19]]>
            </description>
            <pubDate>Sun, 19 Nov 2023 03:50:00 GMT</pubDate>
            <guid isPermaLink="false">https://mp.weixin.qq.com/s?__biz=MzA4OTI5NjUwOA==&#38;mid=2649093971&#38;idx=1&#38;sn=3f2a763dda28e1c46c3aeca3f287766e&#38;chksm=880c4c40bf7bc556325bae39dd086d3b0d3cea17b35ad8c141b34669fc8c632bc161023a587a&#38;token=584579097&#38;lang=zh_CN#rd</guid>
            <link>https://mp.weixin.qq.com/s?__biz=MzA4OTI5NjUwOA==&#38;mid=2649093971&#38;idx=1&#38;sn=3f2a763dda28e1c46c3aeca3f287766e&#38;chksm=880c4c40bf7bc556325bae39dd086d3b0d3cea17b35ad8c141b34669fc8c632bc161023a587a&#38;token=584579097&#38;lang=zh_CN#rd</link>
        </item>
        <item>
            <title>
                <![CDATA[Linux Kernel 6.6 確認成為 LTS 版本]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">Greg Kroah-Hartman 已經宣佈 Linux Kernel 6.6 版本為長期支持 (LTS) 版本；支持期限到 2026 年 12 月。</span></p><p><span style="color:#000000">Linux Kernel 6.6 於 10 月 29 日正式發佈，是一次包含了新功能、硬件支持、安全增強和性能改進的重大更新。具體包括有：引入了 EEVDF scheduler，最終實現了對 Intel Shadow Stack 的支持，為 Nouveau DRM 驅動程序添加了 Mesa NVK Vulkan 驅動程序所需的&nbsp;user-space API，繼續支持即將到來的 Intel 和 AMD 平台，以及大量的其他驅動程序改進和一些不錯的性能優化等。</span></p><p><img height="254" src="https://oscimg.oschina.net/oscnet/up-40bae094eb2126579af39e14031fa92878c.png" width="700" referrerpolicy="no-referrer"></p><p><span style="color:#000000">一般來説，年度 LTS 內核往往是該日曆年的最後一個穩定內核版本。Linux 6.6 於十月底發佈，Linux 6.7 預計可能會在 2023 年的最後幾天或者 2024 年年初達到穩定。但考慮到 6.7 版本規模較大，且年末的假期往往會放慢測試和 bug 修復的速度，導致相關週期拖長，因此 6.7 版本大概率還是可能在 2024 年初登陸。</span></p><p><span style="color:#000000">目前，Kernel.org 已更新相關版本信息。Linux 6.6 生命週期將將截止 2026 年 12 月；與此同時，Linux 6.1、5.15 和 5.10 也將於 2026 年 12 月結束生命週期。因此根據當下的政策，Linux 6.6 LTS 將在未來三年內得到維護，不過也有消息稱內核開發人員一直在討論將 LTS 支持期縮短為 2 年。</span></p><p><span style="color:#000000">更多詳情可查看<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.kernel.org%2Fcategory%2Freleases.html" target="_blank">此處</a>。</span></p></div>
                                    ]]>
            </description>
            <pubDate>Sun, 19 Nov 2023 03:36:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/267220/linux-6-6-lts</guid>
            <link>https://www.oschina.net/news/267220/linux-6-6-lts</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Altman 以訪客身份回到 OpenAI，和公司高管會面談判]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>據 The Information 報道，OpenAI 首席戰略官 Jason Kwon 在員工備忘錄中表示，<strong>上週五離職的 Sam Altman 等高管或將會回到公司</strong>。</p><p>而 Altman 本人也在週一<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftwitter.com%2Fsama%2Fstatus%2F1726345564059832609" target="_blank">推文</a></u>寫道「這是我第一次也是最後一次帶這玩意」，配圖是他手持 OpenAI 訪客工牌的自拍，表示他持訪客證明造訪了 OpenAI 總部，與公司董事會討論某事。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-01348c9bedfa830267784f185d7e8e2dbeb.png" referrerpolicy="no-referrer"></p><p>有消息稱，包括微軟在內的投資者正在向 OpenAI 董事會施壓，要求他們同意 Sam Altman 等離職高管迴歸 OpenAI 工作。</p><p>目前尚不能確定 Altman 等人是否會回到 OpenAI 繼續工作。有消息稱，Altman 正計劃同前 OpenAI 總裁 Greg Brockman 一起成立一間新的 AI 公司。</p></div>
                                    ]]>
            </description>
            <pubDate>Sun, 19 Nov 2023 02:11:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/267200</guid>
            <link>https://www.oschina.net/news/267200</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[中國科學院軟件所在分組加密算法差分密碼分析方面取得進展]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">中國科學院軟件研究所可信智能系統研究團隊在分組加密算法的差分密碼分析方面取得<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FbrkeBtNVsRP27RgnXZLnVg" target="_blank">進展</a>。該工作設計了一個面向分組加密算法的領域編程語言 EasyBC，在此基礎上提出了通用、可擴展的差分密碼分析方法，研製了全自動分析工具平台 EasyBC （如圖 1）。</span></p><p><span style="color:#000000">該研究成果以_EasyBC: A Cryptography-Specific Language for Security Analysis of Block Ciphers against Differential Cryptanalysis_為題被編程語言國際頂級會議 POPL 2024 錄用，通訊作者是軟件所計算機科學國家重點實驗室宋富研究員。</span></p><p><span style="color:#000000"><img alt="" height="122" src="https://oscimg.oschina.net/oscnet/up-3680dde4b4183fc67c37f117d71002e2e79.png" width="500" referrerpolicy="no-referrer"></span></p><p><em><span style="color:#000000">圖 1. EasyBC 平台流程圖</span></em></p><p><span style="color:#000000">分組加密算法（block cipher）是將明文分成多個等長的模塊（block），使用對稱密鑰對每組分別加密或解密，廣泛應用於電子郵件加密、銀行交易轉帳等多個領域。作為極其重要的加密協議組成，主流分組加密算法有中國國家密碼管理局頒佈的 SM1、SM4 和 SM7，美國政府覈定的標準算法 AES 和 3DES。而差分密碼分析在評估分組加密算法的安全性方面發揮着核心作用，是分組加密算法標準化不可或缺的安全性分析手段。當前已有的差分密碼分析方法在通用性、自動化程度方面存在一定不足，同時建模過程複雜導致用戶需要熟悉大量的建模方法及底層分析工具的應用。</span></p><p><span style="color:#000000">為解決上述不足，研究團隊設計了一種分組加密算法的密碼學專用高級編程語言 EasyBC，提供了完整的語法、類型和語義的形式定義，為分組加密算法安全性自動分析奠定了良好基礎；提出了三種不同分析精度和性能的差分密碼分析方法，不僅統一和優化了已有的各類加密操作的建模方法，並提出了多種新的建模方法。</span></p><p><span style="color:#000000">研究團隊實現了 23 個加密原語，包括美國國家標準與技術研究院（National Institute of Standards and Technology，NIST）認證加密方案的底層置換算法以及多種常用分組加密算法（如圖 2）；並對其中的分組密碼原語進行了安全性分析（如圖 3），進而驗證了 EasyBC 語言的表達能力以及 EasyBC 工具平台安全性自動分析的有效性。</span></p><p><span style="color:#000000"><img alt="" height="184" src="https://oscimg.oschina.net/oscnet/up-6c84d792455028442affb5312288fbac624.png" width="500" referrerpolicy="no-referrer"></span></p><p><em><span style="color:#000000">圖 2.EasyBC 語言實現的 23 個加密原語</span></em></p><p><em><span style="color:#000000"><img alt="" height="171" src="https://oscimg.oschina.net/oscnet/up-55a59db5baf9240d59fc4e82c667f38b199.png" width="500" referrerpolicy="no-referrer"></span></em></p><p><em><span style="color:#000000">圖 3.Word-wise 實現的加密原語差分密碼安全性分析結果</span></em></p><p><span style="color:#000000">該研究對分組加密算法的差分密碼分析研究具有重要意義，為後續密碼學相關研究者們進行分組加密算法的安全性全自動分析和各類運算操作建模方法性能評估提供了良好的研究基礎和平台支撐。</span></p><p style="color:#000000; margin-left:0; margin-right:0; text-align:left"><strong>論文信息：</strong></p><p style="color:#000000; margin-left:0; margin-right:0; text-align:left"><em>EasyBC: A Cryptography-Specific Language for Security Analysis of Block Ciphers against Differential Cryptanalysis</em>. Pu Sun (ShanghaiTech University), Fu Song* (Institute of Software Chinese Academy of Sciences, and University of Chinese Academy of Sciences), Yuqi Chen (ShanghaiTech University), Taolue Chen (Birkbeck, University of London). Proc. ACM Program. Lang. 8, POPL, Article 29 (January 2024), 33 pages.<span>&nbsp;</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdoi.org%2F10.1145%2F3632871" target="_blank">https://doi.org/10.1145/3632871</a></p></div>
                                    ]]>
            </description>
            <pubDate>Sat, 18 Nov 2023 04:31:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/267024</guid>
            <link>https://www.oschina.net/news/267024</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Kotlin Multiplatform 公佈 2024 年開發路線圖]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">繼幾周前宣佈推出</span><a href="https://www.oschina.net/news/265360/kotlin-multiplatform-stable">第一個穩定版本</a><span style="color:#000000">後，JetBrains <span style="background-color:#ffffff">發佈了 2024 年 </span>Kotlin Multiplatform&nbsp;<span style="background-color:#ffffff">的<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.jetbrains.com%2Fkotlin%2F2023%2F11%2Fkotlin-multiplatform-development-roadmap-for-2024%2F" target="_blank">開發路線圖</a>。 其</span></span><span style="background-color:#ffffff; color:#19191c">目標是在 2024 年對 Kotlin Multiplatform 核心技術、Compose Multiplatform、KMP 工具和 KMP 庫進行一系列改進。</span></p><p><span style="color:#000000">「我們致力於使 Compose Multiplatform 成為一個框架，允許創建在所有受支持的平台上看起來都同樣美觀且高性能的應用程序。」</span></p><p><span style="color:#000000"><img alt="" height="281" src="https://oscimg.oschina.net/oscnet/up-8af6c9da66280ab985d71d05df036c402a9.png" width="500" referrerpolicy="no-referrer"></span></p><p><span style="color:#000000">目前，該公司對&nbsp;<span style="background-color:#ffffff">Compose Multiplatform 的主要關注點是將 iOS 版 Compose 升級到 Beta 版。同時還計劃：</span></span></p><ul style="margin-left:0; margin-right:0"><li>使所有 Jetpack Compose core API 和組件實現多平台。</li><li>提高 iOS 上的渲染性能。</li><li>使 Compose for iOS 應用程序中的滾動和文本編輯行為與 iOS 原生應用程序中的行為相同。</li><li>實現通用 API 以共享所有類型的資源。</li><li>與 iOS 和&nbsp;Desktop accessibility API 集成。</li><li>提供多平台導航解決方案。</li></ul><p><span style="color:#000000">以及致力於改進 Compose for Web，尤其<span style="background-color:#ffffff">是 Wasm</span>。例如：</span></p><ul><li><span style="color:#000000">允許你移植現有代碼；</span></li><li><span style="color:#000000">支持不同的屏幕尺寸、方向和密度；</span></li><li><span style="color:#000000">支持通過鼠標、觸摸屏、物理鍵盤或屏幕鍵盤進行輸入；</span></li><li><span style="color:#000000">改善性能和 binary size。</span></li></ul><p style="margin-left:0; margin-right:0; text-align:start"><span style="color:#000000"><span style="background-color:#ffffff">JetBrains 還將對 IDE 進行多項改進，</span>包括：增強對 Compose Multiplatform 的支持，包括常見代碼的實時預覽和可視化調試工具；<span style="background-color:#ffffff">項目配置幫助；</span>多平台項目所有部分的統一和增強的調試體驗。</span></p><p style="margin-left:0; margin-right:0; text-align:start"><span style="display:none">&nbsp;</span><span style="color:#000000"><span style="background-color:#ffffff">為了支持想要與 iOS target&nbsp;共享代碼的開發人員，項目團隊將致力於直接從 Kotlin 導出到 Swift。「流行的 Kotlin Multiplatform 應用場景之一是與 iOS target&nbsp;共享代碼。我們希望關注在代碼庫中使用 Kotlin Multiplatform 框架的 iOS 開發人員的開發體驗......它將消除 Objective-C 瓶頸，從而提供更廣泛的 Swift 語言支持和更自然的 API 導出。」</span></span></p><p style="margin-left:0; margin-right:0; text-align:start"><span style="color:#000000">還在專門為 Kotlin 庫作者創建工具，旨在提高 Kotlin API 導出到 Swift 時的兼容性和用戶友好性。一些其他舉措包括，<span style="background-color:#ffffff">提高 Kotlin/Native 編譯的性能、改進 CocoaPods 集成以及添加對使用 SwiftPM 導出框架的支持。&nbsp;</span></span></p><p style="margin-left:0; margin-right:0; text-align:start"><span style="color:#000000">此外，隨着 Kotlin <span style="background-color:#ffffff">Multiplatform&nbsp;</span>生態系統的快速發展，庫的向後兼容性變得至關重要。<span style="background-color:#ffffff">JetBrains 將重點關注改進 klib 格式，以允許庫創建者利用他們的 JVM 庫構建技能；</span><span style="background-color:#ffffff">在 Kotlin Multiplatform&nbsp;</span><span style="background-color:#ffffff">庫中實現與 JVM 相同的代碼內聯行為；以及提供一個工具來確認庫的公共 API 沒有以不兼容的方式進行了更改。</span></span></p><p style="margin-left:0; margin-right:0; text-align:start">更多詳情可<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.jetbrains.com%2Fkotlin%2F2023%2F11%2Fkotlin-multiplatform-development-roadmap-for-2024%2F" target="_blank">查看官方博客</a>。</p></div>
                                    ]]>
            </description>
            <pubDate>Sat, 18 Nov 2023 04:00:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/267112/kotlin-multiplatform-development-roadmap-2024</guid>
            <link>https://www.oschina.net/news/267112/kotlin-multiplatform-development-roadmap-2024</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[GROMACS —— 分子動力學模擬工具包]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>GROMACS（全稱：GROningen MAchine for Chemical Simulations，格羅寧根化學模擬體系），是用於研究生物分子體系的分子動力學模擬工具包，主要用來模擬研究蛋白質、脂質、核酸等生物分子的性質。</p><p>它可以用分子動力學、隨機動力學或者路徑積分方法模擬溶液或晶體中的任意分子，進行分子能量的最小化，分析構象等。</p><p>它的模擬程序包包含 GROMACS 力場 (蛋白質、核苷酸、糖等)，研究的範圍可以包括玻璃和液晶、到聚合物、晶體和生物分子溶液。</p><p>GROMACS 是一個功能強大的分子動力學的模擬軟件，其在模擬大量分子系統的牛頓運動方面具有極大的優勢。</p><blockquote><p>分子動力學模擬是分子模擬中最接近實驗條件的模擬方法。它能夠從原子層面給出體系的微觀演變過程，直觀的展示實驗現象發生的機理與規律。</p><p>因此，分子動力學模擬在生物，藥學，化學以及材料科學的研究中發揮着越來越重要的作用。</p></blockquote><p>GROMACS 起初由荷蘭格羅寧根大學生物化學系開發，目前由來自世界各地的大學和研究機構維護。</p><p><strong>主要功能</strong></p><ul><li><p>支持基本動力學相關算法，包括牛頓力學及隨機動力學積分器、能量最小化、正則模式分析等。</p></li><li><p>支持溫度及壓強控制，支持基於 SHAKE 和 P-LINCS 的完全約束算法，支持多種幾何約束。</p></li><li><p>支持 AMBER、CHARMM 及 OPLS 等常見經典力場。</p></li><li><p>支持 QM/MM 混合動力學，可對接 GAMESS、Orca 等量化軟件。</p></li></ul><p>它可以用於上百萬個粒子體系的分子動力學模擬研究，尤其是生物體系，如磷脂雙分子層生物膜、蛋白質、藥物分子等。</p><p><img src="https://static.oschina.net/uploads/space/2023/1102/194131_DK4t_2720166.png" referrerpolicy="no-referrer"></p><p>此外，GROMACS 能夠非常快速地計算非鍵作用，因此也可用於非生物體系，如聚合物、一些有機物、無機物等。</p><p><img src="https://static.oschina.net/uploads/space/2023/1102/194200_MtCm_2720166.png" referrerpolicy="no-referrer"></p><p><strong>核心優勢</strong></p><ul><li><p>開源軟件、可免費使用</p></li><li><p>力場較全面且容易擴充</p></li><li><p>操作方便，相關教程也多</p></li><li><p>算法性能好，計算效率高</p></li></ul><p>GROMACS 最突出的特色和優勢是高效，無論串行還是並行版本。</p><p><img src="https://static.oschina.net/uploads/space/2023/1102/194219_S3QX_2720166.png" referrerpolicy="no-referrer"></p></div>
                                                                ]]>
            </description>
            <pubDate>Sat, 18 Nov 2023 03:38:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/p/gromacs</guid>
            <link>https://www.oschina.net/p/gromacs</link>
        </item>
        <item>
            <title>
                <![CDATA[Gitee 推薦 | 網絡自動化領域解決方案框架 NetAxe]]>
            </title>
            <description>
                <![CDATA[<p align="center"><img src="https://gitee.com/iflytek/NetAxe/raw/master/readme/logo.png" alt="netaxe" referrerpolicy="no-referrer"></p><p align="center"><img src="https://img.shields.io/badge/Python-brightgreen.svg" referrerpolicy="no-referrer"><img src="https://img.shields.io/badge/Django-orange.svg" referrerpolicy="no-referrer"><img src="https://img.shields.io/badge/FastAPI-brightgreen.svg" referrerpolicy="no-referrer"><img src="https://img.shields.io/badge/Vue3-blue.svg" referrerpolicy="no-referrer"><img src="https://img.shields.io/badge/Vite-orange.svg" referrerpolicy="no-referrer"><img src="https://img.shields.io/badge/NaiveUI-blue.svg" referrerpolicy="no-referrer"><img src="https://img.shields.io/badge/license-Apache-green.svg" referrerpolicy="no-referrer"><a href="https://gitee.com/NetAxeClub" target="_blank"><img src="https://img.shields.io/badge/Author-NetAxeClub-orange.svg" referrerpolicy="no-referrer"></a></p><p align="center"><a target="_blank" href="https://gitee.com/link?target=https%3A%2F%2Fnetaxe.github.io">Netaxe 官方文檔</a> |  <a target="_blank" href="https://gitee.com/link?target=http%3A%2F%2F47.99.86.164%3A9980">在線預覽</a></p><h2><a id="user-content-項目介紹" class="anchor" href="https://gitee.com/iflytek/NetAxe#%E9%A1%B9%E7%9B%AE%E4%BB%8B%E7%BB%8D"></a>項目介紹</h2><p><strong>專注網絡自動化領域的整體架構解決方案</strong></p><p>[ NetAxe ]是一個網絡自動化領域解決方案框架，通過微服務和微前端的方式構建的應用集合，主要有資源管理、配置管理、自動化、網絡拓撲、地址定位、地址管理等等功能集合，同時各個微應用支持插件形式的能力集成，方便用戶自行擴展。</p><h2><a id="user-content-組織地址" class="anchor" href="https://gitee.com/iflytek/NetAxe#%E7%BB%84%E7%BB%87%E5%9C%B0%E5%9D%80"></a>組織地址</h2><p><a href="https://gitee.com/NetAxeClub">NetAxeClub</a></p><p>致力於網絡自動化工具和平台開發</p><p>聯繫郵箱:<a href="mailto:netaxe@qun.mail.163.com">netaxe@qun.mail.163.com</a></p><h2><a id="user-content-文檔説明" class="anchor" href="https://gitee.com/iflytek/NetAxe#%E6%96%87%E6%A1%A3%E8%AF%B4%E6%98%8E"></a>文檔説明</h2><p>👇👇👇👇👇👇👇👇👇👇👇</p><p>📚 <a href="https://gitee.com/link?target=https%3A%2F%2Fnetaxe.github.io%2F">NetAxe 文檔教程使用説明</a> : <a href="https://gitee.com/link?target=https%3A%2F%2Fnetaxe.github.io%2F">https://netaxe.github.io/</a></p><p>👆👆👆👆👆👆👆👆👆👆👆</p><h2><a id="user-content-項目預覽" class="anchor" href="https://gitee.com/iflytek/NetAxe#%E9%A1%B9%E7%9B%AE%E9%A2%84%E8%A7%88"></a>項目預覽</h2><p>👇👇👇👇👇👇👇👇👇👇👇</p><p><a href="https://gitee.com/link?target=http%3A%2F%2F47.99.86.164%3A9980">體驗環境</a> 賬號密碼：admin/123456</p><p>僅在工作時間開啓 (9:30-18:00)</p><p>👆👆👆👆👆👆👆👆👆👆👆</p><h2><a id="user-content-平台架構圖" class="anchor" href="https://gitee.com/iflytek/NetAxe#%E5%B9%B3%E5%8F%B0%E6%9E%B6%E6%9E%84%E5%9B%BE"></a>平台架構圖</h2><p><img src="https://cdn.staticaly.com/gh/xuehaoweng/netaxe-image@master/%E6%9E%B6%E6%9E%84%E5%9B%BE.3vrmin46me00.webp" alt="平台架構圖" referrerpolicy="no-referrer"></p><h2><a id="user-content-1 平台登錄頁" class="anchor" href="https://gitee.com/iflytek/NetAxe#1%E5%B9%B3%E5%8F%B0%E7%99%BB%E5%BD%95%E9%A1%B5"></a>1.平台登錄頁</h2><p><img src="https://cdn.staticaly.com/gh/xuehaoweng/netaxe-image@master/netaxe-login.78afwmigsc00.webp" alt="登錄頁面" referrerpolicy="no-referrer"></p><h2><a id="user-content-2 資產管理" class="anchor" href="https://gitee.com/iflytek/NetAxe#2%E8%B5%84%E4%BA%A7%E7%AE%A1%E7%90%86"></a>2.資產管理</h2><p><img src="https://cdn.staticaly.com/gh/xuehaoweng/netaxe-image@master/golang.63zo8r1zsjs0.webp" alt="資產管理" referrerpolicy="no-referrer"></p><h2><a id="user-content-3 配置差異比較" class="anchor" href="https://gitee.com/iflytek/NetAxe#3%E9%85%8D%E7%BD%AE%E5%B7%AE%E5%BC%82%E6%AF%94%E8%BE%83"></a>3.配置差異比較</h2><p><img src="https://cdn.staticaly.com/gh/xuehaoweng/netaxe-image@master/netaxe-git-diff.60gnker70dk0.webp" alt="配置差異比較" referrerpolicy="no-referrer"></p><h2><a id="user-content-4webssh" class="anchor" href="https://gitee.com/iflytek/NetAxe#4webssh"></a>4.Webssh</h2><p><img src="https://cdn.staticaly.com/gh/xuehaoweng/netaxe-image@master/netaxe-webssh.3rs5vtioxe80.webp" alt="Webssh" referrerpolicy="no-referrer"></p><h2><a id="user-content-5 接口清單" class="anchor" href="https://gitee.com/iflytek/NetAxe#5%E6%8E%A5%E5%8F%A3%E6%B8%85%E5%8D%95"></a>5.接口清單</h2><p><img src="https://cdn.staticaly.com/gh/xuehaoweng/netaxe-image@master/netaxe-interface.5pje0o1za4w0.webp" alt="接口清單" referrerpolicy="no-referrer"></p><h2><a id="user-content-6 採集方案" class="anchor" href="https://gitee.com/iflytek/NetAxe#6%E9%87%87%E9%9B%86%E6%96%B9%E6%A1%88"></a>6.採集方案</h2><p><img src="https://cdn.staticaly.com/gh/xuehaoweng/netaxe-image@master/netzxe-collect.4yf0qcxemhk0.webp" alt="採集方案" referrerpolicy="no-referrer"></p><h2><a id="user-content-7 任務列表" class="anchor" href="https://gitee.com/iflytek/NetAxe#7%E4%BB%BB%E5%8A%A1%E5%88%97%E8%A1%A8"></a>7.任務列表</h2><p><img src="https://cdn.staticaly.com/gh/xuehaoweng/netaxe-image@master/netaxe-task.58uns0zatss0.webp" alt="任務列表" referrerpolicy="no-referrer"></p><h2><a id="user-content-8 任務調度管理" class="anchor" href="https://gitee.com/iflytek/NetAxe#8%E4%BB%BB%E5%8A%A1%E8%B0%83%E5%BA%A6%E7%AE%A1%E7%90%86"></a>8.任務調度管理</h2><p><img src="https://cdn.staticaly.com/gh/xuehaoweng/netaxe-image@master/netaxe-dispatch.3x68huinuzi0.webp" alt="任務調度管理" referrerpolicy="no-referrer"></p><h2><a id="user-content-9-地址管理" class="anchor" href="https://gitee.com/iflytek/NetAxe#9-%E5%9C%B0%E5%9D%80%E7%AE%A1%E7%90%86"></a>9. 地址管理</h2><p><img src="https://cdn.staticaly.com/gh/xuehaoweng/netaxe-image@master/ipam.3vspimj3jf20.webp" alt="地址管理" referrerpolicy="no-referrer"></p><h2><a id="user-content-10-權限中心" class="anchor" href="https://gitee.com/iflytek/NetAxe#10-%E6%9D%83%E9%99%90%E4%B8%AD%E5%BF%83"></a>10. 權限中心</h2><p><img src="https://cdn.staticaly.com/gh/xuehaoweng/netaxe-image@master/rbac.6k2qnc2yqxk0.webp" alt="權限中心" referrerpolicy="no-referrer"></p><h2><a id="user-content-交流羣" class="anchor" href="https://gitee.com/iflytek/NetAxe#%E4%BA%A4%E6%B5%81%E7%BE%A4"></a>交流羣</h2><blockquote><p>掃碼添加好友，提交入羣申請。</p></blockquote><p><img src="https://cdn.staticaly.com/gh/xuehaoweng/netaxe-image@master/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20230106172200.240x6tqonx9c.webp" alt="NetAxe 開源社區" referrerpolicy="no-referrer"></p><h2><a id="user-content--參與貢獻" class="anchor" href="https://gitee.com/iflytek/NetAxe#-%E5%8F%82%E4%B8%8E%E8%B4%A1%E7%8C%AE"></a>🤝 參與貢獻</h2><p>歡迎你參與到 NetAxe 項目的建設中來！🎉</p><p>我們可以一起：</p><ul><li>🎁 設計和開發功能模塊</li><li>⭐ 討論實際運維場景和自動化的落地實踐</li><li>🎊 結識一羣熱愛學習、熱愛開源的朋友</li></ul><h2><a id="user-content--維護者" class="anchor" href="https://gitee.com/iflytek/NetAxe#-%E7%BB%B4%E6%8A%A4%E8%80%85"></a>✨ 維護者</h2><p>維護者是做出傑出貢獻且在社區長期活躍的 NetAxe 社區成員。</p><ul><li><a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2FM87NET">jamlee</a></li><li><a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2Fxuehaoweng">xuehaoweng</a></li></ul><h2><a id="user-content--貢獻者" class="anchor" href="https://gitee.com/iflytek/NetAxe#-%E8%B4%A1%E7%8C%AE%E8%80%85"></a>✨ 貢獻者</h2><p>貢獻者是在 NetAxe 社區中合併了 1 個或多個 PR 的社區成員。
虛位以待。。。</p><p><a href="https://gitee.com/link?target=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FsP2dC0txvBhExYxbjq94UA">PR 提交指南</a></p><p>github:&nbsp;<a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2Fiflytek%2FNetAxe">https://github.com/iflytek/NetAxe</a><br>
gitee:&nbsp;<a href="https://gitee.com/iflytek/NetAxe">https://gitee.com/iflytek/NetAxe</a><br>
NetAxe 官網文檔:<a href="https://gitee.com/link?target=https%3A%2F%2Fnetaxe.github.io%2F">https://netaxe.github.io/</a></p>]]>
            </description>
            <pubDate>Sat, 18 Nov 2023 03:32:00 GMT</pubDate>
            <guid isPermaLink="false">https://gitee.com/iflytek/NetAxe</guid>
            <link>https://gitee.com/iflytek/NetAxe</link>
        </item>
        <item>
            <title>
                <![CDATA[每日一博 | 彩虹橋架構演進之路 - 性能篇]]>
            </title>
            <description>
                <![CDATA[<div class="content"><h1>一、前言</h1><p>一年前的《<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzkxNTE3ODU0NA%3D%3D%26mid%3D2247488943%26idx%3D1%26sn%3D867041a53c801b5f83457fa622bb4909%26scene%3D21%23wechat_redirect" target="_blank">彩虹橋架構演進之路</a>》側重探討了穩定性和功能性兩個方向。在過去一年中，儘管業務需求不斷增長且流量激增了數倍，彩虹橋仍保持着零故障的一個狀態，算是不錯的階段性成果。而這次的架構演進，主要分享一下近期針對性能層面做的一些架構調整和優化。其中最大的調整就是 Proxy-DB 層的線程模式從 BIO 改造成了性能更好的 NIO。下面會詳細介紹一下具體的改造細節以及做了哪些優化。</p><blockquote><p>閲讀本文預計需要 20～30 分鐘，整體內容會有些枯燥難懂，建議閲讀前先看一下上一篇彩虹橋架構演進的文章（<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzkxNTE3ODU0NA%3D%3D%26mid%3D2247488943%26idx%3D1%26sn%3D867041a53c801b5f83457fa622bb4909%26scene%3D21%23wechat_redirect" target="_blank">彩虹橋架構演進之路</a>）以及 MySQL 協議相關基礎知識。</p></blockquote><h1>‍<img src="" alt="" referrerpolicy="no-referrer"></h1><h1>二、改造前的架構</h1><p>先來複習一下彩虹橋的全景架構圖： <img src="https://oscimg.oschina.net/oscnet/up-a99befe24a3c3d97eae3a3fd156ae4e23bd.jpg" alt="" referrerpolicy="no-referrer"></p><h2>Proxy 三層模塊</h2><p>針對 Proxy 這一層，可以大致分成 Frontend、Core、Backend 三層：</p><ul><li><strong>Frontend-服務暴露層</strong>：使用 Netty 作為服務器，按照 MySQL 協議對接收&amp;返回的數據進行編解碼。</li><li><strong>Core-功能&amp;內核層</strong>：通過解析、改寫、路由等內核能力實現數據分片、讀寫分離、影子庫路由等核心功能。</li><li><strong>Backend-底層 DB 交互層</strong>：通過 JDBC 實現與數據庫交互、對結果集改列、歸併等操作。</li></ul><h2>BIO 模式下的問題</h2><p>這裏 Core 層為純計算操作，而 Frontend、Backend 都涉及 IO 操作，Frontend 層使用 Netty 暴露服務為 NIO 模式，但是 Backend 使用了數據庫廠商提供的傳統 JDBC 驅動，為 BIO 模式。所以 Proxy 的整體架構還是 BIO 模式。在 BIO 模型中，每個連接都需要一個獨立的線程來處理。這種模型有一些明顯的缺點：</p><ul><li><strong>高資源消耗</strong>：每個請求創建獨立線程，伴隨大量線程開銷。線程切換與調度額外消耗 CPU。</li><li><strong>擴展性受限</strong>：受系統線程上限影響，處理大量併發連接時，性能急劇下降。</li><li><strong>I/O 阻塞</strong>：BIO 模型中，讀/寫操作均為阻塞型，導致線程無法執行其他任務，造成資源浪費。</li><li><strong>複雜的線程管理</strong>：線程管理和同步問題增加開發和維護難度。</li></ul><p>我們看最簡單的一個場景：在 JDBC 在發起請求後，當前線程會一直阻塞直到數據庫返回數據，當出現大量慢查或者數據庫出現故障時，會導致大量線程阻塞，最終雪崩。在上一篇彩虹橋架構演進文章中，我們做了一些改進來避免了 BIO 模型下的一些問題，比如使用線程池隔離來解決單庫阻塞導致全局雪崩的問題。 <img src="https://oscimg.oschina.net/oscnet/up-5dad3dc23bdca9a239bdf3253b4a7f9b319.jpg" alt="" referrerpolicy="no-referrer"></p><p>但是隨着邏輯庫數量的增多，最終導致 Proxy 的線程數膨脹。系統的可伸縮性和吞吐量都受到了挑戰。因此有必要將現有的基於 JDBC 驅動的阻塞式連接升級為採用 NIO（非阻塞 I/O）方式連接數據庫。</p><h1>‍<img src="" alt="" referrerpolicy="no-referrer"></h1><h1>三、改造後的架構</h1><ul><li><strong>BIO-&gt;NIO</strong></li></ul><p>想把 Proxy 整體架構從 BIO-&gt;NIO，最簡單的方式就是把傳統的 BIO 數據庫驅動 JDBC 換成 NIO 的數據庫驅動，但是在調研過後發現開源的 NIO 驅動並不多，而且基本上沒有什麼最佳實踐。最後在參考 ShardingSphere 社區之前做的調研後（<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fshardingsphere%2Fissues%2F13957" target="_blank">https://github.com/apache/shardingsphere/issues/13957</a> ） ，決定使用 Vertx 來替換 JDBC。最開始使用 Vert.x 的原因，第一是 Vertx 的異步編碼方式更友好，編碼複雜度相對較低，第二是因為它實現了主流數據庫的驅動。但最終的結果不盡人意，由於 Vertx 相關抽象化的架構，導致鏈路較長時，整個調用棧深非常誇張。最終壓測出來的吞吐量提升只有 5% 不到，而且存在很多兼容性問題。於是推倒重來，決定自研數據庫驅動和連接池。</p><ul><li><strong>跳過不必要的編解碼階段</strong></li></ul><p>由於 JDBC 驅動會自動把 MySQL 的字節數據編解碼成 Java 對象，然後 Proxy 再把這些結果集經過一些加工（元信息修正、結果集歸併）後再進行編碼返回給上游。如果自研驅動的話，就可以把編解碼流程控制的更細緻一些，把 Proxy 不需要加工的數據直接轉發給上游，跳過無意義的編解碼。後面會介紹一下哪些場景是不需要 Proxy 對結果集進行加工的。</p><h2>自研 NIO 數據庫驅動</h2><p>數據庫驅動主要是封裝了與 DB 層交互協議，封裝成高級 API。下面 2 張圖是 java.sql 包中的 Connection 和 Statement 的一些核心接口。 <img src="https://oscimg.oschina.net/oscnet/up-517ee2a0bafe29e2a2e648762ed31d87bb9.jpg" alt="" referrerpolicy="no-referrer"><img src="https://oscimg.oschina.net/oscnet/up-3e947c153f1f81f011a177b66d7b2036cee.jpg" alt="" referrerpolicy="no-referrer"></p><p>所以首先我們需要了解一下，如何與數據庫進行數據交互，以 MySQL 為例，使用 Netty 連接 MySQL，簡單的交互流程如下。 <img src="https://oscimg.oschina.net/oscnet/up-99ac2f8e643ce9a4d7c1db6f7db7a20a81e.jpg" alt="" referrerpolicy="no-referrer"></p><p>使用 Netty 與 MySQL 連接建立後，我們要做的就是按照 MySQL 協議規定的數據格式，先鑑權後再發送具體的命令包即可。下面是 MySQL 官方文檔中鑑權流程和命令執行流程：</p><ul><li><strong>鑑權流程</strong>：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdev.mysql.com%2Fdoc%2Fdev%2Fmysql-server%2Flatest%2Fpage_protocol_connection_phase.html" target="_blank">https://dev.mysql.com/doc/dev/mysql-server/latest/page_protocol_connection_phase.html</a></li><li><strong>執行命令流程</strong>：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdev.mysql.com%2Fdoc%2Fdev%2Fmysql-server%2Flatest%2Fpage_protocol_command_phase.html" target="_blank">https://dev.mysql.com/doc/dev/mysql-server/latest/page_protocol_command_phase.html</a></li></ul><p>下面就是按照 MySQL 的文檔，去實現編解碼 Handle，我們簡單看一下實現的代碼。 <img src="https://oscimg.oschina.net/oscnet/up-93dbe9735b43149a35e21ca060fb870ed92.jpg" alt="" referrerpolicy="no-referrer"></p><ul><li>decode 解碼</li></ul><p>就是針對 MySQL 返回的數據包解碼，根據長度解析出 Palyload 封裝成 MySQLPacketPayload 傳給對應的 Handle 處理。</p><ul><li>encode 編碼</li></ul><p>把具體的命令類轉換成具體的 MySQL 數據包，這裏的 MySQLPacket 有多個實現類，跟 MySQL 的 Command 類型一一對應。</p><p>現在還需要一個類似 java.sql.Connection 的實現類，來組裝 MySQLPacket 並寫入到 Netty 通道中，並且解析編碼後的 MySQLPacketPayload 轉換成 ResultSet。</p><p><img src="https://oscimg.oschina.net/oscnet/up-5cf9d17b87a550d191bd089eef9e41f28fd.jpg" alt="" referrerpolicy="no-referrer"><img src="https://oscimg.oschina.net/oscnet/up-2c4b743cde5a7c667d2a2d04881afaf237a.jpg" alt="" referrerpolicy="no-referrer"> 看起來比較簡單，交互流程和傳統的 JDBC 幾乎一樣，但是由於現在是異步化流程，所有的 Response 都是通過回調返回，所以這裏有 2 個難點：</p><ul><li>由於 MySQL 在上一條命令沒結束前無法接受新的命令，所以如何控制單個連接的命令串行化？</li><li>如何將 MySQL 返回的數據包和發起命令的 Request 一一綁定？</li></ul><p>首先 NettyDbConnection 引入了一個無鎖化非阻塞隊列 ConcurrentLinkedQueue。 <img src="https://oscimg.oschina.net/oscnet/up-95d916682b2dd973e5096a9c7889a398b1c.jpg" alt="" referrerpolicy="no-referrer"></p><p>在發送 Command 時，如何沒有正在進行中的 Command，則直接發送，如果有正在進行中的 Command，直接扔到隊列中，等待上一條 Command 處理完成後推動下一條命令的執行。保證了單個連接命令串行化。</p><p>其次，NettyDbConnection 在執行命令時，傳入一個 Promise，在 MySQL 數據包全部返回後，這個 Promise 將會被設置完成，即可於發起命令的 Request 一一綁定。 <img src="https://oscimg.oschina.net/oscnet/up-fbcb7f0a0133a4cb43712626f4fbfed08a3.jpg" alt="" referrerpolicy="no-referrer"></p><h2>自研 NIO 數據庫連接池</h2><p>前面介紹了 NettyDbConnection 這個類，實現了與 MySQL 的交互，並且提供了執行 SQL 的高級 API，但實際使用過程中，不可能每次都創建一個連接執行完 SQL 就關閉。所以需要對 NettyDbConnection 進行池化，統一管理連接的生命週期。其功能類似於傳統連接池 HikariCP，在完成基本能力的基礎上，做了很多性能優化。</p><ul><li>連接生命週期管控</li><li>連接池動態伸縮</li><li>完善的監控</li><li>連接異步保活</li><li>超時控制</li><li>EventLoop 親和性</li></ul><p>這裏除了 EventLoop 親和性，其他幾個功能只要用過傳統的數據庫連接池應該都比較熟悉，這裏不做過多展開。這裏主要針對 EventLoop 親和性展開介紹一下。</p><p>在文章開頭我們説到 Proxy 的三層模塊，Frontend、Core、Backend，如果現在我們把 Backend 層於數據庫交互的組件換成了我們自研的驅動，那麼 Proxy 就即是 Netty Server，也是 Netty Client，所以 Frontend 和 Backend 可以共用一個 EventLoopGroup。為了降低線程上下文切換，在單個請求從 Frontend 接收、經過 Core 層計算後轉發到 MySQL ，再到接收 MySQL 服務響應，以及最終的回寫給 Client 端，這一些列操作儘量放在一個 EventLoop 線程中處理。 <img src="https://oscimg.oschina.net/oscnet/up-e04581647d274a5cc64fded2d2f26bff551.jpg" alt="" referrerpolicy="no-referrer"></p><p>具體的做法就是 Backend 在選擇與數據庫連接時，優先選擇與當前 EventLoop 綁定的連接。也就是前面提到的 EventLoop 親和性，這樣就能保證大部分場景下一次請求從頭到尾都由同一個 EventLoop 處理，下面我們看一下具體的代碼實現。</p><p>在 NettyDbConnectionPool 類中使用一個 Map 存儲連接池中的空閒連接，Key 為 EventLoop，Value 為當前 EventLoop 綁定的空閒連接隊列。 <img src="https://oscimg.oschina.net/oscnet/up-3099eb3f9c96d39f72551fa8442ebdce261.jpg" alt="" referrerpolicy="no-referrer"></p><p>在獲取時，優先獲取當前 EventLoop 綁定的連接，如果當前 EventLoop 未綁定連接，則會借用其他 EventLoop 的連接。 <img src="https://oscimg.oschina.net/oscnet/up-830d6a25ed63767ae092d9eaa272e7624b5.jpg" alt="" referrerpolicy="no-referrer"></p><p>為了提高&nbsp;EventLoop 命中率，需要注意幾點配置：</p><ul><li>EventLoop 線程數量儘量與 CPU 核心數保持一致。</li><li>連接池最大連接數超過&nbsp;EventLoop 線程數越多，EventLoop 命中率越高。</li></ul><p>下面放一張壓測環境（8C16G、連接池最大連接數 10~30）的命中率監控，大部分保持在 75% 左右。 <img src="https://oscimg.oschina.net/oscnet/up-2164ed7abbf169379e215ff14861f04d876.jpg" alt="" referrerpolicy="no-referrer"></p><h2>跳過不必要的編解碼</h2><p>前面説到，有部分 SQL 的結果集是不需要 Proxy 進行加工的，也就是可以直接把 MySQL 返回的數據流原封不動轉發給上游，直接省去編解碼操作。那什麼 SQL 是不需要 Proxy 進行加工的呢，我們舉個例子説明一下。</p><p>假設邏輯庫 A 裏面有一張表 User 做了分庫，分了 2 個庫 DB1 和 DB2，分片算法是 user_id%2。</p><ul><li>SQL 1</li></ul><blockquote><p>‍SELECT id, name FROM user WHERE user_id in (1, 2)</p></blockquote><ul><li>SQL 2</li></ul><blockquote><p>‍SELECT id, name FROM user WHERE user_id in (1)</p></blockquote><p>很顯然 SQL 1 由於有 2 個分片 Value，最終匹配到了 2 個節點，SQL 2 只會匹配到 1 個節點。 <img src="https://oscimg.oschina.net/oscnet/up-f6637b742c35d1af023f60cf01309006bc9.jpg" alt="" referrerpolicy="no-referrer"></p><p>SQL 1 由於需要對結果集進行歸併，所以無法跳過編解碼，SQL 2 不需要對結果集歸併，只需要把結果集中的列定義數據做修正後，真正的 Row 數據無需處理，這種情況就可以把 Row 數據直接轉發至上游。</p><h2>全鏈路異步化</h2><p>Backend 層用自研連接池+驅動替換原先的 HikariCP+JDBC 後，從 Frontend-Core-Backend 全鏈路涉及到阻塞的操作需要全部替換成異步化編碼，也就是通過 Netty 的 Promise 和 Future 來實現。 <img src="https://oscimg.oschina.net/oscnet/up-3eb5da9b30f76427c3cddf2847919af3b71.jpg" alt="" referrerpolicy="no-referrer"></p><p>由於部分場景拿到 Future 時，可能當前 Future 已經完成了，如果每次都是無腦的加 Listener 會讓調用棧加長，所以我們定義了一個通用的工具類來處理 Future，即 future.isDone() 時直接執行，反之才會 addListener，最大化降低整個調用棧的深度。 <img src="https://oscimg.oschina.net/oscnet/up-d36312a5a58e232274aa174dea7ccd9551a.jpg" alt="" referrerpolicy="no-referrer"></p><h2>兼容性</h2><p>除了以上基本代碼的改造外，還需要做大量的兼容工作：</p><ul><li>特殊數據庫字段類型處理</li><li>JDBC URL 參數兼容</li><li>ThreadLocal 相關數據全部需要遷移至 ChannelHandlerContext 中</li><li>日誌 MDC、TraceContext 相關數據傳遞</li><li>……</li></ul><h1>‍<img src="" alt="" referrerpolicy="no-referrer"></h1><h1>四、性能表現</h1><p>經過幾輪性能壓測後，NIO 架構相較於 BIO 架構性能有較大提升：</p><ul><li>整體最大吞吐量提升 67%</li><li>LOAD 下降 37% 左右</li><li>高負載情況下 BIO 多次出現進程夯住現象，NIO 相對較穩定</li><li>線程數減少 98% 左右</li></ul><h1>‍<img src="" alt="" referrerpolicy="no-referrer"></h1><h1>‍五、總結</h1><p>NIO 架構的改造工作量相當巨大，中間也經歷了一些曲折，但是最終的結果令人滿意。得益於 ShardingShpere 本身內核層面的高性能加上本次 NIO 改造後，彩虹橋在 DAL 中間件性能層面基本上可以算是第一梯隊了。</p><h1>‍<img src="" alt="" referrerpolicy="no-referrer"></h1><p>*文 / 新一</p><p>本文屬得物技術原創，更多精彩文章請看：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftech.dewu.com" target="_blank">得物技術官網</a></p><p>未經得物技術許可嚴禁轉載，否則依法追究法律責任！</p></div>
                                    ]]>
            </description>
            <pubDate>Sat, 18 Nov 2023 03:27:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/5783135/blog/10143389</guid>
            <link>https://my.oschina.net/u/5783135/blog/10143389</link>
            <author>
                <![CDATA[原創]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[OpenAI 董事會與 Sam Altman 討論重返 CEO 崗位事宜]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">The Verge 援引多位知情人士消息稱，OpenAI 董事會正在與 Sam Altman 討論重返公司擔任首席執行官的事宜。</span></p><p><span style="color:#000000">其中一位知情人士表示，在經歷了沒有任何通知就突然被董事會解僱的 Altman 對迴歸一事"態度曖昧"，並希望對公司的治理模式進行重大變革。</span></p><p><img height="358" src="https://oscimg.oschina.net/oscnet/up-7c44d0d4980461dc3b0cab2147edf5763c7.png" width="500" referrerpolicy="no-referrer"></p><p><span style="color:#000000">事實上，在 OpenAI 董事會宣佈解僱了 Altman 幾小時後；被免去董事會主席職務的 Greg Brockman 就公開宣佈辭職，後續還有多位 OpenAI 高管也陸續辭職。一些風險投資家也公開聲明表示支持 Altman，紅杉資本普通合夥人 Alfred Lin 在推特上發文稱，期待着 Altman 和 Brockman 建立下一個改變世界的公司。OpenAI 最大的投資者微軟則在 Altman 被解僱後不久發表聲明稱，該公司「將繼續致力於」與 OpenAI 的合作關係。</span></p><p><span style="color:#000000">事件後續的進展是，Altman 和董事會約定了一個時間點 —— 在當地時間下午 5 點之前達成停戰協議，即董事會辭職，他和 Brockman 迴歸。然後董事會的搖擺不定導致他們錯過了這一時間期限。</span></p><p><span style="color:#000000">如果不能儘快達成協議，Altman 和 Brockman 的離開勢必會帶走更多 OpenAI 員工。兩人一直在與朋友和投資者討論創辦另一家公司的事宜，如果 Altman 決定離開並創辦一家新公司，肯定會有大批員工追隨。目前 OpenAI 的發言人仍未迴應有關 Altman 與董事會討論迴歸事宜的置評請求。微軟發言人則拒絕發表評論。</span></p><p><span style="color:#000000">OpenAI 當下的董事會成員包括首席科學家 Ilya Sutskever、Quora 首席執行官 Adam D'Angelo、前 GeoSim Systems 首席執行官 Tasha McCauley 以及喬治城安全與新興技術中心戰略總監 Helen Toner 組成。</span></p><p><span style="color:#000000">多位消息人士透露，Sutskever 也是 OpenAI 的聯合創始人之一併領導着 OpenAI 的研究團隊，他在罷免 Altman 的過程中發揮了重要作用。而他在這次政變中的角色也表明，公司的研發部門和產品部門之間存在權力鬥爭。</span></p><p><strong><span style="color:#000000">相關閲讀：</span></strong></p><ul><li><a href="https://www.oschina.net/news/267006/openai-ceo-sam-altman-fired" target="_blank">OpenAI 董事會內訌，CEO 兼創始人 Sam Altman 被逐出公司</a></li><li><a href="https://www.oschina.net/news/267013/openai-greg-brockman-quit" target="_blank">OpenAI 總裁 Greg Brockman 辭職</a></li></ul></div>
                                    ]]>
            </description>
            <pubDate>Sat, 18 Nov 2023 03:19:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/267101/openai-board-discussions-with-sam-altman-return-as-ceo</guid>
            <link>https://www.oschina.net/news/267101/openai-board-discussions-with-sam-altman-return-as-ceo</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[OneTable —— Lakehouse 表格式間全方位互操作]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="background-color:#ffffff; color:#1f2328">OneTable 是一種表格式的全方位轉換器，可促進數據處理系統和查詢引擎之間的互操作性</span><span style="color:#000000">。Apache Hudi、Delta Lake 和 Apache Iceberg 之間無縫互操作。</span></p><p>OneTable 不是一種新的或獨立的格式，OneTable 提供了用於轉換 Lakehouse 表格式元數據的抽象和工具</p><p><span><span>OneTable 通過利用表表示的通用模型來簡化數據湖操作。這允許用戶以一種格式寫入數據，同時仍然受益於其他格式的集成和功能。例如，OneTable 使現有的 Hudi 用戶能夠無縫地使用 Databricks 的 Photon Engine 或使用 Snowflake 查詢 Iceberg 表。創建從一種格式到另一種格式的轉換非常簡單，只需要實現一些接口，項目團隊認為，這將有助於將來支持的源格式和目標格式的擴展。</span></span></p><p style="margin-left:0px; margin-right:0px"><img alt="" height="414" src="https://static.oschina.net/uploads/space/2023/1116/163549_inUl_4252687.png" width="500" referrerpolicy="no-referrer"></p></div>
                                                                ]]>
            </description>
            <pubDate>Sat, 18 Nov 2023 03:13:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/p/onetable</guid>
            <link>https://www.oschina.net/p/onetable</link>
        </item>
    </channel>
</rss>
