<?xml version="1.0" encoding="UTF-8"?>
<rss
    xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"


>
    <channel>
        <title>
            <![CDATA[開源中國-綜合資訊]]>
        </title>
        <link>https://www.oschina.net/news/industry</link>
        <atom:link href="http://rsshub.app/oschina/news/industry" rel="self" type="application/rss+xml" />
        <description>
            <![CDATA[開源中國-綜合資訊 - Made with love by RSSHub(https://github.com/DIYgod/RSSHub)]]>
        </description>
        <generator>RSSHub</generator>
        <webMaster>i@diygod.me (DIYgod)</webMaster>
        <language>zh-cn</language>
        <lastBuildDate>Sun, 03 Mar 2024 08:04:11 GMT</lastBuildDate>
        <ttl>120</ttl>
        <item>
            <title>
                <![CDATA[英特爾開源其 Python NPU 加速庫]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">英特爾已將其 NPU 加速庫 (intel-npu-acceleration-library) 在 Apache-2.0 協議下開源。這是一個 Python 庫，旨在利用英特爾神經處理單元 (NPU) 的強大功能在兼容硬件上執行高速計算，從而提高應用程序的效率。</span></p><p><span style="color:#000000">該庫目前正處於積極開發狀態。為了顯着提高庫的性能，項目團隊正在努力實現一系列關鍵功能。其中已實現的包括支持 8 位量化、Float16 支持、torch.compile 支持和 Static shape inference。計劃實現的有：</span></p><ul><li><span style="color:#000000">4 位量化和 GPTQ</span></li><li><span style="color:#000000">NPU-Native 混合精度推理</span></li><li><span style="color:#000000">BFloat16 (Brain Floating Point Format)</span></li><li><span style="color:#000000">LLM MLP horizontal fusion 實現</span></li><li><span style="color:#000000">MHA NPU 推理</span></li><li><span style="color:#000000">NPU/GPU 異構計算</span></li><li><span style="color:#000000">Paper</span></li></ul><p><span style="color:#000000">倉庫頁面上的 Python 代碼示例還展示了在 NPU 上進行單矩陣乘法運算、為 NPU 編譯模型，甚至在 NPU 上運行 Tiny-Llama 模型。</span></p><div style="text-align:start"><pre><span><span><span><span><span><span><span style="background-color:var(--bgColor-muted, var(--color-canvas-subtle))"><span style="color:#1f2328"><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span style="color:var(--fgColor-default, var(--color-fg-default))"><span style="background-color:var(--bgColor-muted, var(--color-canvas-subtle))"><span><span><span><span style="color:var(--color-prettylights-syntax-keyword)">from</span></span><span>intel_npu_acceleration_library</span>.<span>backend</span><span><span style="color:var(--color-prettylights-syntax-keyword)">import</span></span><span><span style="color:var(--color-prettylights-syntax-variable)">MatMul</span></span><span><span style="color:var(--color-prettylights-syntax-keyword)">import</span></span><span>numpy</span><span><span style="color:var(--color-prettylights-syntax-keyword)">as</span></span><span>np</span><span>inC</span>, <span>outC</span>, <span>batch</span><span><span style="color:var(--color-prettylights-syntax-constant)">=</span></span> ... <span><span style="color:var(--color-prettylights-syntax-comment)"># Define your own values</span></span><span><span style="color:var(--color-prettylights-syntax-comment)"># Create both inputs</span></span><span><span style="color:var(--color-prettylights-syntax-variable)">X1</span></span><span><span style="color:var(--color-prettylights-syntax-constant)">=</span></span><span>np</span>.<span>random</span>.<span><span style="color:var(--color-prettylights-syntax-entity)">uniform</span></span>(<span><span style="color:var(--color-prettylights-syntax-constant)">-</span></span><span><span style="color:var(--color-prettylights-syntax-constant)">1</span></span>, <span><span style="color:var(--color-prettylights-syntax-constant)">1</span></span>, (<span>batch</span>, <span>inC</span>)).<span><span style="color:var(--color-prettylights-syntax-entity)">astype</span></span>(<span>np</span>.<span>float16</span>) <span><span style="color:var(--color-prettylights-syntax-variable)">X2</span></span><span><span style="color:var(--color-prettylights-syntax-constant)">=</span></span><span>np</span>.<span>random</span>.<span><span style="color:var(--color-prettylights-syntax-entity)">uniform</span></span>(<span><span style="color:var(--color-prettylights-syntax-constant)">-</span></span><span><span style="color:var(--color-prettylights-syntax-constant)">1</span></span>, <span><span style="color:var(--color-prettylights-syntax-constant)">1</span></span>, (<span>outC</span>, <span>inC</span>)).<span><span style="color:var(--color-prettylights-syntax-entity)">astype</span></span>(<span>np</span>.<span>float16</span>) <span>mm</span><span><span style="color:var(--color-prettylights-syntax-constant)">=</span></span><span><span style="color:var(--color-prettylights-syntax-variable)">MatMul</span></span>(<span>inC</span>, <span>outC</span>, <span>batch</span>, <span>profile</span><span><span style="color:var(--color-prettylights-syntax-constant)">=</span></span><span><span style="color:var(--color-prettylights-syntax-constant)">False</span></span>) <span>result</span><span><span style="color:var(--color-prettylights-syntax-constant)">=</span></span><span>mm</span>.<span><span style="color:var(--color-prettylights-syntax-entity)">run</span></span>(<span><span style="color:var(--color-prettylights-syntax-variable)">X1</span></span>, <span><span style="color:var(--color-prettylights-syntax-variable)">X2</span></span>)</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></pre></div><p>更多詳情可查看<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fintel%2Fintel-npu-acceleration-library" target="_blank">此處</a>。</p></div>
                                    ]]>
            </description>
            <pubDate>Sun, 03 Mar 2024 03:56:49 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/281262/intel-npu-acceleration-library</guid>
            <link>https://www.oschina.net/news/281262/intel-npu-acceleration-library</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[深圳發佈政策支持鴻蒙原生應用發展]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>深圳市工業和信息化局、深圳市政務服務和數據管理局聯合印發《深圳市支持開源鴻蒙原生應用發展 2024 年行動計劃》。</p><p>《行動計劃》提出到 2024 年底，深圳市在鴻蒙原生應用發展上的具體目標包括：</p><ul><li>深圳企業開發的鴻蒙原生應用軟件數量佔全國總量 10% 以上。</li><li>深圳政務服務、教育醫療、銀行金融、交通運輸、生活保障、文旅體育等各類垂直領域實現鴻蒙原生應用軟件全覆蓋，滿足消費者"衣食住行、吃喝玩樂「應用軟件所需。</li><li>深圳主要高校和培訓機構開設鴻蒙原生應用軟件開發培訓課程，取得資質的鴻蒙開發者數量佔全國總量 15% 以上，擁有鴻蒙開發資質的軟件企業超千家。</li><li>建成 2 家以上以鴻蒙原生應用軟件開發、應用企業為主的專業產業園。探索設立鴻蒙產業基金，推動各類政策性基金將鴻蒙原生應用軟件企業作為投資重點之一。</li><li>推動鴻蒙生態創新中心穩健運營，提供鴻蒙原生應用展示推廣、人才培養等公共服務。全球智慧物聯網聯盟正式落地運營，持續擴大鴻蒙原生應用國際影響力。</li></ul><p><img alt="" height="750" src="https://oscimg.oschina.net/oscnet/up-b489842bf2e49bdfcb1aadfae520638c97a.jpg" width="300" referrerpolicy="no-referrer">&nbsp;</p><p><img alt="" height="1249" src="https://oscimg.oschina.net/oscnet/up-552fd10790b2141cc767dfed733cce7c781.jpg" width="300" referrerpolicy="no-referrer"></p><p><img alt="" height="545" src="https://oscimg.oschina.net/oscnet/up-a3cd687efbbd968e93b901b95c5278f9a97.jpg" width="300" referrerpolicy="no-referrer"></p><p><img alt="" height="483" src="https://oscimg.oschina.net/oscnet/up-f06d7c6d2e83e15138bcb91f2723cb2c4af.jpg" width="300" referrerpolicy="no-referrer"></p><p><img alt="" height="465" src="https://oscimg.oschina.net/oscnet/up-c6e7eb93d9c63bc96c5afe0dbe86d4d8819.jpg" width="300" referrerpolicy="no-referrer"></p><p><img alt="" height="693" src="https://oscimg.oschina.net/oscnet/up-f0ee8476d31f1230858b49eb45a45c70ff2.jpg" width="300" referrerpolicy="no-referrer"></p></div>
                                    ]]>
            </description>
            <pubDate>Sun, 03 Mar 2024 03:23:27 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/281254</guid>
            <link>https://www.oschina.net/news/281254</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[OpenChat —— D 語言 IM 套件]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>OpenChat&nbsp;<span>是一套完整的 IM 軟件平台，包含完整的服務器、客戶端。</span></p><p>服務器使用 D 語言編寫，通信協議使用了 msgtrans + protobuf 3.x ，內置 e2ee 加密。</p><p>IM 服務器分為 Gate / Msg / Logic 三個服務，下面是三個服務的解釋：</p><ol><li>Gate：顧名思義是網關服務，可以啓用多個網關，比如北京、上海、深圳我們都放一個網關，來提升用戶訪問的響應問題。</li><li>Msg：消息服務器，Msg 服務可以根據需求無限擴展，來提服務的併發能力。</li><li>Logic：這個是邏輯服務器，所有用戶關係、羣、紅包等功能都會在這個服務內完成，主要是操作消息隊列和數據庫。</li></ol><p>值得一提的是 OpenChat 配套了完整的 SDK 封裝，SDK 封裝使用了 C++11 語法，兼容了 iOS / Android / Windows /macOS/ Linux / FreeBSD 等主流平台。</p><p>目前支持的客戶端：</p><ol><li>iOS 客戶端採用 SwiftUI 開發</li><li>Android 客戶使用 Jetpack Compose 開發</li></ol></div>
                                                                ]]>
            </description>
            <pubDate>Sun, 03 Mar 2024 03:03:27 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/p/OpenChat</guid>
            <link>https://www.oschina.net/p/OpenChat</link>
        </item>
        <item>
            <title>
                <![CDATA[Gitee 推薦 | 使用 C# Blazor 編寫的 Kubernetes 管理工具 Blazor k8s]]>
            </title>
            <description>
                <![CDATA[<p><a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2Fweibaohui%2Fblazork8s%2Factions%2Fworkflows%2Fserver.yml"><img src="https://github.com/weibaohui/blazork8s/actions/workflows/BlazorApp.yml/badge.svg" alt="Build" referrerpolicy="no-referrer"></a></p><p align="center"><a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2Fweibaohui%2Fblazork8s"><img src="https://raw.githubusercontent.com/weibaohui/blazork8s/main/BlazorApp/wwwroot/pro_icon.svg" referrerpolicy="no-referrer"></a></p><h1 align="center"><a id="user-content--blazor-k8s-" class="anchor" href="https://gitee.com/weibaohui/blazork8s#-blazor-k8s-"></a> Blazor k8s </h1><p>使用 C# Blazor 編寫的 kubernetes 管理工具，集成了 ChatGPT 類大模型，用簡單易用的操作界面，提升 k8s 管理效率。
尤其適合新手入門使用，提供多種便捷功能方便初學者掌握 k8s 知識。</p><ul><li>多彩直觀顯示 k8s 資源</li><li>Yaml 定義字段按樹形展開分析，自帶文檔，且有可使用大模型進行翻譯。再也不用擔心記不住定義了。</li><li>詳細的 k8s 資源字段解釋，再也不用擔心不知道這個字段有幾個選項、都是什麼意思了。</li><li>官方示例集成，以目錄樹的形式呈現 k8s 官方示例，可以隨時瀏覽參考，複製字段了。</li><li>大模型生成 yaml</li><li>大模型問題分析</li><li>大模型安全檢測</li><li>資源用量動態展示（需安裝 metric server）</li><li>頁面功能集成 kubectl Describe、kubectl explain 等高頻命令，使用界面點擊即可查看。</li><li>集羣頁面增加巡檢功能，對主要資源對象的常見錯誤進行巡檢，並給出明細列表。</li></ul><h2><a id="user-content-️-授權協議" class="anchor" href="https://gitee.com/weibaohui/blazork8s#%EF%B8%8F-%E6%8E%88%E6%9D%83%E5%8D%8F%E8%AE%AE"></a>☀️ 授權協議</h2><p><a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2Fweibaohui%2Fblazork8s%2Fblob%2Fmaster%2FLICENSE"><img src="https://img.shields.io/badge/License-MIT-blue?style=flat-square" alt="BlazorK8s" referrerpolicy="no-referrer"></a></p><h1><a id="user-content-k8s-集羣安裝" class="anchor" href="https://gitee.com/weibaohui/blazork8s#k8s-%E9%9B%86%E7%BE%A4%E5%AE%89%E8%A3%85"></a>k8s 集羣安裝</h1><p>使用<a href="https://gitee.com/link?target=https%3A%2F%2Fkind.sigs.k8s.io%2Fdocs%2Fuser%2Fquick-start%2F">KinD</a>、<a href="https://gitee.com/link?target=https%3A%2F%2Fminikube.sigs.k8s.io%2Fdocs%2Fstart%2F">MiniKube</a>
安裝一個小型 k8s 集羣</p><h2><a id="user-content-kind 方式" class="anchor" href="https://gitee.com/weibaohui/blazork8s#kind%E6%96%B9%E5%BC%8F"></a>KinD 方式</h2><ul><li>創建 KinD Kubernetes 集羣</li></ul><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line">brew install kind</span></pre><div class="markdown-code-block-copy-btn"></div></div></div><ul><li>創建新的 Kubernetes 集羣：</li></ul><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line">kind create cluster --name k8sgpt-demo</span></pre><div class="markdown-code-block-copy-btn"></div></div></div><h1><a id="user-content-將 blazork8s-部署到集羣中體驗" class="anchor" href="https://gitee.com/weibaohui/blazork8s#%E5%B0%86blazork8s-%E9%83%A8%E7%BD%B2%E5%88%B0%E9%9B%86%E7%BE%A4%E4%B8%AD%E4%BD%93%E9%AA%8C"></a>將 blazorK8s 部署到集羣中體驗</h1><h2><a id="user-content-安裝腳本" class="anchor" href="https://gitee.com/weibaohui/blazork8s#%E5%AE%89%E8%A3%85%E8%84%9A%E6%9C%AC"></a>安裝腳本</h2><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line">kubectl apply -f https://raw.githubusercontent.com/weibaohui/blazork8s/main/deploy/deployment.yaml</span></pre><div class="markdown-code-block-copy-btn"></div></div></div><ul><li>訪問：
默認使用了 nodePort 開放，請訪問 31999 端口。或自行配置 Ingress
<a href="https://gitee.com/link?target=http%3A%2F%2F127.0.0.1%3A31999">http://NodePortIP:31999</a></li></ul><h1><a id="user-content-使用 docker 啓動鏡像進行體驗" class="anchor" href="https://gitee.com/weibaohui/blazork8s#%E4%BD%BF%E7%94%A8docker%E5%90%AF%E5%8A%A8%E9%95%9C%E5%83%8F%E8%BF%9B%E8%A1%8C%E4%BD%93%E9%AA%8C"></a>使用 docker 啓動鏡像進行體驗</h1><h2><a id="user-content-啓動服務" class="anchor" href="https://gitee.com/weibaohui/blazork8s#%E5%90%AF%E5%8A%A8%E6%9C%8D%E5%8A%A1"></a>啓動服務</h2><p>使用 docker-desktop 需要自行處理 apiserver 的訪問域名地址，請確保在 docker 內可訪問</p><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line">docker run -it --rm    -v ~/.kube/:/root/.kube/ -p 4000:8080 ghcr.io/weibaohui/blazork8s:0.1.1</span></pre><div class="markdown-code-block-copy-btn"></div></div></div><ul><li>訪問：<a href="https://gitee.com/link?target=http%3A%2F%2F127.0.0.1%3A4000">web ui</a></li></ul><h1><a id="user-content-源碼-debug-調試" class="anchor" href="https://gitee.com/weibaohui/blazork8s#%E6%BA%90%E7%A0%81-debug-%E8%B0%83%E8%AF%95"></a>源碼 DEBUG 調試</h1><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"> git clone git@github.com:weibaohui/blazork8s.git</span><span id="LC2" class="line"> cd blazork8s/BlazorApp</span><span id="LC3" class="line"> dotnet watch run</span></pre><div class="markdown-code-block-copy-btn"></div></div></div><h1><a id="user-content-大模型-配置" class="anchor" href="https://gitee.com/weibaohui/blazork8s#%E5%A4%A7%E6%A8%A1%E5%9E%8B-%E9%85%8D%E7%BD%AE"></a>大模型，配置</h1><ul><li>√ 阿里雲通義千問</li><li>√ 科大訊飛星火大模型</li><li>√ openAI</li><li>未完待續 (百度等模型...)</li></ul><p>修改源碼 BlazorApp 目錄下的 appsettings.json
或鏡像/app/目錄下的 appsettings.json</p><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line">  "AI": {</span><span id="LC2" class="line">    "Enable": true, //是否開啓</span><span id="LC3" class="line">    "Select": "QwenAI" //選擇哪一個大模型。可選阿里通義千問、科大訊飛星火大模型</span><span id="LC4" class="line">  },</span><span id="LC5" class="line">   "QwenAI": {</span><span id="LC6" class="line">    "APIKey": "sk-xxxxxxx7dd3494880a7920axxxxxxxxx",</span><span id="LC7" class="line">    "Prompt": {</span><span id="LC8" class="line">      "error": "簡明扼要地用 Kubernetes 專家的身份判斷一下這段輸出有什麼問題，要整齊列出問題對象和可能原因以及操作建議：",</span><span id="LC9" class="line">      "security": "簡明扼要地用 Kubernetes 安全專家的身份判斷一下這段輸出有什麼問題，要整齊列出問題對象和可能原因以及操作建議:"</span><span id="LC10" class="line">    }</span><span id="LC11" class="line">  },</span><span id="LC12" class="line">  "XunFeiAI": {</span><span id="LC13" class="line">    "APPID": "xxxxxx",</span><span id="LC14" class="line">    "APISecret": "XXXjYzgzY2E0ZTkwxxxxxxYxMDJkYTBl",</span><span id="LC15" class="line">    "APIKey": "xxxxxxx7dd3494880a7920axxxxxxxxx",</span><span id="LC16" class="line">    "Prompt": {</span><span id="LC17" class="line">      "error": "簡明扼要地用 Kubernetes 專家的身份判斷一下這段輸出有什麼問題，要整齊列出問題對象和可能原因以及操作建議：",</span><span id="LC18" class="line">      "security": "簡明扼要地用 Kubernetes 安全專家的身份判斷一下這段輸出有什麼問題，要整齊列出問題對象和可能原因以及操作建議:"</span><span id="LC19" class="line">    }</span><span id="LC20" class="line">  },</span></pre><div class="markdown-code-block-copy-btn"></div></div></div><h2><a id="user-content-大模型應用效果" class="anchor" href="https://gitee.com/weibaohui/blazork8s#%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8%E6%95%88%E6%9E%9C"></a>大模型應用效果</h2><h3><a id="user-content-doctree 樹狀展開 yaml 定義再也不用擔心記不住定義了" class="anchor" href="https://gitee.com/weibaohui/blazork8s#doctree%E6%A0%91%E7%8A%B6%E5%B1%95%E5%BC%80yaml%E5%AE%9A%E4%B9%89%E5%86%8D%E4%B9%9F%E4%B8%8D%E7%94%A8%E6%8B%85%E5%BF%83%E8%AE%B0%E4%B8%8D%E4%BD%8F%E5%AE%9A%E4%B9%89%E4%BA%86"></a>DocTree 樹狀展開 yaml 定義，再也不用擔心記不住定義了</h3><br><img src="https://raw.githubusercontent.com/weibaohui/blazork8s/main/docs/img/doc-tree.gif" referrerpolicy="no-referrer"><br><h3><a id="user-content-字段含義解釋" class="anchor" href="https://gitee.com/weibaohui/blazork8s#%E5%AD%97%E6%AE%B5%E5%90%AB%E4%B9%89%E8%A7%A3%E9%87%8A"></a>字段含義解釋</h3><h4><a id="user-content-點擊資源詳情頁面上字段前面的問號" class="anchor" href="https://gitee.com/weibaohui/blazork8s#%E7%82%B9%E5%87%BB%E8%B5%84%E6%BA%90%E8%AF%A6%E6%83%85%E9%A1%B5%E9%9D%A2%E4%B8%8A%E5%AD%97%E6%AE%B5%E5%89%8D%E9%9D%A2%E7%9A%84%E9%97%AE%E5%8F%B7"></a>點擊資源詳情頁面上，字段前面的問號</h4><ul><li>使用 kubectl 獲取 k8s 解釋</li><li>使用配置的 AI 大模型，進行智能解釋，效果如下：
<br><img src="https://raw.githubusercontent.com/weibaohui/blazork8s/main/docs/img/kubectl-explain.gif" referrerpolicy="no-referrer"><br></li></ul><h3><a id="user-content-生成部署 yaml" class="anchor" href="https://gitee.com/weibaohui/blazork8s#%E7%94%9F%E6%88%90%E9%83%A8%E7%BD%B2yaml"></a>生成部署 yaml</h3><br>
通過提示詞獲得 k8s 部署 yaml，並執行<br><img src="https://raw.githubusercontent.com/weibaohui/blazork8s/main/docs/img/gpt-deploy.gif" referrerpolicy="no-referrer"><br><h3><a id="user-content-智能分析" class="anchor" href="https://gitee.com/weibaohui/blazork8s#%E6%99%BA%E8%83%BD%E5%88%86%E6%9E%90"></a>智能分析</h3><p>在每一個資源上面都增加了智能分析、安全分析兩個按鈕。
<br><img src="https://raw.githubusercontent.com/weibaohui/blazork8s/main/docs/img/POD-analyze.gif" referrerpolicy="no-referrer"><br></p><h2><a id="user-content-巡檢支持資源情況" class="anchor" href="https://gitee.com/weibaohui/blazork8s#%E5%B7%A1%E6%A3%80%E6%94%AF%E6%8C%81%E8%B5%84%E6%BA%90%E6%83%85%E5%86%B5"></a>巡檢支持資源情況</h2><ul><li>Node</li><li>Pod</li><li>Deployment</li><li>StatefulSet</li><li>ReplicaSet</li><li>CronJob</li><li>Ingress</li><li>Service/Endpoints</li><li>PersistentVolumeClaim</li><li>NetworkPolicy</li><li>HorizontalPodAutoscaler
<br><img src="https://raw.githubusercontent.com/weibaohui/blazork8s/main/docs/img/cluster-inspection.png" referrerpolicy="no-referrer"><br></li></ul><h2><a id="user-content-頁面預覽" class="anchor" href="https://gitee.com/weibaohui/blazork8s#%E9%A1%B5%E9%9D%A2%E9%A2%84%E8%A7%88"></a>頁面預覽</h2><p><a href="https://gitee.com/weibaohui/blazork8s/blob/main/ui.md">click me</a></p>]]>
            </description>
            <pubDate>Sun, 03 Mar 2024 02:57:00 GMT</pubDate>
            <guid isPermaLink="false">https://gitee.com/weibaohui/blazork8s</guid>
            <link>https://gitee.com/weibaohui/blazork8s</link>
        </item>
        <item>
            <title>
                <![CDATA[什麼樣才算好圖 —— 從生圖模型質量度量方法看模型能力的發展]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div class="rich_media_content js_underline_content
                       autoTypeSetting24psection
            " id="js_content"><p data-mpa-powered-by="yiban.io"><img class="rich_pages wxw-img __bg_gif" data-backh="96" data-backw="578" data-cropselx1="0" data-cropselx2="578" data-cropsely1="0" data-cropsely2="96" data-imgfileid="503045966" data-ratio="0.16666666666666666" src="https://oscimg.oschina.net/oscnet/4c055b94-302c-409a-9335-80d972a686cb.gif" data-type="gif" data-w="636" style="font-size: var(--articleFontsize);color: rgb(34, 34, 34);font-family: system-ui, -apple-system, &quot;system-ui&quot;, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;outline: 0px;border-radius: 8px;width: 100%;visibility: visible !important;background-size: 16px !important;height: auto;" referrerpolicy="no-referrer"><br></p><section data-mpa-template="t" data-mpa-template-id="502" data-mpa-category="模板" style="outline: 0px;font-family: system-ui, -apple-system, &quot;system-ui&quot;, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;text-wrap: wrap;color: rgb(34, 34, 34);background-color: rgb(255, 255, 255);visibility: visible;"><section data-mpa-category="模板" data-mid="" style="padding-right: 1px;padding-left: 1px;outline: 0px;width: 677px;display: flex;justify-content: flex-start;align-items: center;flex-direction: column;visibility: visible;"><section data-mid="" style="outline: 0px;letter-spacing: 0.544px;width: 675px;display: grid;grid-template-columns: 26px auto;visibility: visible;"><section data-mid="" style="outline: 0px;width: 26px;height: 14px;display: flex;justify-content: center;align-items: center;align-self: center;visibility: visible;"><br style="outline: 0px;visibility: visible;"></section><section data-mid="" style="padding-left: 7px;outline: 0px;display: flex;justify-content: flex-start;align-items: center;visibility: visible;"><section data-mid="" style="margin-right: 7px;outline: 0px;text-align: left;visibility: visible;"><p data-mid="" style="outline: 0px;width: 0px;font-size: 14px;font-family: PingFangSC-Semibold, &quot;PingFang SC&quot;;font-weight: bold;color: rgb(58, 92, 244);line-height: 20px;visibility: visible;"><br style="outline: 0px;visibility: visible;"></p></section><section data-mid="" style="margin-bottom: 4px;outline: 0px;width: 635px;height: 1px;border-top: 1px solid rgb(58, 92, 244);align-self: flex-end;visibility: visible;"><br style="outline: 0px;visibility: visible;"></section></section></section><section data-mid="" style="padding: 7px 14px 9px 19px;outline: 0px;width: 675px;text-align: left;border-bottom: 1px solid rgb(58, 92, 244);visibility: visible;"><p style="margin-top: 8px;margin-bottom: 8px;line-height: 1.75em;"><span style="box-sizing: inherit;color: rgb(25, 27, 31);font-size: 15px;letter-spacing: 1px;">本文總結了近 10 年來的生圖模型論文中用到的評價指標，並嘗試解答兩個問題</span></p><ol class="list-paddingleft-1" style="width: 577.422px;"><li><p style="margin-top: 8px;margin-bottom: 8px;line-height: 1.75em;"><span style="box-sizing: inherit;color: rgb(25, 27, 31);font-size: 15px;letter-spacing: 1px;">不同時期的評價標準都有哪些特點？</span></p></li><li><p style="margin-top: 8px;margin-bottom: 8px;line-height: 1.75em;"><span style="box-sizing: inherit;color: rgb(25, 27, 31);font-size: 15px;letter-spacing: 1px;">圖片質量的評價如何輔助模型的迭代？</span><span style="color: rgb(0, 0, 0);font-family: &quot;zh quote&quot;, &quot;Helvetica Neue&quot;, -apple-system, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, STHeiti, Helvetica, Arial, sans-serif, &quot;Apple Color Emoji&quot;;font-size: 15px;letter-spacing: 1px;white-space-collapse: break-spaces;"></span></p></li></ol></section></section></section><section style="margin-top: 8px;margin-bottom: 8px;outline: 0px;font-family: system-ui, -apple-system, &quot;system-ui&quot;, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;text-wrap: wrap;background-color: rgb(255, 255, 255);line-height: 1.75em;visibility: visible;"><br style="outline: 0px;visibility: visible;"></section><section style="margin-bottom: 0px;outline: 0px;box-sizing: inherit;letter-spacing: 0.544px;text-wrap: wrap;background-color: rgb(255, 255, 255);color: rgba(25, 26, 31, 0.9);font-family: &quot;Helvetica Neue&quot;, Helvetica, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 16px;text-align: center;visibility: visible;line-height: 1.75em;"><span style="outline: 0px;visibility: visible;font-size: 15px;letter-spacing: 1px;"><img class="rich_pages wxw-img" data-imgfileid="503045963" data-ratio="0.3161764705882353" data-s="300,640" src="https://oscimg.oschina.net/oscnet/96781131-3581-4707-a2c1-235f86cc994b.png" data-type="png" data-w="408" style="outline: 0px;color: rgb(34, 34, 34);font-family: system-ui, -apple-system, system-ui, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;visibility: visible !important;width: 113px !important;" referrerpolicy="no-referrer"></span></section><section style="margin-bottom: 0px;outline: 0px;font-family: system-ui, -apple-system, &quot;system-ui&quot;, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;text-wrap: wrap;background-color: rgb(255, 255, 255);color: rgb(34, 34, 34);text-align: center;visibility: visible;line-height: normal;"><span style="outline: 0px;color: rgb(3, 69, 255);font-family: -apple-system, system-ui, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 18px;letter-spacing: 1px;visibility: visible;">前言</span></section><p style="margin-bottom: 8px;line-height: 1.75em;margin-top: 8px;"><span style="font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 15px;letter-spacing: 1px;"><br></span></p><p style="margin-bottom: 8px;line-height: 1.75em;margin-top: 8px;"><span style="box-sizing: inherit;color: rgb(25, 27, 31);font-size: 15px;letter-spacing: 1px;">隨着各種文生圖模型逐漸從 toy project 進入到生產鏈路，在線上實際落地併產生業務價值，同時自研/來源模型也進入了快速迭代的階段。</span></p><p style="margin-bottom: 8px;line-height: 1.75em;margin-top: 8px;"><span style="box-sizing: inherit;color: rgb(25, 27, 31);font-size: 15px;letter-spacing: 1px;"><br></span></p><p style="margin-bottom: 8px;line-height: 1.75em;margin-top: 8px;"><span style="box-sizing: inherit;color: rgb(25, 27, 31);font-size: 15px;letter-spacing: 1px;">一套直指問題、綜合拓展性和複用性的評價指標變得尤為寶貴，從效果上來講，如果説數據質量決定了模型效果的上限，那麼指標的好壞直接決定了模型下限的位置。</span></p><p style="margin-bottom: 8px;line-height: 1.75em;margin-top: 8px;"><span style="box-sizing: inherit;color: rgb(25, 27, 31);font-size: 15px;letter-spacing: 1px;"><br></span></p><p style="margin-bottom: 8px;line-height: 1.75em;margin-top: 8px;"><span style="box-sizing: inherit;color: rgb(25, 27, 31);font-size: 15px;letter-spacing: 1px;">2016 年以前圖像質量檢測主要是在構建各種手動特徵，最初圖片質量是作為一個二類問題，後來根據不同的對象/場景衍生出多了分類的問題，2016 年到 2019 年期間，GAN 方法生成的圖片越來越逼真，此時各家的指標更多的關注 GAN 生成圖像和樣本圖像之間的差異以及生成圖片的多樣性（mode collapse）。</span></p><p style="margin-bottom: 8px;line-height: 1.75em;margin-top: 8px;"><span style="box-sizing: inherit;color: rgb(25, 27, 31);font-size: 15px;letter-spacing: 1px;"><br></span></p><p style="margin-bottom: 8px;line-height: 1.75em;margin-top: 8px;"><span style="box-sizing: inherit;color: rgb(25, 27, 31);font-size: 15px;letter-spacing: 1px;">自 2020 年往後，transformor 火遍機器學習圈，同時多模態大模型能力也越來越強，在圖片美觀度、真實度這種抽象的指標的評價在 LLM 上又有比較好的表現，同時因為 zero-shot 和 few-shot 的特性，在一些自定義的指標上 LLM 可以快速響應，對於使用方來説，這種方式也是更友好的。</span></p><p style="margin-bottom: 8px;line-height: 1.75em;margin-top: 8px;"><br></p><section style="margin-bottom: 0px;outline: 0px;box-sizing: inherit;letter-spacing: 0.544px;text-wrap: wrap;background-color: rgb(255, 255, 255);color: rgba(25, 26, 31, 0.9);font-family: &quot;Helvetica Neue&quot;, Helvetica, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 16px;text-align: center;visibility: visible;line-height: normal;"><span style="outline: 0px;font-size: 15px;letter-spacing: 1px;visibility: visible;"><img class="rich_pages wxw-img" data-imgfileid="503045962" data-ratio="0.3056872037914692" data-s="300,640" src="https://oscimg.oschina.net/oscnet/acf4576c-9f7b-455b-a32e-8358aab3f6ba.png" data-type="png" data-w="422" style="outline: 0px;color: rgb(34, 34, 34);font-family: system-ui, -apple-system, system-ui, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;visibility: visible !important;width: 117px !important;" referrerpolicy="no-referrer"></span></section><section style="margin-bottom: 0px;outline: 0px;font-family: system-ui, -apple-system, &quot;system-ui&quot;, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;text-wrap: wrap;background-color: rgb(255, 255, 255);color: rgb(34, 34, 34);text-align: center;visibility: visible;line-height: normal;"><span style="outline: 0px;font-family: -apple-system, system-ui, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 18px;letter-spacing: 1px;visibility: visible;color: rgb(0, 17, 255);">2016 年以前</span></section><section style="margin-bottom: 0px;outline: 0px;font-family: system-ui, -apple-system, &quot;system-ui&quot;, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;text-wrap: wrap;background-color: rgb(255, 255, 255);color: rgb(34, 34, 34);text-align: justify;visibility: visible;line-height: normal;"><br></section><section style="margin-bottom: 8px;line-height: 1.75em;margin-top: 8px;"><span style="box-sizing: inherit;color: rgb(25, 27, 31);font-size: 15px;letter-spacing: 1px;">在深度特徵出現以前，傳統方法設計了設計大量的手動特徵特徵來研究計算機美學這個問題。常見做法是通過各種圖像變換產出不同的特徵並通過一個有監督的模型評價評價整體的圖片質量。</span></section><section style="margin-bottom: 8px;line-height: 1.75em;margin-top: 8px;"><span style="box-sizing: inherit;color: rgb(25, 27, 31);font-size: 15px;letter-spacing: 1px;"><br></span></section><span id="OSC_h4_1"></span><h4 data-lake-id="ca6fa186228ff7efaa653334195896c8" data-wording="true" style="margin-top: 8px;margin-bottom: 8px;outline: 0px;letter-spacing: 0.544px;text-wrap: wrap;color: rgb(34, 34, 34);background-color: rgb(255, 255, 255);font-family: -apple-system-font, system-ui, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;visibility: visible;line-height: 1.75em;"><span style="outline: 0px;visibility: visible;letter-spacing: 1px;color: rgb(0, 17, 255);"><strong style="outline: 0px;visibility: visible;"><span style="outline: 0px;font-family: Optima-Regular, PingFangTC-light;visibility: visible;">▐</span></strong><strong style="outline: 0px;visibility: visible;"><span style="outline: 0px;font-family: Optima-Regular, PingFangTC-light;visibility: visible;">&nbsp;&nbsp;</span></strong><strong style="outline: 0px;visibility: visible;"><span style="color: rgb(0, 17, 255);outline: 0px;font-family: Optima-Regular, PingFangTC-light;visibility: visible;">手動特徵方法</span></strong></span></h4><section style="line-height: 1.75em;margin-top: 8px;margin-bottom: 8px;"><br></section><ul class="list-paddingleft-1" style="list-style-type: disc;"><li style="color: rgb(0, 17, 255);"><span id="OSC_h3_2"></span><h3 data-cangjie-key="38" data-cangjie-leaf-block="true" data-type="heading-3" style="line-height: 1.75em;margin-top: 8px;margin-bottom: 8px;"><span style="box-sizing: inherit;font-size: 15px;letter-spacing: 1px;color: rgb(0, 17, 255);">主物體明確，背景不雜亂</span></h3></li></ul><section style="margin-bottom: 8px;"><span style="box-sizing: inherit;color: rgb(25, 27, 31);font-size: 15px;letter-spacing: 1px;"><br></span></section><section style="line-height: 1.75em;margin-top: 8px;margin-bottom: 8px;"><span style="box-sizing: inherit;color: rgb(25, 27, 31);font-size: 15px;letter-spacing: 1px;">一般來説我們希望圖片主題明確，輪廓清晰，如下圖左圖內容就是一個較為雜亂的室內場景，右圖明顯優於左圖，由於左圖背景雜亂，圖片邊界有較多的邊緣，而右圖的邊緣集中在圖片中心。</span></section><section style="line-height: 1.75em;margin-top: 8px;margin-bottom: 8px;"><span style="box-sizing: inherit;color: rgb(25, 27, 31);font-size: 15px;letter-spacing: 1px;"><br></span></section><section style="line-height: 1.75em;margin-top: 8px;margin-bottom: 8px;text-align: center;"><span style="box-sizing: inherit;color: rgb(25, 27, 31);font-size: 15px;letter-spacing: 1px;"><img class="rich_pages wxw-img" data-imgfileid="503045964" data-ratio="0.5345454545454545" src="https://oscimg.oschina.net/oscnet/397f6541-750a-49e3-8cff-5df250cab122.png" data-type="png" data-w="550" referrerpolicy="no-referrer"></span></section><p style="line-height: 1.75em;margin-top: 8px;margin-bottom: 8px;"><br></p><section style="margin-top: 8px;margin-bottom: 8px;line-height: 1.75em;"><span style="box-sizing: inherit;color: rgb(25, 27, 31);font-size: 15px;letter-spacing: 1px;">具體實現方法，通過一個 3*3 的拉普拉斯濾波器對每一層通道進行邊緣提取並取得均值，然後對整體 resize 到 100*100 的範圍，將圖片像素總和歸一化，並分別投影到 X 軸和 Y 軸，取</span><span style="font-size: 15px;letter-spacing: 1px;">邊緣 98% 作為邊框的大小（Wx，Wy），按照前文的假設，越雜亂的圖片邊緣像素點越多，最終圖片的邊框面積為 1-Wx*Wy，圖 a 和圖 b 的邊框面積分別為 0.94 和 0.56。</span></section><section style="margin-top: 8px;margin-bottom: 8px;line-height: 1.75em;"><br></section><ul class="list-paddingleft-1" style="list-style-type: disc;"><li style="color: rgb(0, 17, 255);"><span id="OSC_h3_3"></span><h3 data-cangjie-key="57" data-cangjie-leaf-block="true" data-type="heading-3" style="margin-top: 8px;margin-bottom: 8px;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;color: rgb(0, 17, 255);">色彩分佈</span></h3></li></ul><section style="margin-top: 8px;margin-bottom: 8px;line-height: 1.75em;"><br></section><section style="margin-top: 8px;margin-bottom: 8px;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;">統計圖片的色彩分佈，最直觀的就是顏色直方圖。好的照片，一般會有一個統一的風格。或偏暖色，或偏冷色，這些都可以通過彩色直方圖表徵出來。同時，局部直方圖的複雜程度，也可以反映出圖像風格的一致性。</span></section><h3 data-cangjie-key="63" data-cangjie-leaf-block="true" data-type="heading-3" style="margin-top: 8px;margin-bottom: 8px;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;"><br></span></h3><ul class="list-paddingleft-1" style="list-style-type: disc;"><li style="color: rgb(0, 17, 255);"><span id="OSC_h3_4"></span><h3 data-cangjie-key="63" data-cangjie-leaf-block="true" data-type="heading-3" style="margin-top: 8px;margin-bottom: 8px;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;color: rgb(0, 17, 255);">色調分析</span></h3></li></ul><section style="margin-top: 8px;margin-bottom: 8px;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;"><br></span></section><section style="margin-top: 8px;margin-bottom: 8px;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;">這是從色調的特性上來分享一張好圖。一張好的靜物攝影，色調一般會比較單一，不會五顏六色的各種顏色都雜糅在一起。</span></section><h3 data-cangjie-key="69" data-cangjie-leaf-block="true" data-type="heading-3" style="margin-top: 8px;margin-bottom: 8px;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;"><br></span></h3><ul class="list-paddingleft-1" style="list-style-type: disc;"><li style="color: rgb(0, 17, 255);"><span id="OSC_h3_5"></span><h3 data-cangjie-key="69" data-cangjie-leaf-block="true" data-type="heading-3" style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="font-size: 15px;letter-spacing: 1px;color: rgb(0, 17, 255);">模糊</span></h3></li></ul><section style="margin-bottom: 8px;"><span style="font-size: 15px;letter-spacing: 1px;"><br></span></section><section style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="font-size: 15px;letter-spacing: 1px;">一般來説一個模糊圖片的質量要比清晰圖片的質量更差的，假設一張模糊的圖片是經過用高斯平滑濾波器處理後的，那麼要在僅知道模糊圖片的情況下計算出平滑參數即可評估出圖片質量，這裏是通過一個二階傅立葉變化並計算大於某個閾值 a（這裏使用 5）的頻率數量來表示清晰圖片的最大頻率，自此我們評估出圖片質量的一個評分。如下，a 圖的質量分數為 0.91，b 圖為 0.58</span></section><section style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="font-size: 15px;letter-spacing: 1px;"><br></span></section><section style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;text-align: center;"><span style="font-size: 15px;letter-spacing: 1px;"><img class="rich_pages wxw-img" data-imgfileid="503045965" data-ratio="0.42804878048780487" src="https://oscimg.oschina.net/oscnet/aaeadee0-14e8-4f0a-9fcb-e5c192450098.png" data-type="png" data-w="820" referrerpolicy="no-referrer"></span></section><p style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><br></p><span id="OSC_h4_6"></span><h4 data-lake-id="ca6fa186228ff7efaa653334195896c8" data-wording="true" style="margin-top: 8px;margin-bottom: 8px;outline: 0px;letter-spacing: 0.544px;text-wrap: wrap;color: rgb(34, 34, 34);background-color: rgb(255, 255, 255);font-family: -apple-system-font, system-ui, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;visibility: visible;line-height: 1.75em;"><span style="outline: 0px;visibility: visible;letter-spacing: 1px;color: rgb(0, 17, 255);"><strong style="outline: 0px;visibility: visible;"><span style="outline: 0px;font-family: Optima-Regular, PingFangTC-light;visibility: visible;">▐</span></strong><strong style="outline: 0px;visibility: visible;"><span style="outline: 0px;font-family: Optima-Regular, PingFangTC-light;visibility: visible;">&nbsp;&nbsp;</span></strong><strong style="outline: 0px;visibility: visible;"><span style="color: rgb(0, 17, 255);outline: 0px;font-family: Optima-Regular, PingFangTC-light;visibility: visible;">深度特徵</span></strong></span></h4><h3 data-cangjie-key="88" data-cangjie-leaf-block="true" data-type="heading-3" style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><br></h3><ul class="list-paddingleft-1" style="list-style-type: disc;"><li style="color: rgb(0, 17, 255);"><span id="OSC_h3_7"></span><h3 data-cangjie-key="88" data-cangjie-leaf-block="true" data-type="heading-3" style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="font-size: 15px;letter-spacing: 1px;color: rgb(0, 17, 255);">RAPID: Rating Pictorial Aesthetics using Deep Learning (ACM MM2014)</span><span style="font-size: 15px;letter-spacing: 1px;"></span></h3></li></ul><p style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="font-size: 15px;letter-spacing: 1px;"><br></span></p><section style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="font-size: 15px;letter-spacing: 1px;">第一個使用深度學習做美學評分的論文了。作者考慮了在美學評估中要同時考慮整體佈局和細節內容。因此作者除了將圖片整體輸入模型，還會從圖片中摳出很多（patch）輸入網絡，兩者結合起來進行分類。其在圖片中摳取 patch 的方式在後續論文中都有借鑑。</span></section><section style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="font-size: 15px;letter-spacing: 1px;"><br></span></section><section style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="font-size: 15px;letter-spacing: 1px;"><img class="rich_pages wxw-img" data-imgfileid="503045970" data-ratio="0.37" src="https://oscimg.oschina.net/oscnet/ed40b841-b7ac-4972-9db4-4f3cade5facd.png" data-type="png" data-w="1000" referrerpolicy="no-referrer"></span></section><section style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><br></section><ul class="list-paddingleft-1" style="list-style-type: disc;"><li style="color: rgb(0, 17, 255);"><span id="OSC_h3_8"></span><h3 data-cangjie-key="107" data-cangjie-leaf-block="true" data-type="heading-3" style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="font-size: 15px;letter-spacing: 1px;color: rgb(0, 17, 255);">Composition-preserving Deep Photo Aesthetics Assessment (CVPR 2016)</span></h3></li></ul><p style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><br></p><section style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="font-size: 15px;letter-spacing: 1px;">由於 CNN 中必須將圖片 resize 到固定尺寸輸入到網絡，這種方式往往會破壞圖片的佈局，這種方法沒有使用 patch 的分割方法，提出了一種 Adaptive Spatial Pooling 的操作：動態地將不同 size 的 feature map 處理成指定的 size 大小，這個操作可以參考 SPPNet。結合多個 Adaptive Spatial Pooling 得到多個 size 的 feature map。同時這時期一些論文也證明瞭場景語意信息對美學評分會有提升，後續論文也陸續嘗試了將場景特徵加入到網絡中。</span></section><section style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="font-size: 15px;letter-spacing: 1px;"><br></span></section><section style="margin-top: 8px;line-height: 1.75em;text-align: center;margin-bottom: 8px;"><span style="font-size: 15px;letter-spacing: 1px;"><img class="rich_pages wxw-img" data-imgfileid="503045969" data-ratio="1.1943734015345269" src="https://oscimg.oschina.net/oscnet/6151558b-9b88-4da0-8ccf-fbc13907dc93.png" data-type="png" data-w="782" referrerpolicy="no-referrer"></span></section><section style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="font-size: 15px;letter-spacing: 1px;"><br></span></section><section style="margin-top: 8px;margin-bottom: 0px;outline: 0px;font-family: system-ui, -apple-system, &quot;system-ui&quot;, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;text-wrap: wrap;font-size: 15px;text-align: center;visibility: visible;color: rgb(34, 34, 34);background-color: rgb(255, 255, 255);line-height: 1.75em;"><img class="rich_pages wxw-img" data-imgfileid="503045967" data-ratio="0.3056872037914692" data-s="300,640" data-type="png" data-w="422" src="https://oscimg.oschina.net/oscnet/dc6e86fc-c3b1-4a5c-b787-ee0e0da59af5.png" style="outline: 0px;letter-spacing: 0.544px;font-size: 14px;visibility: visible !important;width: 117px !important;" referrerpolicy="no-referrer"></section><p style="margin-bottom: 0px;outline: 0px;font-family: system-ui, -apple-system, &quot;system-ui&quot;, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;text-wrap: wrap;font-size: 15px;text-align: center;background-color: rgb(255, 255, 255);color: rgb(100, 99, 99);line-height: normal;"><span style="outline: 0px;font-family: -apple-system, system-ui, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 18px;color: rgb(0, 17, 255);letter-spacing: 1px;">2016～2019</span></p><p style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><br></p><p style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="font-size: 15px;letter-spacing: 1px;">生成式對抗網絡 (Generative Adversarial Networks， GAN）自在 2014 年被 Ian Goodfellow 提出後，就在深度學習領域掀起了一場革命，GAN 主要分為兩部分：生成模型和判別模型。生成模型的作用是模擬真實數據的分佈，判別模型的作用是判斷一個樣本是真實的樣本還是生成的樣本，GAN 的目標是訓練一個生成模型完美的擬合真實數據分佈使得判別模型無法區分。從這裏我們可以看出來，GAN 的最終結果的好壞一定是要比較樣本集和生成集的差距，同時為了不讓最終的圖片過於單一，多樣性的指標也是要被考慮在內，又因為 GAN 本身是無監督的，一個好的評價方法（損失函數）直接會對結果造成影響。</span></p><p style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><br></p><span id="OSC_h4_9"></span><h4 data-lake-id="ca6fa186228ff7efaa653334195896c8" data-wording="true" style="margin-top: 0.5em;margin-bottom: 8px;outline: 0px;letter-spacing: 0.544px;text-wrap: wrap;color: rgb(34, 34, 34);background-color: rgb(255, 255, 255);font-family: -apple-system-font, system-ui, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;visibility: visible;line-height: 1.75em;"><span style="outline: 0px;visibility: visible;letter-spacing: 1px;color: rgb(0, 17, 255);"><strong style="outline: 0px;visibility: visible;"><span style="outline: 0px;font-family: Optima-Regular, PingFangTC-light;visibility: visible;">▐</span></strong><strong style="outline: 0px;visibility: visible;"><span style="outline: 0px;font-family: Optima-Regular, PingFangTC-light;visibility: visible;">&nbsp;&nbsp;</span></strong><strong style="outline: 0px;visibility: visible;"><span style="color: rgb(0, 17, 255);outline: 0px;font-family: Optima-Regular, PingFangTC-light;visibility: visible;">Inception Score（IS）</span></strong></span></h4><section style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><br></section><ul class="list-paddingleft-1" style="list-style-type: disc;"><li style="color: rgb(0, 17, 255);"><span id="OSC_h4_10"></span><h4 data-cangjie-key="135" data-cangjie-leaf-block="true" data-type="heading-4" style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="font-size: 15px;letter-spacing: 1px;color: rgb(0, 17, 255);">方法</span></h4></li></ul><p style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><br></p><p style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="font-size: 15px;letter-spacing: 1px;">Inception Score（IS）FID 中使用了 Inception-v3，這個網絡最初由 google 在 2014 年提出，用於 ImageNet 上的圖片分類，輸入一個圖片，輸出一個 1000 維的 tensor 代表輸出類別，在 GAN 生成數據中常用來評價數據的多樣性和數據的質量。</span></p><p style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="font-size: 15px;letter-spacing: 1px;"><br></span></p><p style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="font-size: 15px;letter-spacing: 1px;">假定 x 為生成的圖像，y 為生成的圖片的判別器的分類結果在 IS 中即為一個 1000 類別的分類，那麼圖片的質量越高則判別器的分類結果越穩定（屬於某一個類別的概率越高），即 P(y|x) 的熵越小。</span></p><p style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="font-size: 15px;letter-spacing: 1px;"><br></span></p><p style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="font-size: 15px;letter-spacing: 1px;">在此基礎上，從一個圖片集合的角度考慮，如果圖片是多種多樣的，那麼他們涵蓋的類目數也應該是儘可能多的，即 P(y) 的熵應該越大越好。</span></p><section style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><br></section><section style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="font-size: 15px;letter-spacing: 1px;">由於我們要最小化 P(y|x) 的熵：</span></section><section style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;text-align: center;"><span style="font-size: 15px;letter-spacing: 1px;"><img class="rich_pages wxw-img" data-imgfileid="503045971" data-ratio="0.17785234899328858" src="https://oscimg.oschina.net/oscnet/cc6eaf66-c7cc-4f35-8d07-a3a8dc85d6b1.png" data-type="png" data-w="596" style="width: 324px;height: 58px;" referrerpolicy="no-referrer"></span></section><section style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><br></section><section style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;text-align: justify;"><span style="font-size: 15px;letter-spacing: 1px;">最大化 P(y) 的熵：</span></section><section style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;text-align: center;"><span style="font-size: 15px;letter-spacing: 1px;"><img class="rich_pages wxw-img" data-imgfileid="503045968" data-ratio="0.14847161572052403" src="https://oscimg.oschina.net/oscnet/0cbde8d7-0b1d-4be3-bd31-4fffa3801d53.png" data-type="png" data-w="458" style="width: 341px;height: 51px;" referrerpolicy="no-referrer"></span></section><p style="line-height: 1.75em;margin-top: 8px;margin-bottom: 8px;"><br></p><p style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;text-align: justify;"><span style="font-size: 15px;letter-spacing: 1px;">説到衡量兩個概率分佈的距離的方式，那就是 KL 散度了，</span><span style="font-size: 15px;letter-spacing: 1px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;">KL 散度的一般形式如下：</span></p><p style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;text-align: center;"><span style="font-size: 15px;letter-spacing: 1px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;"><img class="rich_pages wxw-img" data-imgfileid="503045973" data-ratio="0.20696324951644102" src="https://oscimg.oschina.net/oscnet/d5f10fb8-a07c-4c15-9331-edb0cfd04717.png" data-type="png" data-w="1034" style="width: 355px;height: 73px;" referrerpolicy="no-referrer"></span></p><p style="line-height: 1.75em;margin-top: 8px;margin-bottom: 8px;"><br></p><p style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;text-align: justify;"><span style="font-size: 15px;letter-spacing: 1px;">由於實際中，選取大量生成樣本，用經驗分佈模擬 p(y)：</span></p><p style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;text-align: center;"><span style="font-size: 15px;letter-spacing: 1px;"><img class="rich_pages wxw-img" data-imgfileid="503045974" data-ratio="0.30848329048843187" src="https://oscimg.oschina.net/oscnet/a6379fa5-a36a-487d-afdf-e42deaf8897e.png" data-type="png" data-w="778" style="width: 364px;height: 112px;" referrerpolicy="no-referrer"></span></p><p style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;text-align: justify;"><br></p><p style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;text-align: justify;"><span style="font-size: 15px;letter-spacing: 1px;">最終得到的 IS 計算公式為：</span></p><p style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;text-align: center;"><span style="font-size: 15px;letter-spacing: 1px;"><img class="rich_pages wxw-img" data-imgfileid="503045975" data-ratio="0.10826210826210826" src="https://oscimg.oschina.net/oscnet/25708f8b-984e-454e-a3b3-83fe3fc2116b.png" data-type="png" data-w="702" style="width: 362px;height: 39px;" referrerpolicy="no-referrer"></span></p><p style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;text-align: justify;"><br></p><p style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;text-align: justify;"><span style="font-size: 15px;letter-spacing: 1px;">其實還是</span>求 P(y|x) 和 P(y) 的 KL 散度套了一個 exp，並不影響最終的單調性。</p><p style="text-align: justify;margin-top: 8px;margin-bottom: 8px;line-height: 1.75em;"><br></p><ul class="list-paddingleft-1" style="list-style-type: disc;"><li style="color: rgb(0, 17, 255);"><span id="OSC_h4_11"></span><h4 data-cangjie-key="191" data-cangjie-leaf-block="true" data-type="heading-4" style="text-align: justify;margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="font-size: 15px;letter-spacing: 1px;color: rgb(0, 17, 255);">侷限性</span></h4><h4 data-cangjie-key="191" data-cangjie-leaf-block="true" data-type="heading-4" style="text-align: justify;margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><br></h4></li></ul><ol class="list-paddingleft-1" style="list-style-type: decimal;"><li><section style="text-align: justify;margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="font-size: 15px;letter-spacing: 1px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;">當一個圖片的類目本身並不確定，或者在原數據集中並沒有出現過，那麼此時的 p(y|x) 的概率密度就不再是一個尖鋭的分佈，而是趨於平緩，</span></section></li><li><section style="text-align: justify;margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="font-size: 15px;letter-spacing: 1px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;">不能判別出網絡是否過擬合，當 GAN 生成數據和訓練集完全相同時，會得到極高的 IS 分數，但是這種模型毫無作用。</span></section></li><li><section style="text-align: justify;margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 15px;letter-spacing: 1px;">如果某一個物體的類別本身就比較模糊，在幾種類別會得到相近的分數，或者這個物體類別在 ImageNet 中不存在，那麼 p(y|x) 的概率密度就不再是一個尖鋭的分佈；如果生成模型在每類上都生成了 50 個圖片，那麼生成的圖片的類別邊緣分佈是嚴格均勻分佈的，按照 Inception Score 的假設，這種模型不存在 mode collapse，但是，如果各類中的 50 個圖片，都是一模一樣的，仍然是 mode collapse（相同模式大量出現）。Inception Score 無法檢測這種同類目下的重複出圖的情況。</span><br></section></li></ol><h4 data-cangjie-key="203" data-cangjie-leaf-block="true" data-type="heading-4" style="text-align: justify;margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><br></h4><ul class="list-paddingleft-1" style="list-style-type: disc;"><li style="color: rgb(0, 17, 255);"><span id="OSC_h4_12"></span><h4 data-cangjie-key="203" data-cangjie-leaf-block="true" data-type="heading-4" style="text-align: justify;margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="font-size: 15px;letter-spacing: 1px;color: rgb(0, 17, 255);">總結</span></h4></li></ul><section style="margin-bottom: 8px;"><span style="font-size: 15px;letter-spacing: 1px;"><br></span></section><section style="text-align: justify;margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="font-size: 15px;letter-spacing: 1px;">綜上，Inception Score 可以表現出數據的多樣性和質量，適用於分類模型和生成模型數據集相近的情況，但是存在數值受內部權重影響較大和不能區分過擬合情況的問題，雖然在論文中非常常見，但是實際上生產使用的模型數據集會持續迭代，因此這個指標用於模型自身的迭代還是不夠穩定。另外從文生圖模型的角度來看，這個指標也無法表現模型對文本的響應程度。</span></section><p style="text-align: justify;margin-top: 8px;margin-bottom: 8px;line-height: 1.75em;"><br></p><span id="OSC_h4_13"></span><h4 data-lake-id="ca6fa186228ff7efaa653334195896c8" data-wording="true" style="margin-top: 0.5em;margin-bottom: 8px;outline: 0px;letter-spacing: 0.544px;text-wrap: wrap;color: rgb(34, 34, 34);background-color: rgb(255, 255, 255);font-family: -apple-system-font, system-ui, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;visibility: visible;line-height: 1.75em;"><span style="outline: 0px;visibility: visible;letter-spacing: 1px;color: rgb(0, 17, 255);"><strong style="outline: 0px;visibility: visible;"><span style="outline: 0px;font-family: Optima-Regular, PingFangTC-light;visibility: visible;">▐</span></strong><strong style="outline: 0px;visibility: visible;"><span style="outline: 0px;font-family: Optima-Regular, PingFangTC-light;visibility: visible;">&nbsp;&nbsp;</span></strong><strong style="outline: 0px;visibility: visible;"><span style="color: rgb(0, 17, 255);outline: 0px;font-family: Optima-Regular, PingFangTC-light;visibility: visible;">Fidelity (FID)</span></strong></span></h4><p style="text-align: justify;margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><br></p><ul class="list-paddingleft-1" style="list-style-type: disc;"><li style="color: rgb(0, 17, 255);"><span id="OSC_h4_14"></span><h4 data-cangjie-key="212" data-cangjie-leaf-block="true" data-type="heading-4" style="text-align: justify;margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="font-size: 15px;letter-spacing: 1px;color: rgb(0, 17, 255);">方法</span></h4></li></ul><p style="text-align: justify;margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><br></p><p style="text-align: justify;margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="font-size: 15px;letter-spacing: 1px;">FID（Frechet Inception Distance）是 GAN 等定量評價指標之一，最早提出於 2017 年，由於 IS 在 ImageNet 上的侷限性，當生成的數據樣本超出 ImageNet 的範圍時，該圖片的效果是不好的，因此 FID 中使用的是生成數據分佈和真實世界數據分佈之間的距離，和 Inception Score 一樣，FID 也使用了 Inception-v3 模型，而 FID 並沒有直接使用 Inception-v3 的分類結果，而是獲取了最後一個池化層用於提取圖片特徵，通過計算兩組圖像（生成圖像和真實圖像）的均值和協方差，將激活函數的輸出歸納為一個多變量高斯分佈。然後將這些統計量用於計算真實圖像和生成圖像集合中的 Frechet 距離。同時因為 Frechet 距離關注的是多維空間中移動一個分佈到另一個分佈所需的「工作」量，所以對於不在 ImageNet 中，圖片差距較大的情況下也可以有比較好的泛化能力。原文見</span><span style="box-sizing: inherit;cursor: pointer;background-color: transparent;font-size: 15px;letter-spacing: 1px;color: rgb(0, 128, 255) !important;">https://arxiv.org/abs/1706.08500</span></p><p style="text-align: justify;margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><br></p><p style="text-align: center;margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><img class="rich_pages wxw-img" data-imgfileid="503045976" data-ratio="0.41686746987951806" src="https://oscimg.oschina.net/oscnet/49b894d1-c74d-4439-be45-453b327de89f.png" data-type="png" data-w="830" referrerpolicy="no-referrer"></p><p style="text-align: center;margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="letter-spacing: 1px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 12px;color: rgb(136, 136, 136);">Frechet 距離的幾何含義</span><br></p><p style="text-align: justify;margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><br></p><ul class="list-paddingleft-1" style="list-style-type: disc;"><li style="color: rgb(0, 17, 255);"><span id="OSC_h4_15"></span><h4 data-cangjie-key="235" data-cangjie-leaf-block="true" data-type="heading-4" style="text-align: justify;margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="font-size: 15px;letter-spacing: 1px;color: rgb(0, 17, 255);">侷限性</span></h4></li></ul><p style="text-align: justify;margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="font-size: 15px;letter-spacing: 1px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;"><br></span></p><ol class="list-paddingleft-1" style="list-style-type: decimal;"><li><p style="text-align: justify;margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="font-size: 15px;letter-spacing: 1px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;">FID 和 IS 一樣，依賴於現有特徵的出現或不出現，即無法判斷到生成的圖片中產生的一些異常結構（頭上出現一張嘴），這種情況 FID 也會認為是一張好圖。</span></p></li><li><p style="text-align: justify;margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="font-size: 15px;letter-spacing: 1px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;">同 IS，FID 無法區分過擬合等。</span></p></li><li><p style="text-align: justify;margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="font-size: 15px;letter-spacing: 1px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;">FID 中假設了激活函數的輸出（2048 維度的 Inception 特徵）是符合高斯分佈的，但實際上這在 ReLU 之後的結果恆為正數，所以在 FID 的計算方式下不存在無偏的評估指標。</span></p></li></ol><h4 data-cangjie-key="247" data-cangjie-leaf-block="true" data-type="heading-4" style="text-align: justify;margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><br></h4><ul class="list-paddingleft-1" style="list-style-type: disc;"><li style="color: rgb(0, 17, 255);"><span id="OSC_h4_16"></span><h4 data-cangjie-key="247" data-cangjie-leaf-block="true" data-type="heading-4" style="text-align: justify;margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="font-size: 15px;letter-spacing: 1px;color: rgb(0, 17, 255);">結論</span></h4></li></ul><h4 data-cangjie-key="247" data-cangjie-leaf-block="true" data-type="heading-4" style="text-align: justify;margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><br></h4><span id="OSC_h4_17"></span><h4 data-cangjie-key="247" data-cangjie-leaf-block="true" data-type="heading-4" style="text-align: justify;margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="letter-spacing: 1px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 15px;">相較於 IS，FID 更專注於對於圖片真實性的評價，在樣本集之外的數據中也有比較好的效果，在 mode collapsing 問題上也適用，適合用作 IS 之外的補充，作者也證明 FID 優於 IS，因為它對圖像中的細微變化更敏感，即高斯模糊、高斯模糊、椒鹽噪聲。FID 使用 Inception 網絡將生成圖像集合和真實圖像集合轉換為保留圖像高維信息的特徵向量。假設這兩個特徵向量的分佈為高斯分佈，並計算其均值和協方差矩陣。通過測量概率分佈之間的「距離」（相似程度）來評估生成圖像與真實圖像的相似程度。值越小，質量越高。</span></h4><p style="text-align: justify;margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="font-size: 15px;letter-spacing: 1px;">﻿</span></p><span id="OSC_h4_18"></span><h4 data-lake-id="ca6fa186228ff7efaa653334195896c8" data-wording="true" style="margin-top: 0.5em;margin-bottom: 8px;outline: 0px;letter-spacing: 0.544px;text-wrap: wrap;color: rgb(34, 34, 34);background-color: rgb(255, 255, 255);font-family: -apple-system-font, system-ui, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;visibility: visible;line-height: 1.75em;"><span style="outline: 0px;visibility: visible;letter-spacing: 1px;color: rgb(0, 17, 255);"><strong style="outline: 0px;visibility: visible;"><span style="outline: 0px;font-family: Optima-Regular, PingFangTC-light;visibility: visible;">▐</span></strong><strong style="outline: 0px;visibility: visible;"><span style="outline: 0px;font-family: Optima-Regular, PingFangTC-light;visibility: visible;">&nbsp;&nbsp;</span></strong><strong style="outline: 0px;visibility: visible;"><span style="color: rgb(0, 17, 255);outline: 0px;font-family: Optima-Regular, PingFangTC-light;visibility: visible;">Kernel Inception Distance（KID）</span></strong></span></h4><h4 data-lake-id="ca6fa186228ff7efaa653334195896c8" data-wording="true" style="margin-top: 0.5em;margin-bottom: 8px;outline: 0px;letter-spacing: 0.544px;text-wrap: wrap;color: rgb(34, 34, 34);background-color: rgb(255, 255, 255);font-family: -apple-system-font, system-ui, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;visibility: visible;line-height: 1.75em;"></h4><p style="text-align: justify;margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><br></p><p style="text-align: justify;margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="letter-spacing: 1px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 15px;">論文：https://openreview.net/pdf?id=r1lUOzWCW</span></p><p style="text-align: justify;margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><br></p><ul class="list-paddingleft-1" style="list-style-type: disc;"><li style="color: rgb(0, 17, 255);"><span id="OSC_h4_19"></span><h4 data-cangjie-key="266" data-cangjie-leaf-block="true" data-type="heading-4" style="text-align: justify;margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="letter-spacing: 1px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 15px;color: rgb(0, 17, 255);">方法</span></h4></li></ul><p style="text-align: justify;margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><br></p><p style="text-align: justify;margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="letter-spacing: 1px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 15px;">按照作者的描述，KID 沒有像 FID 那樣的正態分佈的假設，是一種無偏的估計。不同的是將圖像的 2048 維 Inception 特徵通過 maximum mean discrepancy（MMD）的方法分別求兩個分佈不同樣本在映射空間中的值，用於度量兩個分佈之間的距離。通過比較生成樣本和真實樣本之間的距離來評價圖片生成的效果。</span></p><p style="text-align: justify;margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="letter-spacing: 1px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 15px;"><br></span></p><p style="text-align: justify;margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="letter-spacing: 1px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 15px;">MMD 是遷移學習中最常見的損失函數之一，MMD 在設計之初重新考慮了對一個隨機變量的表現形式，對於簡單的方式我們可以給出一個概率分佈函數，像正態分佈函數，只要給出均值+方差就可以確定其分佈，像高斯分佈等，如果兩個分佈的均值和方差如果相同的話，這兩個分佈應該比較接近，但對於一些高階的、複雜的隨機變量，我們就沒有辦法給出其分佈函數，也需要更高階的參數（矩）描述一個分佈。</span></p><p style="text-align: justify;margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="letter-spacing: 1px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 15px;"><br></span></p><p style="text-align: justify;margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="letter-spacing: 1px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 15px;">論文《A Hilbert Space Embedding for Distributions》提出了一個高斯核函數，它對應的映射函數恰好可以映射到無窮維上，映射到無窮維上再求期望，正好可以得到隨機變量的高階矩。簡單理解就是將一個分佈映射到再生希爾伯特空間（RKHS）（每個核函數都對應一個 RKHS）上的一個點，兩個分佈之間的距離就可以用兩個點的內積進行表示。至此我們獲得了一個隨機變量的任意階矩的表示。</span></p><p style="text-align: justify;margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><br></p><p style="text-align: center;margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><img class="rich_pages wxw-img" data-imgfileid="503045972" data-ratio="0.5738125802310655" src="https://oscimg.oschina.net/oscnet/5f7d30ed-43bb-4c28-8259-23f6c8bbebe9.png" data-type="png" data-w="779" referrerpolicy="no-referrer"></p><p style="text-align: center;margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="color: rgb(176, 171, 172);font-family: &quot;zh quote&quot;, &quot;Helvetica Neue&quot;, -apple-system, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, STHeiti, Helvetica, Arial, sans-serif, &quot;Apple Color Emoji&quot;;font-size: 13.3333px;letter-spacing: normal;text-align: left;text-indent: 32px;white-space: break-spaces;background-color: rgb(255, 255, 255);">當兩個紅點和藍點在二維空間時，我們很難把他們分開，當映射到多維空間後事情就很容易了</span></p><p style="text-align: justify;margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><br></p><p style="text-align: justify;margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="letter-spacing: 1px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 15px;">這種方法相比於 FLD 可以小數據集上更快達到穩定的效果。同時因為 KID 有一個三次核的無偏估計值，它更一致地匹配人類的感知。</span></p><p style="text-align: justify;margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="letter-spacing: 1px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 15px;"><br></span></p><p style="text-align: center;margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="letter-spacing: 1px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 15px;"><img class="rich_pages wxw-img" data-backh="142" data-backw="578" data-imgfileid="503045977" data-ratio="0.2462962962962963" src="https://oscimg.oschina.net/oscnet/c3802c4a-8314-4634-9d43-65dc034fdec0.png" data-type="png" data-w="1080" style="width: 100%;height: auto;" referrerpolicy="no-referrer"></span></p><p style="text-align: justify;margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><br></p><ul class="list-paddingleft-1" style="list-style-type: disc;"><li style="color: rgb(0, 17, 255);"><span id="OSC_h4_20"></span><h4 data-cangjie-key="304" data-cangjie-leaf-block="true" data-type="heading-4" style="text-align: justify;margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="letter-spacing: 1px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 15px;color: rgb(0, 17, 255);">結論</span></h4></li></ul><p style="text-align: justify;margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><br></p><p style="text-align: justify;margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="letter-spacing: 1px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 15px;">對比 FID，KID 是無偏的，FID 是有偏的，在時間效率上，FID 為 O(n)，KID 為 O(n^2)</span></p><p style="text-align: justify;margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="letter-spacing: 1px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 15px;">﻿</span></p><span id="OSC_h4_21"></span><h4 data-lake-id="ca6fa186228ff7efaa653334195896c8" data-wording="true" style="margin-top: 0.5em;margin-bottom: 8px;outline: 0px;letter-spacing: 0.544px;text-wrap: wrap;color: rgb(34, 34, 34);background-color: rgb(255, 255, 255);font-family: -apple-system-font, system-ui, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;visibility: visible;line-height: 1.75em;"><span style="outline: 0px;visibility: visible;letter-spacing: 1px;color: rgb(0, 17, 255);"><strong style="outline: 0px;visibility: visible;"><span style="outline: 0px;font-family: Optima-Regular, PingFangTC-light;visibility: visible;">▐</span></strong><strong style="outline: 0px;visibility: visible;"><span style="outline: 0px;font-family: Optima-Regular, PingFangTC-light;visibility: visible;">&nbsp;&nbsp;</span></strong><strong style="outline: 0px;visibility: visible;"><span style="color: rgb(0, 17, 255);outline: 0px;font-family: Optima-Regular, PingFangTC-light;visibility: visible;">Learned Perceptual Image Patch Similarity（LPIPS）</span></strong></span></h4><p style="text-align: justify;margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><br></p><p style="text-align: justify;margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="letter-spacing: 1px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 15px;">LPIPS 在 2018 年提出，是一種基於深度方法提取圖片比較兩幅圖片相似度的方法，相比於傳統使用的 L2、SSIM 等方法，LPIPS 方法嘗試解決在判斷相似度時更符合人類的感知。如下圖：</span></p><p style="text-align: center;margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="letter-spacing: 1px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 15px;"><img class="rich_pages wxw-img" data-imgfileid="503045978" data-ratio="0.24351851851851852" src="https://oscimg.oschina.net/oscnet/cc6aefae-12be-4ba7-9873-11f414b29c57.png" data-type="png" data-w="1080" referrerpolicy="no-referrer"></span></p><section style="text-align: justify;margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><br></section><p style="text-align: justify;margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="letter-spacing: 1px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 15px;">實際上，兩張圖片是否相似，這是一個比較主觀的結果，從人類判斷的角度上來看，甚至可能受到視覺上下文的影響，該方法嘗試不使用人工的判斷來訓練一個貼近人類感官的相似度的概念。從前文來看，通過深層網絡的內部激活（即便是在圖片分類任務上訓練的）在更廣泛的數據集也是可以適用的，也更符合人類的判斷。</span></p><p style="text-align: justify;margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="letter-spacing: 1px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 15px;"><br></span></p><p style="text-align: justify;margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="letter-spacing: 1px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 15px;">相比於 FID，LPIPS 也是利用深度卷積網絡的內部激活，不同的是，LPIPS 衡量的是感知相似性，而不是質量評估。</span></p><section style="text-align: justify;margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="letter-spacing: 1px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 15px;"><br></span></section><section style="text-align: center;margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="letter-spacing: 1px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 15px;"><img class="rich_pages wxw-img" data-imgfileid="503045979" data-ratio="0.3333333333333333" src="https://oscimg.oschina.net/oscnet/cd7fc82f-33cb-45ad-ac7b-ed479110ff09.png" data-type="png" data-w="1080" referrerpolicy="no-referrer"></span></section><section style="text-align: justify;margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><br></section><span id="OSC_h4_22"></span><h4 data-lake-id="ca6fa186228ff7efaa653334195896c8" data-wording="true" style="margin-top: 0.5em;margin-bottom: 8px;outline: 0px;letter-spacing: 0.544px;text-wrap: wrap;color: rgb(34, 34, 34);background-color: rgb(255, 255, 255);font-family: -apple-system-font, system-ui, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;visibility: visible;line-height: 1.75em;"><span style="outline: 0px;visibility: visible;letter-spacing: 1px;color: rgb(0, 17, 255);"><strong style="outline: 0px;visibility: visible;"><span style="outline: 0px;font-family: Optima-Regular, PingFangTC-light;visibility: visible;">▐</span></strong><strong style="outline: 0px;visibility: visible;"><span style="outline: 0px;font-family: Optima-Regular, PingFangTC-light;visibility: visible;">&nbsp;&nbsp;</span></strong><strong style="outline: 0px;visibility: visible;"><span style="color: rgb(0, 17, 255);outline: 0px;font-family: Optima-Regular, PingFangTC-light;visibility: visible;">總結</span></strong></span></h4><p style="text-align: justify;margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><br></p><p style="text-align: justify;margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="letter-spacing: 1px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 15px;">2016 到 2019 期間，各家學者對生成圖片度量的方法持續優化，基本上還是聚焦在「什麼樣的圖片更貼近真實」，直到 2018 年，圖片的真實性達到的一定水平，LPIPS 提出對於圖片的評價不僅侷限於」有多真實「，同時關注到怎麼樣讓圖片效果更貼近人類的感官。</span></p><p style="text-align: justify;margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="letter-spacing: 1px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 15px;"><br></span></p><section style="margin-bottom: 0px;outline: 0px;font-family: system-ui, -apple-system, &quot;system-ui&quot;, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;text-wrap: wrap;color: rgb(34, 34, 34);font-size: 15px;background-color: rgb(255, 255, 255);text-align: center;line-height: normal;"><img class="rich_pages wxw-img" data-imgfileid="503045980" data-ratio="0.328125" data-s="300,640" src="https://oscimg.oschina.net/oscnet/913b76d2-43d2-4b11-b696-5cb1afc5f70d.png" data-type="png" data-w="256" style="outline: 0px;letter-spacing: 0.544px;font-size: 16px;visibility: visible !important;width: 122px !important;" referrerpolicy="no-referrer"></section><section style="margin-bottom: 0px;outline: 0px;font-family: system-ui, -apple-system, &quot;system-ui&quot;, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;text-wrap: wrap;font-size: 15px;background-color: rgb(255, 255, 255);color: rgb(100, 99, 99);text-align: center;line-height: normal;"><span style="outline: 0px;color: rgb(0, 17, 255);font-family: -apple-system, system-ui, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 18px;letter-spacing: 1px;">2020 往後</span></section><section style="text-align: justify;margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><br style="outline: 0px;font-family: system-ui, -apple-system, &quot;system-ui&quot;, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;text-wrap: wrap;background-color: rgb(255, 255, 255);"></section><section style="text-align: justify;margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="letter-spacing: 1px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 15px;">Transformer 由谷歌團隊在 2017 年論文《Attention is All You Need》提出，DDPM 的 UNet 可以根據當前採樣的 t 預測 noise，但沒有引入其他額外條件。但是 LDM 實現了「以文生圖」，「以圖生圖」等任務，就是因為 LDM 在預測 noise 的過程中加入了條件機制，即通過一個編碼器（encoder）將條件和 Unet 連接起來。一方面，圖片生成的效果在這段時間大幅度提高，另一方面，可以通過自然語言控制生圖模型的輸出，模型的評價指標除了符合人類感官外，圖像美學和圖文對的匹配程度也是後期評價生圖結果的重要指標。</span></section><section style="text-align: justify;margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><br></section><span id="OSC_h4_23"></span><h4 data-lake-id="ca6fa186228ff7efaa653334195896c8" data-wording="true" style="margin-top: 0.5em;margin-bottom: 8px;outline: 0px;letter-spacing: 0.544px;text-wrap: wrap;color: rgb(34, 34, 34);background-color: rgb(255, 255, 255);font-family: -apple-system-font, system-ui, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;visibility: visible;line-height: 1.75em;"><span style="outline: 0px;visibility: visible;letter-spacing: 1px;color: rgb(0, 17, 255);"><strong style="outline: 0px;visibility: visible;"><span style="outline: 0px;font-family: Optima-Regular, PingFangTC-light;visibility: visible;">▐</span></strong><strong style="outline: 0px;visibility: visible;"><span style="outline: 0px;font-family: Optima-Regular, PingFangTC-light;visibility: visible;">&nbsp;&nbsp;</span></strong><strong style="outline: 0px;visibility: visible;"><span style="color: rgb(0, 17, 255);outline: 0px;font-family: Optima-Regular, PingFangTC-light;visibility: visible;">Transformer for image quality（TRIQ）</span></strong></span></h4><p style="text-align: justify;margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><br></p><p style="text-align: justify;margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="letter-spacing: 1px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 15px;">這是第一個使用 Transformer 架構用於圖片質量評價的模型，推出自 2020 年，主要思想是先使用卷積神經網絡（CNN）提取特徵，並在其上方使用了一個淺層 Transformer 編碼器。為了處理不同分辨率的圖像，該架構採用了自適應的位置嵌入。考慮到壓縮圖片的分辨率可能對圖片質量校驗造成負向的影響，TRIQ 框架中保留了圖片的原始大小，首先通過 ResNet-50 作為特徵提取器，C5 的輸出在經過 1*1 的卷積之後可以得到 H/32*W/32*32 維的特徵，考慮到大分辨率的圖片會佔用非常多的內存，這裏在進入 Transformer 之前增加了一個池化層，會通過圖片分辨率動態確定一個 P 值。</span></p><p style="text-align: justify;margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="letter-spacing: 1px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 15px;"><br></span></p><p style="text-align: justify;margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="letter-spacing: 1px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 15px;">Transformer Encoder 後的 MLP 網絡頭部由兩個全連接（FC）層和一箇中間的 dropout 層組成，用於預測感知圖像質量，最終輸出一個五維向量用於表述圖片的質量分佈。</span></p><p style="text-align: justify;margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="letter-spacing: 1px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 15px;"><br></span></p><p style="text-align: justify;margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="letter-spacing: 1px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 15px;"><img class="rich_pages wxw-img" data-imgfileid="503045981" data-ratio="0.41759259259259257" src="https://oscimg.oschina.net/oscnet/6a742e67-7ffd-45b1-b745-cead008ad0ad.png" data-type="png" data-w="1080" referrerpolicy="no-referrer"></span></p><p style="text-align: justify;margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="letter-spacing: 1px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 15px;">code：https://github.com/junyongyou/triq</span></p><p style="text-align: justify;margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><br></p><span id="OSC_h4_24"></span><h4 data-lake-id="ca6fa186228ff7efaa653334195896c8" data-wording="true" style="margin-top: 0.5em;margin-bottom: 8px;outline: 0px;letter-spacing: 0.544px;text-wrap: wrap;color: rgb(34, 34, 34);background-color: rgb(255, 255, 255);font-family: -apple-system-font, system-ui, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;visibility: visible;line-height: 1.75em;"><span style="outline: 0px;visibility: visible;letter-spacing: 1px;color: rgb(0, 17, 255);"><strong style="outline: 0px;visibility: visible;"><span style="outline: 0px;font-family: Optima-Regular, PingFangTC-light;visibility: visible;">▐</span></strong><strong style="outline: 0px;visibility: visible;"><span style="outline: 0px;font-family: Optima-Regular, PingFangTC-light;visibility: visible;">&nbsp;&nbsp;</span></strong><strong style="outline: 0px;visibility: visible;"><span style="color: rgb(0, 17, 255);outline: 0px;font-family: Optima-Regular, PingFangTC-light;visibility: visible;">Image Quality Transformer（IQT）</span></strong></span></h4><p style="text-align: justify;margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><br></p><p style="text-align: justify;margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="letter-spacing: 1px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 15px;">IQT 方法提出於 2021 年，參考了 TRIQ 的方法，也是是一種基於 transformer 的圖像質量評估（IQT），模型的輸出結果更接近人類的感知結果，用於全參考圖像質量評估，類似於 LPIPS。作者宣稱在 CVPR 2021 的 NTIRE 2021 挑戰賽中獲得 Top1。如下圖作者利用 Inception-Resnet-V2 分別對生成圖片和參考圖片的提取感知特徵表徵，感知特徵表徵結果來自於 6 箇中間層的輸出並通過級聯的結果，將參考圖的特徵向量（f ref），和參考圖與生成圖的特徵向量取差值（f diff）並輸入到 Transformer；最後，transformer 的輸出通過一個 MLP Head，用於預測一個最終的圖像質量分數。</span></p><p style="text-align: justify;margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="letter-spacing: 1px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 15px;"><br></span></p><p style="text-align: center;margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="letter-spacing: 1px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 15px;"><img class="rich_pages wxw-img" data-imgfileid="503045982" data-ratio="0.5694444444444444" src="https://oscimg.oschina.net/oscnet/c338b412-e22e-41d5-b414-08ead9254428.png" data-type="png" data-w="1080" referrerpolicy="no-referrer"></span></p><p style="text-align: justify;margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><br></p><span id="OSC_h4_25"></span><h4 data-lake-id="ca6fa186228ff7efaa653334195896c8" data-wording="true" style="margin-top: 0.5em;margin-bottom: 8px;text-wrap: wrap;outline: 0px;letter-spacing: 0.544px;color: rgb(34, 34, 34);background-color: rgb(255, 255, 255);font-family: -apple-system-font, system-ui, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;visibility: visible;line-height: 1.75em;"><span style="outline: 0px;visibility: visible;letter-spacing: 1px;color: rgb(0, 17, 255);"><strong style="outline: 0px;visibility: visible;"><span style="outline: 0px;font-family: Optima-Regular, PingFangTC-light;visibility: visible;">▐</span></strong><strong style="outline: 0px;visibility: visible;"><span style="outline: 0px;font-family: Optima-Regular, PingFangTC-light;visibility: visible;">&nbsp;&nbsp;</span></strong><strong style="outline: 0px;visibility: visible;"><span style="color: rgb(0, 17, 255);outline: 0px;font-family: Optima-Regular, PingFangTC-light;visibility: visible;">CLIPScore</span></strong></span></h4><p style="text-align: justify;margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><br></p><p style="text-align: justify;margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="letter-spacing: 1px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 15px;">提出於 2021 年，這是一種用於評價文本和圖片關聯程度的方法，原理比較簡單，通過一個跨模態檢索模型分別對圖像和文本進行 embeding，並比較兩者的餘弦相似度。公式如下：</span></p><p style="text-align: center;margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="letter-spacing: 1px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 15px;"><img class="rich_pages wxw-img" data-imgfileid="503045983" data-ratio="0.12406947890818859" src="https://oscimg.oschina.net/oscnet/7b2adfb3-d436-4e05-a062-aae071906e63.png" data-type="png" data-w="806" style="width: 394px;height: 49px;" referrerpolicy="no-referrer"></span></p><p style="text-align: justify;margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><br></p><p style="text-align: justify;margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="letter-spacing: 1px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 15px;">其中，c 和 v 是 CLIP 編碼器對 Caption 和圖像處理輸出的 embedding，w 作者設置為 2.5。這個公式不需要額外的模型推理運算，運算速度很快，作者稱在消費級 GPU 上，1 分鐘可以處理 4k 張圖像-文本對。</span></p><p style="text-align: justify;margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><br></p><span id="OSC_h4_26"></span><h4 data-lake-id="ca6fa186228ff7efaa653334195896c8" data-wording="true" style="margin-top: 0.5em;margin-bottom: 8px;outline: 0px;letter-spacing: 0.544px;text-wrap: wrap;color: rgb(34, 34, 34);background-color: rgb(255, 255, 255);font-family: -apple-system-font, system-ui, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;visibility: visible;line-height: 1.75em;"><span style="outline: 0px;visibility: visible;letter-spacing: 1px;color: rgb(0, 17, 255);"><strong style="outline: 0px;visibility: visible;"><span style="outline: 0px;font-family: Optima-Regular, PingFangTC-light;visibility: visible;">▐</span></strong><strong style="outline: 0px;visibility: visible;"><span style="outline: 0px;font-family: Optima-Regular, PingFangTC-light;visibility: visible;">&nbsp;&nbsp;</span></strong><strong style="outline: 0px;visibility: visible;"><span style="color: rgb(0, 17, 255);outline: 0px;font-family: Optima-Regular, PingFangTC-light;visibility: visible;">Aesthetic Predictor</span></strong></span></h4><p style="text-align: justify;margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><br></p><p style="text-align: justify;margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="letter-spacing: 1px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 15px;">目前自 2022 年之後，出現了基於 CLIP+MLP 的美學評價方案，創作者都表示「結果令人興奮」，從大模型的能力可以 YY 到其在小樣本的泛化性上必然非同凡響，同時可以衍生到不同的評價目標上，但是具體對比之前的方案怎麼樣就不得而知了。</span></p><p style="text-align: justify;margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><br></p><ul class="list-paddingleft-1" style="list-style-type: disc;"><li style="color: rgb(0, 17, 255);"><span id="OSC_h3_27"></span><h3 data-cangjie-key="418" data-cangjie-leaf-block="true" data-type="heading-3" style="text-align: justify;margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="letter-spacing: 1px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 15px;color: rgb(0, 17, 255);">LAION-AESTHETICS</span><span style="letter-spacing: 1px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 15px;"></span></h3></li></ul><p style="text-align: justify;margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><br></p><p style="text-align: justify;margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="letter-spacing: 1px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 15px;">laion 在 2022 年提出的一個用於評估圖片的美學評價模型，使用了 clip-ViT-L-14 模型和 MLP 組合，僅模型開源。</span></p><p style="text-align: justify;margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="letter-spacing: 1px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 15px;">官網：https://laion.ai/blog/laion-aesthetics/﻿</span></p><p style="text-align: left;margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="letter-spacing: 1px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 15px;">結果見：http://captions.christoph-schuhmann.de/aesthetic_viz_laion_sac+logos+ava1-l14-linearMSE-en-2.37B.html</span></p><h3 data-cangjie-key="434" data-cangjie-leaf-block="true" data-type="heading-3" style="text-align: justify;margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><br></h3><ul class="list-paddingleft-1" style="list-style-type: disc;"><li style="color: rgb(0, 17, 255);"><span id="OSC_h3_28"></span><h3 data-cangjie-key="434" data-cangjie-leaf-block="true" data-type="heading-3" style="text-align: justify;margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="letter-spacing: 1px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 15px;color: rgb(0, 17, 255);">CLIP+MLP Aesthetic Score Predictor</span><span style="letter-spacing: 1px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 15px;"></span></h3></li></ul><p style="text-align: justify;margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><br></p><p style="text-align: left;margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="letter-spacing: 1px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 15px;">代碼：https://github.com/christophschuhmann/improved-aesthetic-predictor﻿</span></p><p><br></p><span id="OSC_h4_29"></span><h4 data-lake-id="ca6fa186228ff7efaa653334195896c8" data-wording="true" style="margin-top: 0.5em;margin-bottom: 8px;outline: 0px;letter-spacing: 0.544px;text-wrap: wrap;color: rgb(34, 34, 34);background-color: rgb(255, 255, 255);font-family: -apple-system-font, system-ui, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;visibility: visible;line-height: 1.75em;"><span style="outline: 0px;visibility: visible;letter-spacing: 1px;color: rgb(0, 17, 255);"><strong style="outline: 0px;visibility: visible;"><span style="outline: 0px;font-family: Optima-Regular, PingFangTC-light;visibility: visible;">▐</span></strong><strong style="outline: 0px;visibility: visible;"><span style="outline: 0px;font-family: Optima-Regular, PingFangTC-light;visibility: visible;">&nbsp;&nbsp;</span></strong><strong style="outline: 0px;visibility: visible;"><span style="color: rgb(0, 17, 255);outline: 0px;font-family: Optima-Regular, PingFangTC-light;visibility: visible;">Human Preference Score</span></strong></span></h4><p><br></p><p style="text-align: justify;margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="letter-spacing: 1px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 15px;">2023 往後，出現了用於預測圖片是否符合人類偏好模型，這類模型多使用人工標註的圖文偏好數據微調 CLIP 實現。</span></p><h3 data-cangjie-key="453" data-cangjie-leaf-block="true" data-type="heading-3" style="text-align: justify;margin-bottom: 8px;margin-top: 8px;line-height: 1.75em;"><br></h3><ul class="list-paddingleft-1" style="list-style-type: disc;"><li style="color: rgb(0, 17, 255);"><span id="OSC_h3_30"></span><h3 data-cangjie-key="453" data-cangjie-leaf-block="true" data-type="heading-3" style="text-align: justify;margin-bottom: 8px;margin-top: 8px;line-height: 1.75em;"><span style="font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 15px;letter-spacing: 1px;color: rgb(0, 17, 255);">ImageReward</span><span style="font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 15px;letter-spacing: 1px;"></span></h3></li></ul><section style="margin-bottom: 8px;margin-top: 8px;line-height: 1.75em;"><span style="font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 15px;letter-spacing: 1px;"><br></span></section><section style="text-align: justify;margin-bottom: 8px;margin-top: 8px;line-height: 1.75em;"><span style="font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 15px;letter-spacing: 1px;">為了做，文生圖 Diffusion 的獎勵反饋學習對 Diffusion 進行調優，作者設計了 ImageReward，一個由 BLIP（ViT-L 作為圖像編碼器的，12 層 Transformer 作為文本編碼器）+ MLP（打分器）組成的人類偏好預測模型。</span></section><h3 data-cangjie-key="459" data-cangjie-leaf-block="true" data-type="heading-3" style="text-align: justify;margin-bottom: 8px;margin-top: 8px;line-height: 1.75em;"><br></h3><ul class="list-paddingleft-1" style="list-style-type: disc;"><li style="color: rgb(0, 17, 255);"><span id="OSC_h3_31"></span><h3 data-cangjie-key="459" data-cangjie-leaf-block="true" data-type="heading-3" style="text-align: justify;margin-bottom: 8px;margin-top: 8px;line-height: 1.75em;"><span style="font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 15px;letter-spacing: 1px;color: rgb(0, 17, 255);">Human Preference Score (HPS)</span><span style="font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 15px;letter-spacing: 1px;"></span></h3></li></ul><section style="margin-bottom: 8px;margin-top: 8px;line-height: 1.75em;"><span style="font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 15px;letter-spacing: 1px;"><br></span></section><section style="text-align: justify;margin-bottom: 8px;margin-top: 8px;line-height: 1.75em;"><span style="font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 15px;letter-spacing: 1px;">商湯在 CLIP 模型上基於 798,090 條人類偏好標註數據微調了這個模型，標註的圖片來源於各類文生圖模型的輸出，據稱其數據集是同類型數據集中最大的一個。其將 clip 模型視為一個評分器，用於計算提示詞和圖片的相關程度（同 clipscore）。</span></section><section style="text-align: justify;margin-bottom: 8px;margin-top: 8px;line-height: 1.75em;"><span style="letter-spacing: 1px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 15px;">code: https://github.com/tgxs002/HPSv2﻿</span></section><h3 data-cangjie-key="472" data-cangjie-leaf-block="true" data-type="heading-3" style="text-align: justify;margin-bottom: 8px;margin-top: 8px;line-height: 1.75em;"><br></h3><ul class="list-paddingleft-1" style="list-style-type: disc;"><li style="color: rgb(0, 17, 255);"><span id="OSC_h3_32"></span><h3 data-cangjie-key="472" data-cangjie-leaf-block="true" data-type="heading-3" style="text-align: justify;margin-bottom: 8px;margin-top: 8px;line-height: 1.75em;"><span style="font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 15px;letter-spacing: 1px;color: rgb(0, 17, 255);">X-IQE</span><span style="font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 15px;letter-spacing: 1px;"></span></h3></li></ul><section style="text-align: justify;margin-bottom: 8px;margin-top: 8px;line-height: 1.75em;"><span style="font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 15px;letter-spacing: 1px;"><br></span></section><section style="text-align: justify;margin-bottom: 8px;margin-top: 8px;line-height: 1.75em;"><span style="font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 15px;letter-spacing: 1px;">基於視覺大語言模型（MiniGPT-4）進行文本到圖像生成的可解釋圖像質量評估，它從 Fidelity（真實度），Alignment（圖文對應程度），Aesthetics（美觀度）三個指標分別進行評分。從 COCO 和 DrawBench 數據集的測試結果上看，和 ImgRwd 和 HPS 接近。</span><span style="letter-spacing: 1px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 15px;"></span></section><section style="text-align: justify;margin-bottom: 8px;margin-top: 8px;line-height: 1.75em;"><span style="font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 15px;letter-spacing: 1px;"><br></span></section><section style="text-align: center;margin-bottom: 8px;margin-top: 8px;line-height: 1.75em;"><span style="font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 15px;letter-spacing: 1px;"><img class="rich_pages wxw-img" data-backh="174" data-backw="578" data-imgfileid="503045984" data-ratio="0.30185185185185187" src="https://oscimg.oschina.net/oscnet/57b95c4b-34cd-4f43-802d-81363746f258.png" data-type="png" data-w="1080" style="width: 100%;height: auto;" referrerpolicy="no-referrer"></span></section><section style="text-align: left;margin-bottom: 8px;margin-top: 8px;line-height: 1.75em;"><br></section><section style="text-align: left;margin-bottom: 8px;margin-top: 8px;line-height: 1.75em;"><span style="font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 15px;letter-spacing: 1px;">主要的 prompt 見：</span><span style="font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 15px;letter-spacing: 1px;">https://github.com/Schuture/Benchmarking-Awesome-Diffusion-Models/blob/main/X-IQE/README.md</span></section><section style="text-align: justify;margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><br></section><p style="margin-bottom: 0px;outline: 0px;text-wrap: wrap;background-color: rgb(255, 255, 255);font-size: 11pt;font-family: DengXian;color: rgb(0, 0, 0);letter-spacing: normal;text-align: center;line-height: normal;"><img class="rich_pages wxw-img" data-imgfileid="503045985" data-ratio="0.328125" data-s="300,640" src="https://oscimg.oschina.net/oscnet/caac0c01-7116-4895-9dd2-1ca4f772bb75.png" data-type="png" data-w="256" style="outline: 0px;font-size: 14.6667px;color: rgb(34, 34, 34);font-family: system-ui, -apple-system, &quot;system-ui&quot;, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;visibility: visible !important;width: 133px !important;" referrerpolicy="no-referrer"></p><p style="margin-bottom: 0px;outline: 0px;font-family: system-ui, -apple-system, &quot;system-ui&quot;, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;text-wrap: wrap;background-color: rgb(255, 255, 255);line-height: 1.75em;text-align: center;"><span style="outline: 0px;box-sizing: inherit;color: rgb(0, 17, 255);font-family: -apple-system, system-ui, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 18px;letter-spacing: 1px;">總結</span></p><p style="text-align: justify;margin-bottom: 8px;margin-top: 8px;line-height: 1.75em;"><br></p><p style="text-align: justify;margin-bottom: 8px;margin-top: 8px;line-height: 1.75em;"><span style="font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 15px;letter-spacing: 1px;">從計算方法上看，似乎沒有前一個時期那麼精彩，通過微調 CLIP 再套用一個 MLP 幾乎成為了這個時期的評價範式，但是評價指標要遠比前一個時期更抽象和複雜。但這並不意味着</span><span style="font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 15px;letter-spacing: 1px;">FID 這類指標已經沒用了，相反，這個指標幾乎在每個新模型的發佈後都會拿出來比較。</span></p><p style="text-align: justify;margin-bottom: 8px;margin-top: 8px;line-height: 1.75em;"><br></p><section style="text-align: justify;margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 15px;letter-spacing: 1px;">本來只是想梳理一下圖像質量度量的方法，但是層層挖掘卻越可以看出圖片生成模型的發展歷程，從最初的，圖像基礎變換到人臉、動物，到現在可控制的圖像生成，圖片生成技術越來越趨於專業性，我們審視一張圖片的方式從「能看懂」到 「像真的」到「符合美學標準「，可以想到未來一套美學標準是無法通吃的，對於不同行業和場景，生圖模型會越來越細分，而美學標準也會隨之分化。</span></section><section style="text-align: justify;margin-bottom: 8px;"><br></section><section style="margin-bottom: 0px;outline: 0px;font-family: system-ui, -apple-system, &quot;system-ui&quot;, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;text-wrap: wrap;color: rgb(34, 34, 34);background-color: rgb(255, 255, 255);text-align: center;line-height: normal;"><img class="rich_pages wxw-img" data-imgfileid="503045986" data-ratio="0.328125" data-s="300,640" src="https://oscimg.oschina.net/oscnet/d6fdf110-b15f-45b2-8259-582dafd2e86a.png" data-type="png" data-w="256" style="outline: 0px;color: rgb(51, 51, 51);font-size: 20px;font-weight: bold;letter-spacing: 0.578px;visibility: visible !important;width: 134px !important;" referrerpolicy="no-referrer"></section><section style="margin-bottom: 0px;outline: 0px;font-family: system-ui, -apple-system, &quot;system-ui&quot;, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;text-wrap: wrap;background-color: rgb(255, 255, 255);color: rgb(100, 99, 99);font-size: 15px;text-align: center;line-height: normal;"><span style="outline: 0px;font-family: -apple-system, system-ui, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 1px;font-size: 18px;color: rgb(0, 17, 255);">參考資料</span></section><section style="text-align: justify;margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 15px;letter-spacing: 1px;">﻿</span></section><ol class="list-paddingleft-1" style="list-style-type: decimal;"><li><p style="text-align: justify;margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 15px;letter-spacing: 1px;">Heusel, Martin et al. 「GANs Trained by a Two Time-Scale Update Rule Converge to a Nash Equilibrium.」 ArXiv abs/1706.08500 (2017): n. pag.</span></p></li><li><p style="text-align: justify;margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 15px;letter-spacing: 1px;">﻿https://www.jiqizhixin.com/articles/2019-01-10-18﻿</span></p></li><li><p style="text-align: justify;margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 15px;letter-spacing: 1px;">Dziugaite, Gintare Karolina et al. 「Training generative neural networks via Maximum Mean Discrepancy optimization.」 Conference on Uncertainty in Artificial Intelligence (2015).</span></p></li><li><p style="text-align: justify;margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 15px;letter-spacing: 1px;">Binkowski, Mikolaj et al. 「Demystifying MMD GANs.」 ArXiv abs/1801.01401 (2018): n. pag.</span></p></li><li><p style="text-align: justify;margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 15px;letter-spacing: 1px;">﻿https://www.jiqizhixin.com/articles/2019-01-10-18﻿</span></p></li><li><p style="text-align: justify;margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 15px;letter-spacing: 1px;">﻿https://laion.ai/blog/laion-aesthetics/﻿</span></p></li><li><p style="text-align: justify;margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 15px;letter-spacing: 1px;">﻿https://www.jianshu.com/p/fc5526b1fe3b#comments﻿</span></p></li><li><p style="text-align: justify;margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 15px;letter-spacing: 1px;">﻿https://deep-generative-models.github.io/files/ppt/2021/Lecture%2019%20Evaluation%20-%20Sampling%20Quality.pdf﻿</span></p></li><li><p style="text-align: justify;margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 15px;letter-spacing: 1px;">Zhang, Richard et al. 「The Unreasonable Effectiveness of Deep Features as a Perceptual Metric.」 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition (2018): 586-595.</span></p></li><li><p style="text-align: justify;margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 15px;letter-spacing: 1px;">You, Junyong and Jari Korhonen. 「Transformer For Image Quality Assessment.」 2021 IEEE International Conference on Image Processing (ICIP) (2020): 1389-1393.</span></p></li><li><p style="text-align: justify;margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 15px;letter-spacing: 1px;">Cheon, Manri et al. 「Perceptual Image Quality Assessment with Transformers.」 2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW) (2021): 433-442.</span></p></li><li><p style="text-align: justify;margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 15px;letter-spacing: 1px;">Hessel, Jack et al. 「CLIPScore: A Reference-free Evaluation Metric for Image Captioning.」 ArXiv abs/2104.08718 (2021): n. pag.</span></p></li><li><p style="text-align: justify;margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 15px;letter-spacing: 1px;">Wu, Xiaoshi et al. 「Human Preference Score v2: A Solid Benchmark for Evaluating Human Preferences of Text-to-Image Synthesis.」 ArXiv abs/2306.09341 (2023): n. pag.</span></p></li><li><p style="text-align: justify;margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 15px;letter-spacing: 1px;">﻿https://www.e-learn.cn/topic/1480759</span></p></li></ol><p style="text-align: justify;margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><br></p><section style="margin-bottom: 0px;outline: 0px;font-family: system-ui, -apple-system, &quot;system-ui&quot;, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;text-wrap: wrap;background-color: rgb(255, 255, 255);text-align: center;line-height: normal;"><span style="outline: 0px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 15px;letter-spacing: 1px;"><img class="rich_pages wxw-img" data-imgfileid="503046025" data-ratio="0.328125" data-s="300,640" data-type="png" data-w="256" src="https://oscimg.oschina.net/oscnet/74a6de11-4550-496a-a5c9-cf1f18d5b320.png" style="outline: 0px;color: rgb(34, 34, 34);font-family: system-ui, -apple-system, &quot;system-ui&quot;, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;text-align: center;text-wrap: wrap;visibility: visible !important;width: 136px !important;" referrerpolicy="no-referrer"></span></section><section style="margin-bottom: 0px;outline: 0px;font-family: system-ui, -apple-system, &quot;system-ui&quot;, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;text-wrap: wrap;background-color: rgb(255, 255, 255);color: rgb(100, 99, 99);font-size: 15px;text-align: center;line-height: normal;"><span style="outline: 0px;font-family: -apple-system, system-ui, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 18px;color: rgb(0, 17, 255);letter-spacing: 1px;">團隊介紹</span></section><section style="text-align: justify;margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><br style="outline: 0px;font-family: system-ui, -apple-system, &quot;system-ui&quot;, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;text-wrap: wrap;background-color: rgb(255, 255, 255);"></section><section style="text-align: justify;margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 15px;letter-spacing: 1px;">我們是淘天集團-場景智能技術團隊，一支專注於通過 AI 和 3D 技術驅動商業創新的技術團隊, 依託淘寶天貓豐富的業務形態和海量的用戶、數據, 致力於為消費者提供創新的場景化導購體驗, 為商家提供高效的場景化內容創作工具, 為淘寶天貓打造圍繞家的場景的第一消費入口。我們不斷探索並實踐新的技術, 通過持續的技術創新和突破，創新用戶導購體驗, 提升商家內容生產力, 讓用戶享受更好的消費體驗, 讓商家更高效、低成本地經營。</span></section><p><br></p><section data-role="outer" label="Powered by 135editor.com" style="margin-bottom: 0px;outline: 0px;letter-spacing: 0.544px;visibility: visible;"><section style="margin-top: 5px;margin-bottom: 8px;outline: 0px;letter-spacing: 0.544px;font-size: 16px;word-break: break-all;color: rgb(0, 0, 0);font-family: Optima-Regular, Optima, PingFangSC-light, PingFangTC-light, &quot;PingFang SC&quot;, Cambria, Cochin, Georgia, Times, &quot;Times New Roman&quot;, serif;text-align: center;line-height: 1.75em;"><span style="outline: 0px;color: rgb(0, 17, 255);"><strong style="outline: 0px;">¤</strong></span><span style="outline: 0px;"><strong style="outline: 0px;">&nbsp;拓展閲讀&nbsp;</strong></span><span style="outline: 0px;color: rgb(0, 17, 255);"><strong style="outline: 0px;">¤</strong></span></section><section style="margin-top: 5px;margin-bottom: 5px;outline: 0px;letter-spacing: 0.544px;font-size: 16px;word-break: break-all;color: rgb(0, 0, 0);font-family: Optima-Regular, Optima, PingFangSC-light, PingFangTC-light, &quot;PingFang SC&quot;, Cambria, Cochin, Georgia, Times, &quot;Times New Roman&quot;, serif;text-align: center;line-height: 1.75em;"><br style="outline: 0px;"></section><section style="margin-top: 8px;margin-bottom: 8px;outline: 0px;font-family: -apple-system, &quot;system-ui&quot;, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 15px;letter-spacing: 0.544px;text-indent: 0em;text-align: center;line-height: 1.75em;min-height: 24px;clear: both;visibility: visible;"><a target="_blank" href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fmp%2Fappmsgalbum%3F__biz%3DMzAxNDEwNjk5OQ%3D%3D%26action%3Dgetalbum%26album_id%3D2565944923443904512%23wechat_redirect" textvalue="3DXR 技術" linktype="text" imgurl="" imgdata="null" tab="innerlink" data-linktype="2" style="outline: 0px;color: var(--weui-LINK);cursor: pointer;">3DXR 技術</a>&nbsp;|&nbsp; 
   <a target="_blank" href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fmp%2Fappmsgalbum%3F__biz%3DMzAxNDEwNjk5OQ%3D%3D%26action%3Dgetalbum%26album_id%3D1533906991218294785%23wechat_redirect" textvalue="終端技術" linktype="text" imgurl="" imgdata="null" tab="innerlink" data-linktype="2" style="outline: 0px;color: var(--weui-LINK);cursor: pointer;">終端技術</a>&nbsp;|&nbsp; 
   <a target="_blank" href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fmp%2Fappmsgalbum%3F__biz%3DMzAxNDEwNjk5OQ%3D%3D%26action%3Dgetalbum%26album_id%3D1592015847500414978%23wechat_redirect" textvalue="音視頻技術" linktype="text" imgurl="" imgdata="null" tab="innerlink" data-linktype="2" style="outline: 0px;color: var(--weui-LINK);cursor: pointer;">音視頻技術</a></section><p style="margin-top: 8px;margin-bottom: 8px;outline: 0px;min-height: 24px;font-family: -apple-system, &quot;system-ui&quot;, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 15px;letter-spacing: 0.544px;text-indent: 0em;text-align: center;line-height: 1.75em;visibility: visible;"><a target="_blank" href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fmp%2Fappmsgalbum%3F__biz%3DMzAxNDEwNjk5OQ%3D%3D%26action%3Dgetalbum%26album_id%3D1539610690070642689%23wechat_redirect" textvalue="服務端技術" linktype="text" imgurl="" imgdata="null" tab="innerlink" data-linktype="2" style="outline: 0px;color: var(--weui-LINK);cursor: pointer;">服務端技術</a><span style="outline: 0px;letter-spacing: 0.544px;">&nbsp;|&nbsp;</span><a target="_blank" href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fmp%2Fappmsgalbum%3F__biz%3DMzAxNDEwNjk5OQ%3D%3D%26action%3Dgetalbum%26album_id%3D2565883875634397185%23wechat_redirect" textvalue="技術質量" linktype="text" imgurl="" imgdata="null" tab="innerlink" data-linktype="2" style="outline: 0px;color: var(--weui-LINK);cursor: pointer;">技術質量</a>&nbsp;|&nbsp;<a target="_blank" href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fmp%2Fappmsgalbum%3F__biz%3DMzAxNDEwNjk5OQ%3D%3D%26action%3Dgetalbum%26album_id%3D1522425612282494977%23wechat_redirect" textvalue="數據算法" linktype="text" imgurl="" imgdata="null" tab="innerlink" data-linktype="2" style="outline: 0px;color: var(--weui-LINK);cursor: pointer;">數據算法</a></p><p style="margin-top: 8px;margin-bottom: 8px;outline: 0px;min-height: 24px;font-family: -apple-system, &quot;system-ui&quot;, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 15px;letter-spacing: 0.544px;text-indent: 0em;text-align: center;line-height: 1.75em;visibility: visible;"><br style="outline: 0px;"></p><section class="mp_profile_iframe_wrp" style="margin-bottom: 24px;outline: 0px;"><mp-common-profile class="custom_select_card mp_profile_iframe js_wx_tap_highlight" data-pluginname="mpprofile" data-id="MzAxNDEwNjk5OQ==" data-headimg="http://mmbiz.qpic.cn/mmbiz_png/33P2FdAnju8t5nZGhAatCrc4e2iaDfAaoInribRKxc7MOqdTGygfcLqSDxhj0trCHVEh94Sjl7zuWYzwouYtJ0VQ/300?wx_fmt=png&amp;wxfrom=19" data-nickname="大淘寶技術" data-alias="AlibabaMTT" data-signature="大淘寶技術官方賬號" data-from="2" data-index="0" data-origin_num="699" data-isban="0" data-biz_account_status="0" data-weui-theme="light" data-is_biz_ban="0"></mp-common-profile></section></section><section style="line-height: 1.75em;"><section style="display: none;line-height: 1.6em;"><br></section></section><p style="display: none;"><mp-style-type data-value="3"></mp-style-type></p></div><p style="color: #858585; font-size: 13px;">本文分享自微信公眾號 - 大淘寶技術（AlibabaMTT）。<br>如有侵權，請聯繫 support@oschina.cn 刪除。<br>本文參與「<a href="https://www.oschina.net/sharing-plan" target="_blank">OSC 源創計劃</a>」，歡迎正在閲讀的你也加入，一起分享。</p></div>
                                    ]]>
            </description>
            <pubDate>Sun, 03 Mar 2024 02:52:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/4662964/blog/11045189</guid>
            <link>https://my.oschina.net/u/4662964/blog/11045189</link>
            <author>
                <![CDATA[原創]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[FolkMQ 是怎樣進行消息的事務處理？]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="color:#24292e; text-align:start"><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ffolkmq.noear.org%2F" target="_blank">FolkMQ</a><span>&nbsp;</span>提供了二段式提交的事務提交的機制（TCC 模型）。允許生產者在發送消息時綁定到一個事務中並接收事務的管理，以確保消息的原子性（要麼全成功，要麼全失敗）。在 FolkMQ 中，事務是通過 MqTransaction 接口實現管理的。一般是通過：</p><ol><li>新建事務：在產生者端，可以通過調用<span>&nbsp;</span><code>MqTransaction tran = client.newTransaction()</code><span>&nbsp;</span>新建一個事務。後續的消息發送與此事務綁定。綁定的消息，即參與此事務；沒綁定的消息，則照舊。</li><li>發送消息（T）：接下來的事務中，嘗試發送消息。此時，中間件會把消息放在一個事務中轉隊列裏。</li><li>提交事務（C）：如果所有消息都發送成功了，就通過<span>&nbsp;</span><code>tran.commit()</code><span>&nbsp;</span>方法提交事務。此時，中間件把事務相關消息從事務中轉隊列取出，並轉到派發隊列。</li><li>回滾事務（C）：通過<span>&nbsp;</span><code>try catch</code>，如果有某一條消息發送異常了。就通過<span>&nbsp;</span><code>tran.rollback()</code><span>&nbsp;</span>方法回滾事務，即所有消息全部取消。此時，中間件把事務相關消息從事務中轉隊列刪掉。</li></ol><p style="color:#24292e; text-align:start">發送事務消息：</p><pre><code class="language-java"><em>//發送事務消息    </em><span style="color:#986801">MqTransaction</span><span style="color:#986801">tran</span><span>=</span> client.newTransaction();

<span style="color:#a626a4">try</span> {
    <em>//同步</em>
    client.publish(<span style="color:#50a14f">"demo"</span>, <span style="color:#a626a4">new</span><span style="color:#c18401">MqMessage</span>(<span style="color:#50a14f">"demo1"</span>).attr(<span style="color:#50a14f">"orderId"</span>,<span style="color:#50a14f">"1"</span>).transaction(tran));
    client.publish(<span style="color:#50a14f">"demo"</span>, <span style="color:#a626a4">new</span><span style="color:#c18401">MqMessage</span>(<span style="color:#50a14f">"demo2"</span>).attr(<span style="color:#50a14f">"orderId"</span>,<span style="color:#50a14f">"1"</span>).transaction(tran));
    <em>//異步，也行！</em>
    client.publishAsync(<span style="color:#50a14f">"demo"</span>, <span style="color:#a626a4">new</span><span style="color:#c18401">MqMessage</span>(<span style="color:#50a14f">"demo3"</span>).attr(<span style="color:#50a14f">"orderId"</span>,<span style="color:#50a14f">"1"</span>).transaction(tran));
    client.publishAsync(<span style="color:#50a14f">"demo"</span>, <span style="color:#a626a4">new</span><span style="color:#c18401">MqMessage</span>(<span style="color:#50a14f">"demo4"</span>).attr(<span style="color:#50a14f">"orderId"</span>,<span style="color:#50a14f">"1"</span>).transaction(tran));

    tran.commit();
} <span style="color:#a626a4">catch</span> (Throwable e) {
    tran.rollback();
}
</code></pre><p style="color:#24292e; text-align:start">FolkMQ 的服務端事務處理，是基於專屬的"事務中轉隊列"實現（支持快照持久化）。它可以保證在事務中的消息，要麼全部成功，要麼全部失敗。而且，當客戶端沒有提交二次確認時（偶爾會有網絡原因），超過 60 秒後，會發起反向「回查」。要實現更「周密」的事務處理，客戶端還需要實現回查處理。一般在客戶端初始化時，或者連接建立後配置事務回查處理：</p><pre><code class="language-java"><span style="color:#986801">MqClient</span><span style="color:#986801">client</span><span>=</span> FolkMQ.createClient(<span style="color:#50a14f">"folkmq://127.0.0.1:18602"</span>)
    .nameAs(<span style="color:#50a14f">"demoapp"</span>) <em>//一般用當前應用名</em>
    .connect();

client.transactionCheckback(m-&gt;{
  <span style="color:#a626a4">if</span>(<span style="color:#50a14f">"1"</span>.equals(m.getAttr(<span style="color:#50a14f">"orderId"</span>))) {
      m.acknowledge(<span style="color:#0184bb">true</span>);
  }
});
</code></pre><p style="color:#24292e; text-align:start">FolkMQ 的事務機制，並且不會對性能有影響，與非事務消息性能沒什麼差別。</p></div>
                                    ]]>
            </description>
            <pubDate>Sat, 02 Mar 2024 13:35:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/281211</guid>
            <link>https://www.oschina.net/news/281211</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[開源日報 | 為什麼王炸都來自 OpenAI；Pingora 最好不要用 YAML 當配置文件]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>歡迎閲讀 OSCHINA 編輯部出品的開源日報，每天更新一期。</p><h3><span style="color:#e67e22"><strong># 2024.3.1</strong></span></h3><h2><strong><span style="color:#16a085">今日要點</span></strong></h2><p><strong>OpenSource Daily</strong></p><h3><a href="https://www.oschina.net/news/281047/elon-musk-sues-openai-over-ai-threat" target="_blank">馬斯克起訴 OpenAI 及其 CEO 奧特曼，要求公司恢復開源狀態</a></h3><blockquote><p style="margin-left:0; margin-right:0"><img src="https://oscimg.oschina.net/oscnet/up-c1344f68b8ada81d79b927740c5e75e2cce.png" referrerpolicy="no-referrer"></p></blockquote><h3><a href="https://www.oschina.net/news/281036" target="_blank">魅族發佈首款開放式 AI 終端</a></h3><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">魅族發佈了魅族 21 Pro 智能手機，魅族稱之為旗下首款「開放式 AI 終端」，並宣佈將對所有大模型團隊開放。該產品支持 AI 靈動鍵、AI 輔助輸入、Aicy 語音助手、AI 圖庫等 AI 功能。根據官方信息，Aicy 語音助手具備文案撰寫、圖像創作等能力，圖庫應用支持自然語言搜圖，AI 靈動鍵可以支持 AI 識屏等功能，AI 輸入輔助可以生成回覆建議，進行長文創作。</p><hr><h2><strong><span style="color:#16a085">今日觀察</span></strong></h2><p><img height="372" src="https://oscimg.oschina.net/oscnet/up-97365969225a88a683972b5931db427f9dc.png" width="1622" referrerpolicy="no-referrer"></p><p><span style="background-color:#ffffff; color:#333333">- 微博&nbsp;</span><u><em><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fweibo.com%2F2169039837%2FO2Ya5o21i" target="_blank">karminski-牙醫</a></em></u></p><p><img src="https://oscimg.oschina.net/oscnet/up-f53bb9c7bec64dbd3c306dfaa57fd5507bf.png" referrerpolicy="no-referrer"></p><p><span style="background-color:#ffffff; color:#333333">- 微博&nbsp;</span><u><em><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fweibo.com%2F1560906700%2FO30JsvtBj" target="_blank">闌夕</a></em></u></p><hr><h2><span style="color:#16a085"><strong>今日推薦</strong></span></h2><p><img src="https://oscimg.oschina.net/oscnet/up-adaa2887858549a2ff988b1ccabc1aac780.png" referrerpolicy="no-referrer"></p><hr><h2><span style="color:#16a085"><strong>開源之聲</strong></span></h2><p><img src="https://oscimg.oschina.net/oscnet/up-a3a592d7df86fc56d68797e5b8a1016a3dc.png" referrerpolicy="no-referrer"></p><p><img src="https://oscimg.oschina.net/oscnet/up-c60ec6a6cae3c9f90c753f272ec97a17b4c.png" referrerpolicy="no-referrer"></p><hr><h2><span style="color:#16a085"><strong>每日項目榜</strong></span></h2><p><strong><span style="background-color:#e67e22">每日 GitHub 精選</span></strong></p><p><img src="https://oscimg.oschina.net/oscnet/up-805ca31b1cf11ac5d6d4a41d0ef65a3bd11.png" referrerpolicy="no-referrer"></p><blockquote><h4><strong><span style="background-color:#e67e22">在線閲讀完整日報內容，訪問：</span></strong><br><u><em><strong><a href="https://report.oschina.net/api/files/jhim80u9qm1ofsw/lv84pwvd03it00i/20_open_ai_pingora_yaml_mE5RuB20Vl.pdf" target="_blank">開源日報第 20 期：為什麼王炸都來自 OpenAI；Pingora 最好不要用 YAML 當配置文件</a></strong></em></u></h4></blockquote><hr><p><strong>往期回顧</strong></p><ul><li><a href="https://report.oschina.net/api/files/jhim80u9qm1ofsw/mx86z1dhywrw71p/19_ai_c_llm_IgpNOVZtCz.pdf" target="_blank">開源日報第 019 期：我讓 AI 用 C 語言寫一個算法；微軟三進制 LLM</a></li><li><a href="https://report.oschina.net/api/files/jhim80u9qm1ofsw/qdljicvqiqsshd6/187ZiLwG48lc_CngfQJ1Qxs.pdf" target="_blank">開源日報第 018 期：蘋果十年造車夢碎；這個開源項目有點...「大膽」</a></li><li><a href="https://report.oschina.net/api/files/jhim80u9qm1ofsw/7r8dkz3232v4e7a/17_maria_db_v_linux_GoyNoM85IZ.pdf">開源日報第 017 期：MariaDB 消亡史；寫代碼我有三不沾；V 神建議馬斯克用 Linux</a></li><li><a href="https://report.oschina.net/api/files/jhim80u9qm1ofsw/6typ9w3u98f5mxn/16_1_8_2efTeNfFjN.pdf">開源日報第 016 期：鴻蒙程序員平均月薪超 1 萬 8；中美 AI 差距有多大？</a></li><li><a href="https://report.oschina.net/api/files/jhim80u9qm1ofsw/92n4c9ryegpcq1z/015_sora_KcAkRNX93Y.pdf">開源日報第 015 期：為什麼擋不住英偉達；Sora 不靠蠻力</a></li><li><a href="https://report.oschina.net/api/files/jhim80u9qm1ofsw/s7n800w84o6guyv/014_kyezhNxOGD.pdf">開源日報第 014 期：目前的人工智能技術連貓的智能水平都沒達到</a></li><li><a href="https://oscimg.oschina.net/public_shard/%E5%BC%80%E6%BA%90%E6%97%A5%E6%8A%A5%E7%AC%AC013%E6%9C%9F%EF%BC%9A%E7%AD%89%E5%88%B0%20Sora%20%E5%BC%80%E6%BA%90%E4%BA%86%E7%AB%8B%E5%88%BB%E6%8E%A8%E5%87%BA%E5%B1%9E%E4%BA%8E%E6%88%91%E4%BB%AC%E8%87%AA%E5%B7%B1%E7%9A%84%E5%A4%A7%E6%A8%A1%E5%9E%8B.pdf">開源日報第 013 期：等到 Sora 開源了立刻推出屬於我們自己的大模型</a></li><li><a href="https://oscimg.oschina.net/public_shard/%E5%BC%80%E6%BA%90%E6%97%A5%E6%8A%A5%E7%AC%AC012%E6%9C%9F%EF%BC%9ASora%20%E7%BB%99%E4%B8%AD%E5%9B%BD%20AI%20%E5%B8%A6%E6%9D%A5%E7%9A%84%E7%9C%9F%E5%AE%9E%E5%8F%98%E5%8C%96%EF%BC%9BDart%203.3%20%E5%8F%91%E5%B8%83.pdf">開源日報第 012 期：Sora 給中國 AI 帶來的真實變化；Dart 3.3 發佈</a></li><li><a href="https://oscimg.oschina.net/public_shard/%E5%BC%80%E6%BA%90%E6%97%A5%E6%8A%A5%E7%AC%AC11%E6%9C%9F%EF%BC%9A%E7%9B%AE%E5%89%8D%E8%BF%98%E6%B2%A1%E6%9C%89%E2%80%9C%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%89%88Linux%E2%80%9D.pdf">開源日報第 011 期：目前還沒有「大模型版 Linux」</a></li><li><a href="https://oscimg.oschina.net/public_shard/%E5%BC%80%E6%BA%90%E6%97%A5%E6%8A%A5%E7%AC%AC010%E6%9C%9F%EF%BC%9ATauri%20v2%20%E6%94%AF%E6%8C%81%20Android%20%E5%92%8C%20iOS%EF%BC%8C%E8%B7%A8%E5%B9%B3%E5%8F%B0%E5%BC%80%E5%8F%91%E6%96%B0%E9%80%89%E6%8B%A9.pdf">開源日報第 010 期：Tauri v2 支持 Android 和 iOS，跨平台開發新選擇</a></li><li><a href="https://oscimg.oschina.net/public_shard/%E5%BC%80%E6%BA%90%E6%97%A5%E6%8A%A5009%E6%9C%9F%EF%BC%9AVue.js%E8%AF%9E%E7%94%9F10%E5%91%A8%E5%B9%B4%EF%BC%9B%E6%89%8E%E5%85%8B%E4%BC%AF%E6%A0%BC%E8%A7%A3%E9%87%8AMeta%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E5%BC%80%E6%BA%90%E5%85%B6AI%E6%8A%80%E6%9C%AF.pdf">開源日報第 009 期：Vue.js 誕生 10 週年；扎克伯格解釋 Meta 為什麼要開源其 AI 技術</a></li><li><a href="https://www.oschina.net/news/277585">開源日報第 008 期：推動中國開源軟硬件發展的經驗與建議</a></li><li><a href="https://www.oschina.net/news/277415">開源日報第 007 期：「Linux 中國」 開源社區宣佈停止運營</a></li><li><a href="https://www.oschina.net/news/277214">開源日報第 006 期：選擇技術棧一定要選擇開源的</a></li><li><a href="http://www.oschina.net/news/277040">開源日報第 005 期：RISC-V 萬兆開源交換機發售；npm 存在大量武林外傳視頻</a></li><li><a href="https://www.oschina.net/news/276864">開源日報第 004 期：百度輸入法在候選詞區域植入廣告；大神用 Excel 構建 CPU</a></li></ul></div>
                                    ]]>
            </description>
            <pubDate>Sat, 02 Mar 2024 09:20:20 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/281180</guid>
            <link>https://www.oschina.net/news/281180</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Canonical 為 Launchpad 進行主頁改版]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">Launchpad 主頁進行了更新，這是該網站自 2016 年以來的首次重大改版。</span></p><blockquote><p><span style="color:#000000">「如果你進入 </span><a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Flaunchpad.net" target="_blank">launchpad.net</a><span style="color:#000000">，你會發現它與過去 10 年的樣子大不相同--它已經更新過了！我們的目標是在保持 Launchpad 外觀的同時使其現代化。內容保持不變，只增加了一些文字，但在樣式上做了很多改動。」</span></p></blockquote><p><span style="color:#000000">公告<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.launchpad.net%2Fgeneral%2Flaunchpads-new-homepage" target="_blank">指出</a>，最重要的一項變化在於 Launchpad 主頁現在採用了 Vanilla 組件，以使得網站佈局看起來更現代，同時也更有利於好奇的新用戶通過移動設備訪問頁面，且「頁面的可訪問性得分從 75 分提高到了幾乎完美的 98 分。」</span></p><p><span style="color:#000000">從首頁更新開始，Launchpad 接下來還計劃對其他部分進行重新設計，從而實現更現代、用戶體驗更直觀的目標。</span></p><p><span style="color:#000000">以下分別是 Launchpad 在 2006 年、3 月 1 號更新之前以及更新後的樣子：</span></p><p><span style="color:#000000"><img alt="" height="139" src="https://oscimg.oschina.net/oscnet/up-6f9b009ba1df2e4799c692dc387e3327ccf.png" width="500" referrerpolicy="no-referrer"></span></p><p><em><span style="background-color:#ffffff; color:#333333">2006 年</span></em></p><p><span style="background-color:#ffffff; color:#333333"><img alt="" height="321" src="https://oscimg.oschina.net/oscnet/up-9123de2dcc490b270b0788183de8e38c17e.png" width="500" referrerpolicy="no-referrer"></span></p><p><em><span style="background-color:#ffffff; color:#333333">更新前</span></em></p><p><span style="background-color:#ffffff; color:#333333"><img alt="" height="335" src="https://oscimg.oschina.net/oscnet/up-c6a9b949630d6a8ecae579f5ef8c19ef0d0.png" width="500" referrerpolicy="no-referrer"></span></p><p><em><span style="background-color:#ffffff; color:#333333">更新後</span></em></p><p><span style="color:#000000">Launchpad 於 2004 年推出，是 Ubuntu 母公司 Canonical 公司所資助架設的網站，是一個提供維護、支持或連絡 Ubuntu 開發者的平台。開發人員通過它進行協作、提交代碼、計劃發佈、提交錯誤、添加翻譯，並處理與開發新版本相關的其他任務。</span></p></div>
                                    ]]>
            </description>
            <pubDate>Sat, 02 Mar 2024 04:05:12 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/281141/launchpads-new-homepage</guid>
            <link>https://www.oschina.net/news/281141/launchpads-new-homepage</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[CNCF 宣佈 Falco 畢業]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>CNCF <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.cncf.io%2Fannouncements%2F2024%2F02%2F29%2Fcloud-native-computing-foundation-announces-falco-graduation%2F" target="_blank">宣佈</a> Falco 畢業，它是一款專為 Linux 系統設計的雲原生安全工具，也是事實上的 Kubernetes 威脅檢測引擎。</p><p><img height="218" src="https://static.oschina.net/uploads/space/2024/0302/111141_0zZB_4252687.png" width="500" referrerpolicy="no-referrer"></p><p>Falco 是由 Sysdig 在 2016 年創建並開源的，並於 2018 年成為第一個被 CNCF Sandbox 接受的運行時安全項目，隨後在 2020 年 4 月進入孵化器。自那時以來，Falco 已經吸納了來自亞馬遜、蘋果、IBM、紅帽等公司的維護者。該項目的活躍貢獻者數量自孵化以來增加了 400%，目前有數百名活躍的代碼貢獻者。</p><p>該項目有超過 30 個公開自述的採用者，包括 Cisco、Shopify、Skyscanner 和 Vinted 等組織。自孵化以來，總下載量增長了 526%，平均每月下載量增長了 135%。</p><p>「在大規模雲原生部署中，實時可見性對於安全至關重要。」CNCF 首席技術官 Chris Aniszczyk 表示：「Falco 正在通過 eBPF 推動開源雲原生運行時安全領域的進步，我們期待在項目繼續發展的過程中看到這個領域的進展。」</p><p>Falco 通過對內核事件應用自定義規則，提供實時警報，幫助用戶獲得對異常行為、潛在安全威脅和合規性違規行為的可見性，為全面的運行時安全做出貢獻。在過去幾年中，維護者們致力於改進工程流程和重構 Falco 代碼庫，包括改進測試套件和新的內核測試框架，增加質量檢查，以及新功能，如新的 eBPF 探針和與新的第一方數據源的集成。</p><p>「Falco 的開發和貢獻到 CNCF 的結論是，運行時安全必須在雲原生基礎設施中廣泛可訪問和無縫集成——在雲中需要預防，但威脅檢測同樣重要。」Falco 創始人、SysdigCTO 和創始人 Loris Degioanni 表示：「Falco 得到的支持證明瞭一個事實，即你無法阻止一切，安全團隊需要深度防禦，即使在雲中也是如此。我對 Falco 社區的支持感激不盡，並且很高興在 CNCF 內達到了這個里程碑，但 Falco 社區從未將畢業視為終點，而是通過其插件系統擴展 Falco 用例的開始。」</p><p>公告指出，為了正式從孵化階段畢業，Falco 項目經歷了與 CNCF 技術監督委員會（Technical Oversight Committee，TOC）的盡職調查過程，完成了第三方安全審計，並支持 CNCF 項目在 eBPF 代碼旁邊包含 GPL 許可的 Linux 內核模塊的過程。畢業證實了 Falco 的成長、成熟和未來前景，並鞏固了該項目在運行時安全領域的領導地位。</p></div>
                                    ]]>
            </description>
            <pubDate>Sat, 02 Mar 2024 03:11:36 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/281135/cncf-falco-graduation</guid>
            <link>https://www.oschina.net/news/281135/cncf-falco-graduation</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[httpsok —— SSL 證書自動續期工具]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div style="text-align:start"><span>​</span><strong>一行命令，輕鬆搞定 SSL 證書自動續期。</strong><span><code>httpsok</code></span><span> 是一個便捷的 HTTPS 證書自動續期工具，專為 Nginx 服務器設計。已服務眾多中小企業，穩定、安全、可靠。</span></div><h2 style="margin-left:0; margin-right:0; text-align:start"><span>文檔</span></h2><ul style="margin-left:.8em; margin-right:.8em"><li><p style="margin-left:.5rem; margin-right:0"><span>幫助文檔：</span><span><a href="https://fposter.cn/doc/"><span>https://fposter.cn/doc/</span></a></span></p></li></ul><h2 style="margin-left:0; margin-right:0; text-align:start"><span>特性</span></h2><ul style="margin-left:.8em; margin-right:.8em"><li><p style="margin-left:.5rem; margin-right:0"><span>使用簡單，一行命令，一分鐘輕鬆解決 SSL 證書自動續期。</span></p></li><li><p style="margin-left:.5rem; margin-right:0"><span>無需修改任何 nginx 配置。</span></p></li><li><p style="margin-left:.5rem; margin-right:0"><span>對於複雜配置的生產環境，無縫支持。</span></p></li><li><p style="margin-left:.5rem; margin-right:0"><span>多域名、多服務器節點支持。</span></p></li><li><p style="margin-left:.5rem; margin-right:0"><span>證書監控功能，對於即將失效的證書，提供公眾號推送提醒。</span></p></li><li><p style="margin-left:.5rem; margin-right:0"><span>支持主流 Linux 系統</span></p></li></ul><h1 style="text-align:start"><span>快速開始</span></h1><h2 style="margin-left:0; margin-right:0; text-align:start"><span>安裝 httpsok</span></h2><pre style="margin-left:.8rem; margin-right:.8rem; text-align:left"><span><span style="color:#3300aa">curl</span><span style="color:#0000cc">-s</span> https://fposter.cn/httpsok.sh | <span style="color:#3300aa">bash</span><span style="color:#0000cc">-s</span><span style="color:#22a2c9">'your token'</span></span></pre><blockquote><p style="margin-left:0; margin-right:0"><span>登陸控制枱 👉 👉 </span><span><a href="https://fposter.cn/console/"><span>獲取 token</span></a></span></p></blockquote><h2 style="margin-left:0; margin-right:0; text-align:start"><span>安裝成功</span></h2><p style="color:#34495e; margin-left:.8em; margin-right:.8em; text-align:start"><span>安裝成功後，會自動檢測一次系統中的</span><span><code>nginx</code></span><span>證書。</span></p><pre style="margin-left:.8rem; margin-right:.8rem; text-align:left"><span><span style="color:#116644">2024</span><span style="color:#0000cc">-01-21</span><span style="color:#116644">00</span>:22:56 os-name: TencentOS Server <span style="color:#116644">2</span>.4</span><span><span style="color:#116644">2024</span><span style="color:#0000cc">-01-21</span><span style="color:#116644">00</span>:22:56 version: nginx/1.20.1</span><span><span style="color:#116644">2024</span><span style="color:#0000cc">-01-21</span><span style="color:#116644">00</span>:22:56 nginx-config-home: /etc/nginx</span><span><span>​</span></span><span>Httpsok <span style="color:#3300aa">make</span> SSL easy. &nbsp; &nbsp; https://fposter.cn/ </span><span>version: <span style="color:#116644">1</span>.7.1</span><span>home: /root/.httpsok</span><span><span>​</span></span><span><span style="color:#116644">2024</span><span style="color:#0000cc">-01-21</span><span style="color:#116644">00</span>:22:57 DNS check pass</span><span><span style="color:#116644">2024</span><span style="color:#0000cc">-01-21</span><span style="color:#116644">00</span>:22:57 cdb8e6b945154127 /etc/nginx/certs/api.fastposter.net_nginx/api.fastposter.net_bundle.crt Cert valid</span><span><span style="color:#116644">2024</span><span style="color:#0000cc">-01-21</span><span style="color:#116644">00</span>:22:58 e29c94e6c2504f37 /etc/nginx/certs/cloud.fastposter.net_nginx/cloud.fastposter.net_bundle.crt Cert valid</span><span><span style="color:#116644">2024</span><span style="color:#0000cc">-01-21</span><span style="color:#116644">00</span>:22:58 32614897bc364812 /etc/nginx/certs/fastposter.net_nginx/fastposter2.net_bundle.crt Cert valid</span><span><span style="color:#116644">2024</span><span style="color:#0000cc">-01-21</span><span style="color:#116644">00</span>:22:58 7b9be1c745cb41f8 /etc/nginx/certs/fposter.cn_nginx/fposter.cn_bundle.crt Cert valid</span><span><span>​</span></span><span><span style="color:#116644">2024</span><span style="color:#0000cc">-01-21</span><span style="color:#116644">00</span>:22:58 Nginx reload needless.</span></pre></div>
                                                                ]]>
            </description>
            <pubDate>Sat, 02 Mar 2024 02:51:36 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/p/httpsok</guid>
            <link>https://www.oschina.net/p/httpsok</link>
        </item>
        <item>
            <title>
                <![CDATA[Gitee 推薦 | 為項目生成 SBOM 清單的 CLI 工具 SBOM-TOOL]]>
            </title>
            <description>
                <![CDATA[<h1><a id="user-content-sbom-tool" class="anchor" href="https://gitee.com/JD-opensource/sbom-tool#sbom-tool"></a>SBOM-TOOL</h1><p><a href="https://gitee.com/JD-opensource/sbom-tool/blob/master/README.md">English</a> | 簡體中文</p><p>SBOM-TOOL 是通過源碼倉庫、代碼指紋、構建環境、製品信息、製品內容、依賴組建等多種維度信息，為軟件項目生成軟件物料清單（SBOM）的一款 CLI 工具。</p><h2><a id="user-content-功能特性" class="anchor" href="https://gitee.com/JD-opensource/sbom-tool#%E5%8A%9F%E8%83%BD%E7%89%B9%E6%80%A7"></a>功能特性</h2><h3><a id="user-content-信息採集" class="anchor" href="https://gitee.com/JD-opensource/sbom-tool#%E4%BF%A1%E6%81%AF%E9%87%87%E9%9B%86"></a>信息採集</h3><ul><li>採集源代碼工程信息，包括倉庫地址、版本信息等</li><li>採集並生成代碼指紋，利用一定算法生成代碼指紋</li><li>採集工程構建依賴環境信息，包括操作系統、內核、編譯器、構建工具等</li><li>採集工程構建的依賴組件，支持多種語言、多種包管理器的依賴採集</li><li>採集最終製品包信息，包括包名、類型、唯一校驗碼等</li><li>採集製品內容信息，包括文件名類型、唯一校驗碼等</li></ul><h3><a id="user-content-sbom 文檔" class="anchor" href="https://gitee.com/JD-opensource/sbom-tool#sbom%E6%96%87%E6%A1%A3"></a>SBOM 文檔</h3><ul><li>組裝 SBOM 文檔，基於上述採集的信息組裝標準 SBOM 文檔</li><li>規範格式轉換，支持 XSPDX、SPDX 等規範，支持 JSON 等格式</li><li>規範格式校驗，支持 XSPDX、SPDX 等規範，支持 JSON 等格式</li></ul><h2><a id="user-content-代碼指紋生成能力" class="anchor" href="https://gitee.com/JD-opensource/sbom-tool#%E4%BB%A3%E7%A0%81%E6%8C%87%E7%BA%B9%E7%94%9F%E6%88%90%E8%83%BD%E5%8A%9B"></a>代碼指紋生成能力</h2><table><thead><tr><th>開發語言</th><th>是否支持</th></tr></thead><tbody><tr><td><code>C/C++</code></td><td>是</td></tr><tr><td><code>Java</code></td><td>是</td></tr><tr><td><code>C#</code></td><td>是</td></tr><tr><td><code>Dart</code></td><td>是</td></tr><tr><td><code>Golang</code></td><td>是</td></tr><tr><td><code>Javascript</code></td><td>是</td></tr><tr><td><code>Objective-C</code></td><td>是</td></tr><tr><td><code>Php</code></td><td>是</td></tr><tr><td><code>Python</code></td><td>是</td></tr><tr><td><code>Ruby</code></td><td>是</td></tr><tr><td><code>Rust</code></td><td>是</td></tr><tr><td><code>Swift</code></td><td>是</td></tr><tr><td><code>Lua</code></td><td>是</td></tr></tbody></table><h2><a id="user-content-依賴包掃描能力" class="anchor" href="https://gitee.com/JD-opensource/sbom-tool#%E4%BE%9D%E8%B5%96%E5%8C%85%E6%89%AB%E6%8F%8F%E8%83%BD%E5%8A%9B"></a>依賴包掃描能力</h2><p>現已支持以下編程語言相關的配置文件解析、二進制包解析，後續會逐步支持更多的編程語言。</p><table><thead><tr><th>包類型</th><th>包管理器</th><th>解析文件</th><th>是否支持依賴圖譜</th></tr></thead><tbody><tr><td><code>maven</code></td><td><a href="https://gitee.com/link?target=https%3A%2F%2Fmaven.apache.org">Maven</a></td><td><ul><li><code>pom.xml</code></li><li><code>*.jar</code></li><li><code>*.war</code></li><li><code>[graph]maven-dependency-tree.txt(mvn dependency:tree -DoutputFile=maven-dependency-tree.txt)</code></li></ul></td><td>是</td></tr><tr><td><code>maven</code></td><td><a href="https://gitee.com/link?target=https%3A%2F%2Fgradle.org">Gradle</a></td><td><ul><li><code>*.gradle</code></li><li><code>.gradle.lockfile</code></li><li><code>[graph]gradle-dependency-tree.txt(gradlew gradle-baseline-java:dependencies &gt; gradle-dependency-tree.txt)</code></li></ul></td><td>是</td></tr><tr><td><code>conan</code></td><td><a href="https://gitee.com/link?target=https%3A%2F%2Fconan.io">Conan</a></td><td><ul><li><code>conanfile.txt</code></li><li><code>conan.lock</code></li><li><code>[graph]conan-graph-info.json(conan graph info -f json &gt; conan-graph-info.json)</code></li></ul></td><td>是</td></tr><tr><td><code>npm</code></td><td><a href="https://gitee.com/link?target=https%3A%2F%2Fwww.npmjs.com">NPM</a></td><td><ul><li><code>package.json</code></li><li><code>package-lock.json</code></li></ul></td><td>否</td></tr><tr><td><code>npm</code></td><td><a href="https://gitee.com/link?target=https%3A%2F%2Fyarnpkg.com">Yarn</a></td><td><ul><li><code>[graph]yarn.lock</code></li></ul></td><td>是</td></tr><tr><td><code>npm</code></td><td><a href="https://gitee.com/link?target=https%3A%2F%2Fpnpm.io%2F">PNPM</a></td><td><ul><li><code>[graph]pnpm.lock</code></li></ul></td><td>是</td></tr><tr><td><code>golang</code></td><td><a href="https://gitee.com/link?target=https%3A%2F%2Fgo.dev%2Fref%2Fmod">Go Module</a></td><td><ul><li><code>go.mod</code></li><li><code>Go Binary file</code></li><li><code>[graph]go-mod-graph.txt(go mod graph &gt; go-mod-graph.txt)</code></li></ul></td><td>是</td></tr><tr><td><code>golang</code></td><td><a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2FMasterminds%2Fglide">Glide</a></td><td><ul><li><code>glide.yml</code></li><li><code>glide.yaml</code></li></ul></td><td>否</td></tr><tr><td><code>golang</code></td><td><a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2Ftools%2Fgodep">GoDep</a></td><td><ul><li><code>Godeps.json</code></li></ul></td><td>否</td></tr><tr><td><code>golang</code></td><td><a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2Fgolang%2Fdep">Dep</a></td><td><ul><li><code>Gopkg.toml</code></li></ul></td><td>否</td></tr><tr><td><code>golang</code></td><td><a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2FFiloSottile%2Fgvt">GVT</a></td><td><ul><li><code>*/vendor/manifest</code></li></ul></td><td>否</td></tr><tr><td><code>pypi</code></td><td><a href="https://gitee.com/link?target=https%3A%2F%2Fpip.pypa.io">PIP</a></td><td><ul><li><code>Pipfile.lock</code></li><li><code>*dist-info/METADATA</code></li><li><code>PKG-INFO</code></li><li><code>*requirements*.txt</code></li><li><code>setup.py</code></li><li><code>[graph]pipenv-graph.txt(pipenv graph &gt; pipenv-graph.txt)</code></li></ul></td><td>是</td></tr><tr><td><code>pypi</code></td><td><a href="https://gitee.com/link?target=https%3A%2F%2Fpython-poetry.org">Poetry</a></td><td><ul><li><code>[graph]poetry.lock</code></li></ul></td><td>是</td></tr><tr><td><code>conda</code></td><td><a href="https://gitee.com/link?target=https%3A%2F%2Fconda.io">Conda</a></td><td><ul><li><code>environment.yml</code></li><li><code>environment.yaml</code></li><li><code>package-list.txt</code></li></ul></td><td>否</td></tr><tr><td><code>composer</code></td><td><a href="https://gitee.com/link?target=https%3A%2F%2Fgetcomposer.org">Composer</a></td><td><ul><li><code>composer.json</code></li><li><code>composer.lock</code></li></ul></td><td>否</td></tr><tr><td><code>cargo</code></td><td><a href="https://gitee.com/link?target=https%3A%2F%2Fdoc.rust-lang.org%2Fcargo">Cargo</a></td><td><ul><li><code>Cargo.toml</code></li><li><code>[graph]Cargo.lock</code></li><li><code>Rust Binary file</code></li></ul></td><td>是</td></tr><tr><td><code>carthage</code></td><td><a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2FCarthage%2FCarthage">Carthage</a></td><td><ul><li><code>Cartfile</code></li><li><code>Cartfile.resolved</code></li></ul></td><td>否</td></tr><tr><td><code>swift</code></td><td><a href="https://gitee.com/link?target=https%3A%2F%2Fwww.swift.org%2Fpackage-manager">SwiftPM</a></td><td><ul><li><code>Package.swift</code></li></ul></td><td>否</td></tr><tr><td><code>cocoapods</code></td><td><a href="https://gitee.com/link?target=https%3A%2F%2Fcocoapods.org">Cocoapods</a></td><td><ul><li><code>Podfile.lock</code></li><li><code>Podfile</code></li><li><code>*.podspec</code></li></ul></td><td>是</td></tr><tr><td><code>gem</code></td><td><a href="https://gitee.com/link?target=https%3A%2F%2Frubygems.org">Gem</a></td><td><ul><li><code>[graph]Gemfile.lock</code></li><li><code>Gemfile</code></li><li><code>*.gemspec</code></li></ul></td><td>是</td></tr><tr><td><code>nuget</code></td><td><a href="https://gitee.com/link?target=https%3A%2F%2Fwww.nuget.org">NuGet</a></td><td><ul><li><code>[graph]*.deps.json</code></li><li><code>*.csproj</code></li><li><code>*.vbproj</code></li><li><code>*.fsproj</code></li><li><code>*.vcproj</code></li><li><code>*.nuget.dgspec.json</code></li><li><code>*.nuspec</code></li><li><code>packages.json</code></li><li><code>packages.lock.json</code></li></ul></td><td>是</td></tr><tr><td><code>pub</code></td><td><a href="https://gitee.com/link?target=https%3A%2F%2Fpub.dev">Pub</a></td><td><ul><li><code>[graph]pub-deps.json(dart pub deps --json &gt; pub-deps.json)</code></li><li><code>pubspec.lock</code></li><li><code>pubspec.yaml</code></li></ul></td><td>是</td></tr><tr><td><code>rpm</code></td><td><a href="https://gitee.com/link?target=https%3A%2F%2Frpm-packaging-guide.github.io">RPM</a></td><td><ul><li><code>*.spec</code></li></ul></td><td>否</td></tr><tr><td><code>deb</code></td><td><a href="https://gitee.com/link?target=https%3A%2F%2Fdeb.debian.org%2Fdebian">DEB</a></td><td><ul><li><code>*.deb</code></li><li><code>*.control</code></li></ul></td><td>否</td></tr><tr><td><code>lua</code></td><td><a href="https://gitee.com/link?target=https%3A%2F%2Fluarocks.org">LuaRocks</a></td><td><ul><li><code>*.rockspec</code></li></ul></td><td>否</td></tr><tr><td><code>bower</code></td><td><a href="https://gitee.com/link?target=https%3A%2F%2Fbower.io">Bower</a></td><td><ul><li><code>*.spec</code></li></ul></td><td>否</td></tr></tbody></table><h2><a id="user-content-軟件架構" class="anchor" href="https://gitee.com/JD-opensource/sbom-tool#%E8%BD%AF%E4%BB%B6%E6%9E%B6%E6%9E%84"></a>軟件架構</h2><p><img src="https://gitee.com/JD-opensource/sbom-tool/raw/master/docs/img/arch.png" alt="SBOM-TOOL 整體架構" referrerpolicy="no-referrer"></p><h2><a id="user-content-下載安裝" class="anchor" href="https://gitee.com/JD-opensource/sbom-tool#%E4%B8%8B%E8%BD%BD%E5%AE%89%E8%A3%85"></a>下載安裝</h2><ol><li>下載源碼編譯 (需要 <code>go 1.18</code> 及以上版本)
<div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line">git clone git@gitee.com:JD-opensource/sbom-tool.git</span><span id="LC2" class="line"><span class="nb">cd </span>sbom-tool</span><span id="LC3" class="line">make</span></pre><div class="markdown-code-block-copy-btn"></div></div></div>
默認生成多個系統架構的程序二進制包
<ul><li>Linux X86_64：sbom-tool-linux-amd64</li><li>Linux arm64：sbom-tool-linux-arm64</li><li>Windows X86_64：sbom-tool-windows-amd64.exe</li><li>Windows arm64：sbom-tool-windows-arm64.exe</li><li>MacOS amd64:  sbom-tool-darwin-amd64</li><li>MacOS arm64: sbom-tool-darwin-arm64</li></ul></li></ol><p>或者通過 go install 安裝</p><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line">   go <span class="nb">install </span>gitee.com/JD-opensource/sbom-tool/cmd/sbom-tool@latest</span></pre><div class="markdown-code-block-copy-btn"></div></div></div><p>或者通過下載二進制文件安裝:   <a href="https://gitee.com/JD-opensource/sbom-tool/releases">SBOM-TOOL 發行版</a></p><h2><a id="user-content-子命令説明" class="anchor" href="https://gitee.com/JD-opensource/sbom-tool#%E5%AD%90%E5%91%BD%E4%BB%A4%E8%AF%B4%E6%98%8E"></a>子命令説明</h2><table><thead><tr><th>子命令</th><th>功能</th></tr></thead><tbody><tr><td><code>help</code></td><td>工具幫助手冊</td></tr><tr><td><code>artifact</code></td><td>採集軟件包製品信息</td></tr><tr><td><code>assembly</code></td><td>把各階段生成的文檔組裝為 SBOM 文檔</td></tr><tr><td><code>completion</code></td><td>為指定的 shell 生成自動完成腳本</td></tr><tr><td><code>convert</code></td><td>轉換 SBOM 文檔格式</td></tr><tr><td><code>env</code></td><td>生成環境信息</td></tr><tr><td><code>generate</code></td><td>生成 SBOM 文檔</td></tr><tr><td><code>package</code></td><td>收集包依賴項</td></tr><tr><td><code>source</code></td><td>收集源代碼信息</td></tr><tr><td><code>validate</code></td><td>驗證 SBOM 文檔格式</td></tr><tr><td><code>info</code></td><td>獲取工具介紹信息</td></tr><tr><td><code>modify</code></td><td>修改 SBOM 文檔屬性</td></tr></tbody></table><h2><a id="user-content-參數説明" class="anchor" href="https://gitee.com/JD-opensource/sbom-tool#%E5%8F%82%E6%95%B0%E8%AF%B4%E6%98%8E"></a>參數説明</h2><table><thead><tr><th>參數</th><th>短參數</th><th>描述</th><th>使用樣例</th></tr></thead><tbody><tr><td><code>--log-level </code></td><td></td><td>指定日誌級別，包括 <code>debug</code>、<code>info</code>、<code>warn</code>、<code>error</code></td><td><code>--log-level info</code></td></tr><tr><td><code>--log-path </code></td><td></td><td>指定日誌路徑，默認在用戶主目錄下自動生成日誌目錄及日誌文件 ($home/sbom-tool/sbom-tool.log)</td><td><code>--log-path /tmp/sbom.log</code></td></tr><tr><td><code>--quiet  </code></td><td><code>-q</code></td><td>無控制枱輸出</td><td><code>--quiet</code><code>-q</code></td></tr><tr><td><code>--ignore-dirs</code></td><td></td><td>要忽略的目錄，跳過所有點目錄，以逗號分隔。示例：NODE_MODULES，LOGS</td><td><code>--ignore-dirs log,logs</code></td></tr><tr><td><code>--language</code></td><td><code>-l</code></td><td>指定語言 (目前支持：<code>java</code>，<code>cpp</code>)(默認為「*」)</td><td><code>--language java</code><code>-l cpp</code></td></tr><tr><td><code>--parallelism</code></td><td><code>-m</code></td><td>併發度 (默認為<code>8</code>)</td><td><code>--parallelism 4</code><code>-m 9</code></td></tr><tr><td><code>--output</code></td><td><code>-o</code></td><td>指定結果輸出文件存放路徑及名稱，默認會在當前目錄下自動生成</td><td><code>--output /tmp/sbom.json</code></td></tr><tr><td><code>--src</code></td><td><code>-s</code></td><td>指定源代碼存放路徑，默認為當前目錄</td><td><code>--src /tmp/sbomtool/src/</code></td></tr><tr><td><code>--path</code></td><td><code>-p</code></td><td>指定項目工程主目錄；assembly 子命令中用於指定各階段臨時文檔路徑</td><td><code>--path /tmp/sbomtool/</code></td></tr><tr><td><code>--dist </code></td><td><code>-d</code></td><td>指定製品存放路徑，默認為當前目錄</td><td><code>--dist /tmp/sbomtool/bin/</code></td></tr><tr><td><code>--format</code></td><td><code>-f</code></td><td>指定 SBOM 文檔格式 (目前支持：<code>xspdx-json</code>、<code>spdx-json</code>、<code>spdx-tagvalue</code>)(默認為<code>spdx-json</code>)</td><td><code>--format spdx-json</code><code>-f spdx-json</code></td></tr><tr><td><code>--input</code></td><td><code>-i</code></td><td>指定 SBOM 文檔作為輸入</td><td><code>--input /tmp/sbom.jsom</code></td></tr><tr><td><code>--algorithm</code></td><td><code>-a</code></td><td>用於指定生成 SBOM 文檔標識的算法 (目前支持:<code>SHA1</code>、<code>SHA256</code>、<code>SM3</code>)(默認為<code>SM3</code>)</td><td><code>--algorithm SHA256</code></td></tr></tbody></table><h2><a id="user-content-sbom 文檔規範與格式" class="anchor" href="https://gitee.com/JD-opensource/sbom-tool#sbom%E6%96%87%E6%A1%A3%E8%A7%84%E8%8C%83%E4%B8%8E%E6%A0%BC%E5%BC%8F"></a>SBOM 文檔規範與格式</h2><table><thead><tr><th align="left">規範</th><th align="left">格式</th><th align="left">SBOM 文檔格式</th><th align="left">是否支持</th></tr></thead><tbody><tr><td align="left"><code>XSPDX</code></td><td align="left"><code>JSON</code></td><td align="left"><code>xspdx-json</code></td><td align="left">已支持</td></tr><tr><td align="left"><code>SPDX</code></td><td align="left"><code>JSON</code></td><td align="left"><code>spdx-json</code></td><td align="left">已支持</td></tr><tr><td align="left"><code>SPDX</code></td><td align="left"><code>TagValue</code></td><td align="left"><code>spdx-tagvalue</code></td><td align="left">已支持</td></tr></tbody></table><p><code>XSPDX 是基於 SPDX 擴展的 SBOM 格式規範</code></p><h2><a id="user-content-使用示例" class="anchor" href="https://gitee.com/JD-opensource/sbom-tool#%E4%BD%BF%E7%94%A8%E7%A4%BA%E4%BE%8B"></a>使用示例</h2><p>生成 SBOM 文檔並指定格式</p><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line">sbom-tool generate <span class="nt">-m</span> 4 <span class="nt">-p</span><span class="k">${</span><span class="nv">project_path</span><span class="k">}</span><span class="nt">-s</span><span class="k">${</span><span class="nv">src_path</span><span class="k">}</span><span class="nt">-d</span><span class="k">${</span><span class="nv">dist_path</span><span class="k">}</span><span class="nt">-o</span> sbom.spdx.json <span class="nt">-f</span> spdx-json <span class="nt">--ignore-dirs</span> .git  <span class="nt">-n</span><span class="k">${</span><span class="nv">name</span><span class="k">}</span><span class="nt">-v</span><span class="k">${</span><span class="nv">version</span><span class="k">}</span><span class="nt">-u</span><span class="k">${</span><span class="nv">supplier</span><span class="k">}</span><span class="nt">-b</span><span class="k">${</span><span class="nv">namespace</span><span class="k">}</span></span></pre><div class="markdown-code-block-copy-btn"></div></div></div><p>獲取工具介紹信息</p><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line">sbom-tool info</span></pre><div class="markdown-code-block-copy-btn"></div></div></div><p>更多使用案例，詳見<a href="https://gitee.com/JD-opensource/sbom-tool/blob/master/docs/zh-CN/user-guide.md">文檔</a></p><h2><a id="user-content-開發指南" class="anchor" href="https://gitee.com/JD-opensource/sbom-tool#%E5%BC%80%E5%8F%91%E6%8C%87%E5%8D%97"></a>開發指南</h2><p>詳見 <a href="https://gitee.com/JD-opensource/sbom-tool/blob/master/docs/zh-CN/development-guide.md">開發指南文檔</a></p><h2><a id="user-content-問題反饋聯繫我們" class="anchor" href="https://gitee.com/JD-opensource/sbom-tool#%E9%97%AE%E9%A2%98%E5%8F%8D%E9%A6%88%E8%81%94%E7%B3%BB%E6%88%91%E4%BB%AC"></a>問題反饋&amp;聯繫我們</h2><p>如果在使用中遇到問題，歡迎您向我們提交 ISSUE。</p><h2><a id="user-content-如何貢獻" class="anchor" href="https://gitee.com/JD-opensource/sbom-tool#%E5%A6%82%E4%BD%95%E8%B4%A1%E7%8C%AE"></a>如何貢獻</h2><p>SBOM-TOOL 是一款開源的軟件成分分析工具，期待您的貢獻。</p><h2><a id="user-content-許可證" class="anchor" href="https://gitee.com/JD-opensource/sbom-tool#%E8%AE%B8%E5%8F%AF%E8%AF%81"></a>許可證</h2><p>此項目是在 <strong>MulanPSL2</strong> 下授權的，有關詳細信息，請參閲<a href="https://gitee.com/JD-opensource/sbom-tool/blob/master/LICENSE">許可證文件</a>。</p>]]>
            </description>
            <pubDate>Sat, 02 Mar 2024 02:46:36 GMT</pubDate>
            <guid isPermaLink="false">https://gitee.com/JD-opensource/sbom-tool</guid>
            <link>https://gitee.com/JD-opensource/sbom-tool</link>
        </item>
        <item>
            <title>
                <![CDATA[揭祕！KubeSphere 背後的 「超級大腦」：etcd 的魅力與力量]]>
            </title>
            <description>
                <![CDATA[<div class="content"><blockquote><p>作者：尹珉，KubeSphere Ambassador &amp; Contributor，KubeSphere 社區用戶委員會杭州站站長。</p></blockquote><h2>1. 開篇：揭開神祕面紗，etcd 如何驅動 KubeSphere 高效運轉</h2><p>在雲原生時代，etcd 作為 Kubernetes 生態中不可或缺的核心組件，扮演着 KubeSphere 集羣「神經系統」的角色。它利用 Raft 一致性算法提供強大的分佈式鍵值存儲能力，確保集羣狀態信息的實時同步和持久化。</p><p>每當在 KubeSphere 中執行資源操作時，這些指令首先通過 etcd 進行處理和分發，從而實現對整個集羣狀態的瞬時更新與管理。正是由於 etcd 的存在，KubeSphere 才得以在大規模容器編排中展現卓越的性能和穩定性。</p><p>接下來，我們將深入探索 etcd 如何巧妙地融入 KubeSphere 生態系統，並通過實際應用場景展示其對提升平台工作效率和可靠性的關鍵作用。</p><h2>2. 時光機：從誕生到崛起，etcd 如何在雲原生時代嶄露頭角</h2><p>etcd 的旅程始於 2013 年 CoreOS 團隊的一項創新嘗試，隨着其 V1 和 V2 版本的發展，逐漸奠定了在分佈式系統數據一致性解決方案中的地位。從 etcd V1、V2 到 V3 版本的迭代過程中，性能不斷提升，穩定性日益增強，功能上也不斷豐富和完善。</p><p>經歷數次重要升級後，etcd V3 版本尤其顯著地解決了 Kubernetes 發展過程中面臨的存儲瓶頸問題。在性能方面，通過優化實現了更快的數據讀寫速度；在穩定性上，引入了更為健壯的一致性保證機制；在功能上，則擴展了 API 接口，增強了安全性與可管理性。</p><p>因此，etcd 憑藉這些改進，在性能、穩定性和功能上的卓越表現成功捍衞了作為 Kubernetes 核心存儲組件的地位，並在雲原生時代中扮演着不可或缺的角色，持續推動整個生態系統的進步與發展。</p><h2>3. 深度剖析：etcd 核心原理與架構設計，它是如何做到數據存儲的萬無一失</h2><h3>3.1 基礎架構圖</h3><p>etcd 是典型的讀多寫少存儲，實際業務場景中，讀一般佔據 2/3 以上的請求。為了讓大家對 etcd 每個模塊有一定的初步瞭解，簡單介紹一下每個模塊的功能作用。</p><p><img src="https://oscimg.oschina.net/oscnet/up-ee75e231aa87a0517da0140ae92dd291498.png" alt="" referrerpolicy="no-referrer"></p><ul><li><p>Client 層：etcd 提供了 v2 和 v3 兩個版本的 API 客戶端庫，通過負載均衡、節點故障自動轉移等機制簡化了業務集成過程，有效提升了開發效率與服務穩定性。</p></li><li><p>API 網絡層：該層處理客戶端與服務器以及服務器間的通信。v2 API 基於 HTTP/1.x 協議，而 v3 API 則使用 gRPC 協議，並通過 grpc-gateway 支持 HTTP/1.x 調用以滿足多語言需求。此外，Raft 一致性算法驅動下的服務器間通信也採用 HTTP 協議來實現數據複製和 Leader 選舉等功能。</p></li><li><p>Raft 算法層：這一關鍵層實現了諸如 Leader 選舉、日誌複製及 ReadIndex 等核心特性，確保了 etcd 集羣中多個節點間的數據一致性和高可用性。</p></li><li><p>功能邏輯層：在此層面上，etcd 的核心模塊包括 KV 存儲、多版本併發控制（MVCC）、權限驗證（Auth）、租約管理（Lease）以及數據壓縮（Compactor）等組件，其中 MVCC 模塊由 treeIndex 和 boltdb 組成，用於高效且安全地處理鍵值操作。</p></li><li><p>存儲層：為保證數據安全性與持久化，存儲層包含預寫日誌（WAL）和快照（Snapshot）機制，以及用於存儲元數據和用戶數據的 boltdb 數據庫。WAL 防止 etcd 在崩潰後丟失數據，而 boltdb 則負責實際的數據存儲與檢索。</p></li></ul><h3>3.2 etcd 實現高可用、數據一致性的祕訣</h3><p>祕訣就是 Raft 算法，旨在簡化分佈式系統中的共識問題理解與實現。它將複雜的共識過程分解為三個關鍵環節：</p><ul><li><p>Leader 選舉：確保在 Leader 節點失效時能快速重新選舉出新的 Leader。</p></li><li><p>日誌複製：通過僅允許 Leader 節點寫入日誌，並負責向 Follower 節點複製日誌記錄，以保證集羣內部數據一致性。</p></li><li><p>安全性：在安全性方面，Raft 算法設計了嚴格的規則，例如一個任期內僅產生一個有效的 Leader、先前已提交的日誌條目在新 Leader 上必定存在，且所有節點的狀態機應用的相同位置應具有相同的日誌內容。這一系列機制共同保障了分佈式系統的穩定性和一致性。</p></li></ul><h3>3.3 探祕 etcd 讀請求：一次閃電般的數據檢索之旅</h3><p>在分佈式系統背景下，看似簡單的數據讀取操作實則蘊含複雜機制。對於 etcd 這類追求高可用與強一致性的鍵值存儲系統，每一次讀請求均是對底層技術細節和算法智慧的深度實踐。面對大規模集羣環境，當客戶端發送讀取指令時，etcd 如何確保快速準確地響應呢？接下來，我們一起揭示 etcd 讀請求背後的核心技術流程。</p><ul><li><p>客戶端發起請求：應用通過 etcd 的 v2 或 v3 版本 API 客戶端庫發送讀取鍵值對的請求，支持 HTTP/1.x 和 gRPC 協議。</p></li><li><p>Raft 算法交互：對於讀操作，etcd 採用 ReadIndex 機制。客戶端將讀請求發送至當前 Leader 節點，Leader 節點先記錄下這次讀請求，然後在提交一個新的日誌條目後，再響應客戶端的讀請求，確保在此期間沒有新的寫入導致集羣狀態改變。</p></li><li><p>一致性保證：Leader 節點根據 Raft 算法確保所有已提交的日誌條目已被集羣內所有 Follower 節點複製，並達到一致狀態。</p></li><li><p>KV 存儲查詢：Leader 節點從內部 MVCC（多版本併發控制）模塊中的 boltdb 數據庫中檢索對應鍵的最新有效版本數據。</p></li><li><p>返回結果：一旦獲取到數據，Leader 節點將結果返回給客戶端，完成讀取操作。</p></li></ul><p>在深入探討 etcd 的讀流程時，我們觸及到了其核心機制——線性讀與串行讀。這兩種讀模式分別應對不同的一致性需求場景。接下來，我們只對它們的含義做一個簡單的解釋：</p><ul><li><p>串行讀（Serializable Read）適用於對數據實時性要求不嚴苛的情況，直接從節點狀態機中獲取數據，實現低延遲、高吞吐，但可能存在一定的數據一致性風險。</p></li><li><p>線性讀（Linearizable Read）則是為了滿足關鍵業務操作對強一致性的需求，確保任何更新後的值都能被後續請求及時準確地訪問到，即使集羣中有多個節點，客戶端通過線性讀也能如同訪問單一節點般獲得最新且已達成共識的數據。儘管相比串行讀可能帶來更高的延時和較低的吞吐，但在要求嚴格數據一致性的場景下，線性讀是 etcd 默認且理想的讀取方式。</p></li></ul><h2>4. 實戰演練：構建 KubeSphere 環境下的 etcd 服務</h2><h3>4.1 什麼是 KubeSphere？</h3><p>KubeSphere&nbsp;是在 Kubernetes&nbsp;之上構建的面向雲原生應用的分佈式操作系統，完全開源，支持多雲與多集羣管理，提供全棧的 IT 自動化運維能力，簡化企業的 DevOps 工作流。它的架構可以非常方便地使第三方應用與雲原生生態組件進行即插即用 (plug-and-play) 的集成。</p><h3>4.2 架構説明</h3><p>KubeSphere 將前端與後端分開，實現了面向雲原生的設計，後端的各個功能組件可通過 REST API 對接外部系統。可參考 API 文檔。下圖是系統架構圖。KubeSphere 無底層的基礎設施依賴，可以運行在任何 Kubernetes、私有云、公有云、VM 或物理環境（BM）之上。此外，它可以部署在任何 Kubernetes 發行版上。</p><p><img src="https://oscimg.oschina.net/oscnet/up-47654e91babcf7bcd46cf2f153768394038.png" alt="" referrerpolicy="no-referrer"></p><h3>4.3 為什麼選擇 KubeKey</h3><p>KubeKey 由 Go 語言開發，使用便捷、輕量，支持多種主流 Linux 發行版。KubeKey 支持多種集羣部署模式，例如 All-in-One、多節點、高可用以及離線集羣部署。KubeKey 也支持快速構建離線安裝包，加速離線交付場景下的集羣交付效率。KubeKey 實現多節點並行安裝，且利用 Kubeadm 對集羣和節點進行初始化，極大地節省了集羣部署時間，同時也遵循了 Kubernetes 社區主流集羣部署方法。KubeKey 提供內置高可用模式，支持一鍵部署高可用 Kubernetes 集羣。</p><h3>4.4 環境準備</h3><p>為了演示效果使用 all-in-one 快速部署。</p><h4>4.4.1 獲取 KubeKey</h4><pre><code class="language-yaml">export KKZONE=cn
</code></pre><pre><code class="language-yaml">curl -sfL https://get-kk.kubesphere.io | VERSION=v3.0.13 sh -
</code></pre><pre><code class="language-yaml">chmod +x kk
</code></pre><h4>4.4.2 安裝 Kubernetes+KubeSphere</h4><pre><code class="language-yaml">./kk create cluster --with-kubernetes v1.22.12 --with-kubesphere v3.4.1
</code></pre><p><img src="https://oscimg.oschina.net/oscnet/up-f62358927456f293fd4c00f1961169fcbc4.png" alt="" referrerpolicy="no-referrer"></p><h4>4.4.3 檢查集羣狀態</h4><p><img src="https://oscimg.oschina.net/oscnet/up-4c4e05f3208543b4751c8f7d65c9c8e0f8d.png" alt="" referrerpolicy="no-referrer"></p><h4>4.4.4 安裝 etcdctl 工具（可選）</h4><p>使用 KubeKey 部署集羣會默認安裝 etcdctl。</p><pre><code class="language-yaml">https://github.com/etcd-io/etcd/releases  #自行下載
</code></pre><pre><code class="language-yaml">tar -zxvf etcd-v3.5.11-linux-amd64.tar.gz
</code></pre><pre><code class="language-yaml">cp etcdctl /usr/local/bin/
</code></pre><h4>4.4.5 獲取證書並查看 etcd 狀態</h4><p>説明：KubeKey 安裝集羣時默認 etcd 使用二進制安裝，證書路徑默認在此處。</p><pre><code class="language-yaml">/etc/ssl/etcd/ssl
</code></pre><p><img src="https://oscimg.oschina.net/oscnet/up-e2c17f21c96bb35b76d9f7c7aa1ee901230.png" alt="" referrerpolicy="no-referrer"></p><p>通過採用 KubeKey 工具實施最小化部署案例，展示瞭如何運用安全證書機制來實現對 etcd 的訪問以監控集 etcd 服務狀態。儘管此處演示以單一實例呈現，但在實際生產環境中，etcd 服務必然是基於高可用集羣模式運行，始終堅守着高可靠性的核心原則。</p><h3>4.6 etcd 部署建議</h3><h4>4.6.1 系統要求</h4><p>為保證 etcd 性能，推薦使用 SSD 硬盤，並通過工具（如 fio）進行磁盤速度評估。建議系統配置至少與默認存儲配額（2GB）相等的 RAM，一般推薦 8GB 以上以避免性能下降。典型部署中，etcd 集羣應在具有雙核 CPU、2GB 內存和 80GB SSD 的專用服務器上運行。請根據實際工作負載對硬件配置進行調整並預先測試，確保生產環境性能達標。</p><h4>4.6.2 集羣成員數量儘量為奇數</h4><p>etcd 集羣達成狀態更新共識需要多數節點參與，即至少（n/2）+1 個成員在具有 n 個節點的集羣中。對於奇數節點數量的集羣，增加一個節點雖表面上增強了系統規模，但實際上降低了容錯性：相同數量節點故障時仍能保持仲裁，但更多節點故障可能導致仲裁丟失。因此，在集羣無法容忍額外故障且新節點可能註冊失敗的情況下，貿然添加節點是危險的，因為這可能導致永久性的仲裁損失。</p><h4>4.6.3 最大集羣大小不超過 7 個</h4><p>理論上，etcd 集羣規模無明確上限，但實踐中推薦不超過 7 個節點。參照 Google 內部廣泛部署的 Chubby 鎖服務經驗，建議維持 5 節點配置。這樣的集羣能容忍兩個成員故障，通常已滿足需求。儘管更大集羣提升容錯性，但會因數據在更多節點上的複製而導致寫入性能下降。</p><h2>5. etcd 集羣運維那些事兒</h2><h3>5.1 監控及告警</h3><p>在構建和運維 etcd 集羣時，監控是確保業務穩定性和提前識別風險的關鍵步驟。</p><p>etcd 提供了眾多 metrics，按模塊劃分包括磁盤、網絡、MVCC 事務、gRPC RPC 和 etcdserver 等核心指標，用於展示集羣健康狀況。為了有效監控這些指標，推薦使用 Prometheus 服務採集 etcd 2379 端口的 metrics 數據，並可通過靜態或動態配置實現。</p><h4>5.1.1 靜態配置</h4><p>靜態配置需手動在 Prometheus 配置文件中的 scrape_configs 下添加新 job，內容包含被監控的 etcd 集羣地址，如開啓了認證還需配置證書等。</p><p>示例：</p><pre><code class="language-yaml">scrape_configs:
  - job_name: 'etcd'
    static_configs:
      - targets: ['&lt;etcd-node-1&gt;:2379', '&lt;etcd-node-2&gt;:2379', '&lt;etcd-node-3&gt;:2379']
    metrics_path: '/metrics'
    scheme: 'https'
    tls_config:
      ca_file: /path/to/prometheus-server/ca.pem  # 在 Prometheus 服務器上的 CA 證書路徑
      cert_file: /path/to/prometheus-server/client.pem  # 客戶端證書路徑
      key_file: /path/to/prometheus-server/client-key.pem  # 客戶端密鑰路徑
</code></pre><h4>5.1.2 動態配置</h4><p>動態配置藉助 Prometheus-Operator 的 ServiceMonitor 機制，可自動發現並採集 Kubernetes 集羣中的 etcd 服務 metrics。通過創建 ServiceMonitor 資源，Prometheus 可根據 Namespace 和 Labels 自動關聯待監控的服務 Endpoint。</p><p>示例：</p><pre><code class="language-yaml">apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: etcd-service-monitor
  namespace: monitoring
spec:
  selector:
    matchLabels:
      app: etcd # 根據服務標籤選擇匹配的服務
  endpoints:
  - port: http-metrics
    scheme: https
    tlsConfig:
      caFile: /etc/prometheus/secrets/etcd-certs/ca.crt
      certFile: /etc/prometheus/secrets/etcd-certs/client.crt
      keyFile: /etc/prometheus/secrets/etcd-certs/client.key
      insecureSkipVerify: true
  namespaceSelector:
    matchNames:
    - kube-system # 指定監控哪個命名空間下的服務
</code></pre><p><img src="https://oscimg.oschina.net/oscnet/up-1c358cfdf24a005aa12e1d840d0a19bc5ab.png" alt="" referrerpolicy="no-referrer"></p><p>獲取監控數據後，利用 Prometheus 與 Alertmanager 組件設置告警規則至關重要，重點關注影響集羣可用性的核心 metric，例如 Leader 狀態、切換次數及 WAL 和事務操作延時等。社區提供了一些參考告警規則。</p><p>最後，為了提升運維效率和問題定位能力，可以基於收集到的 metrics，在 Grafana 中創建可視化面板，展示集羣 Leader 狀態、key 總數、watcher 數、出流量以及 WAL 持久化延時等關鍵運行狀態指標。</p><p><img src="https://oscimg.oschina.net/oscnet/up-87fbf7d9d8847b546cc3237ec9da4effeb6.png" alt="" referrerpolicy="no-referrer"></p><h3>5.2 數據及還原</h3><p>在完成監控與告警設置後，確保 etcd 集羣在生產環境安全使用還需進行數據備份。針對數據備份，有以下幾種方法：</p><h4>5.2.1 手動備份恢復</h4><p>通過指定端口、證書進行手動備份。</p><pre><code class="language-yaml">etcdCTL_API=3 etcdctl --endpoints=https://127.0.0.1:2379 \
  --cacert=&lt;trusted-ca-file&gt; --cert=&lt;cert-file&gt; --key=&lt;key-file&gt; \
  snapshot save &lt;backup-file-location&gt;
</code></pre><p>使用備份的數據進行恢復。</p><pre><code class="language-yaml">etcdCTL_API=3 etcdctl --endpoints=https://127.0.0.1:2379 \
  --cacert=&lt;trusted-ca-file&gt; --cert=&lt;cert-file&gt; --key=&lt;key-file&gt; \
  restore save &lt;backup-file-location&gt;
</code></pre><h4>5.2.2 定時自動備份</h4><p>建議每小時至少備份一次，可通過定時任務實現。</p><h4>5.2.3 自動化備份</h4><p>利用 etcd-backup-operator 工具，通過創建備份任務 CRD 實現自動化備份管理，例如配置備份頻率、最大保留備份數量以及 S3 存儲等參數。</p><p>示例：</p><pre><code class="language-yaml">apiVersion: "etcd.database.coreos.com/v1beta2"
kind: etcdBackup
metadata:
  name: example-etcd-cluster-backup
spec:
  etcdEndpoints: ["http://etcd-cluster-endpoint:2379"] # 替換為你的 etcd 集羣實際端點
  storageType: S3
  backupPolicy:
    backupIntervalInSecond: 3600 # 每小時執行一次備份（這裏僅為示例，可自定義間隔時間）
    maxBackups: 5 # 最多保留 5 個備份文件
  s3:
    path: "my-s3-bucket/etcd/backups" # 替換為 S3 存儲桶路徑
    awsSecret: qy-credentials # 替換為引用 qy 憑據 secret 的名稱
</code></pre><p>最後，為了實現跨地域熱備，可在 etcd 集羣中添加 Learner 節點。Learner 節點作為非投票成員，不影響集羣性能，其原理是跟隨 Leader 節點同步日誌信息。不過請注意，在 etcd 3.4 版本中，僅支持一個 Learner 節點且串行讀取。</p><h2>6. 未來可期：展望 etcd 在 Kubernetes 生態系統中持續創新的可能性與挑戰</h2><p>在 Kubernetes 生態系統中，etcd 作為核心組件起着不可或缺的作用。隨着雲原生技術的持續演進，etcd 在 Kubernetes 體系中的創新空間及潛在挑戰值得關注。面對未來，etcd 同樣需要應對諸多挑戰，包括如何高效處理海量數據增長、如何更好地兼容異構基礎設施接入，以及如何有效抵禦不斷演變的安全風險。但相信在廣大開發者的共同努力下，etcd 將持續突破，在 Kubernetes 生態系統內推動技術創新，穩固其基石地位。</p><blockquote><p>本文由博客一文多發平台 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopenwrite.cn%3Ffrom%3Darticle_bottom" target="_blank">OpenWrite</a> 發佈！</p></blockquote></div>
                                    ]]>
            </description>
            <pubDate>Sat, 02 Mar 2024 02:42:36 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/4197945/blog/11044560</guid>
            <link>https://my.oschina.net/u/4197945/blog/11044560</link>
            <author>
                <![CDATA[原創]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[向使當時真開源，小人/君子有誰知？某開源賬號引發眾怒]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>近日 Github 一標記為 Alibaba 的賬戶（https://github.com/HumanAIGC）被發現大量空頭開源倉庫：<strong>這些倉庫大多有幾百上千的 Star，而無實質內容</strong>。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-0ce013d83e7939e4945c1bd3ead549a1ea4.png" referrerpolicy="no-referrer"></p><p>這些項目包括：</p><ol><li>https://github.com/HumanAIGC/EMO （4.4k star）</li><li>https://github.com/HumanAIGC/AnimateAnyone （13.3k star）</li><li>https://github.com/HumanAIGC/VividTalk （644 star）</li><li>https://github.com/HumanAIGC/OutfitAnyone （4.6k star）</li><li><p>https://github.com/HumanAIGC/MaTe3D （67 star）</p></li></ol><p>它們普遍無實質性內容，僅發佈有限文件：README.md、LICENCE、doc/下的一些圖片、視頻等。相關圖片見附錄 1。</p><p>另一個特徵是，它們多和 AIGC 論文相關，相關論文信息見附錄 2。</p><p>目前已經有大量網友提起 issue，聲討這種在開源社區打廣告而不公開實質性內容的行為，主要內容包括：</p><ol><li>把開源社區當廣告區是否合理？</li><li>空殼項目能拿這麼多 star，是否正常？</li><li>真 EMO，假論文，騙績效。</li><li>我不在乎是否開源，起碼把 api 放出來讓我玩啊。（<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FHumanAIGC%2FEMO%2Fissues%2F75" target="_blank">I don't mind it is open source or not, pls make the product or API so I could pay for it）</a></li><li>代碼呢？</li><li>&nbsp;建議阿里把這羣騙子裁掉，有損公司名譽，丟中國人的臉</li></ol><p>此外，在 pull request 方面，存在着一些不知所云的內容，例如 EMO 項目：</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-a856f161261f63318cefcafe6d5ba980fa3.png" referrerpolicy="no-referrer"></p><hr><p>評論</p><hr><p>附錄 1：</p><pre><code>@misc{tian2024emo,
      title={EMO: Emote Portrait Alive - Generating Expressive Portrait Videos with Audio2Video Diffusion Model under Weak Conditions}, 
      author={Linrui Tian and Qi Wang and Bang Zhang and Liefeng Bo},
      year={2024},
      eprint={2402.17485},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
</code></pre><pre><code>@article{zhou2023mate3d,
  title     = {MaTe3D: Mask-guided Text-based 3D-aware Portrait Editing},
  author    = {Kangneng Zhou, Daiheng Gao, Xuan Wang, Jie Zhang, Peng Zhang, Xusen Sun, Longhao Zhang, Shiqi Yang, Bang Zhang, Liefeng Bo, Yaxing Wang},
  journal   = {arXiv preprint arXiv:2312.06947},
  website   = {https://humanaigc.github.io/MaTe3D/},
  year      = {2023}}
</code></pre><pre><code>@article{hu2023animateanyone,
  title={Animate Anyone: Consistent and Controllable Image-to-Video Synthesis for Character Animation},
  author={Li Hu and Xin Gao and Peng Zhang and Ke Sun and Bang Zhang and Liefeng Bo},
  journal={arXiv preprint arXiv:2311.17117},
  website={https://humanaigc.github.io/animate-anyone/},
  year={2023}
}</code></pre><pre><code>@article{sun2023vividtalk,
  title     = {VividTalk: One-Shot Audio-Driven Talking Head Generation Based 3D Hybrid Prior},
  author    = {Xusen Sun, Longhao Zhang, Hao Zhu, Peng Zhang, Bang Zhang, Xinya Ji, Kangneng Zhou, Daiheng Gao, Liefeng Bo, Xun Cao},
  journal   = {arXiv preprint arXiv:2312.01841},
  website   = {https://humanaigc.github.io/vivid-talk/},
  year      = {2023},</code></pre><p>附錄 2：部分項目截圖</p><p><img alt="" height="1716" src="https://oscimg.oschina.net/oscnet/up-e7f92fdbff5f155a7d03276013c45a2d3b6.png" width="797" referrerpolicy="no-referrer"></p><p>&nbsp;</p></div>
                                    ]]>
            </description>
            <pubDate>Fri, 01 Mar 2024 22:17:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/281116</guid>
            <link>https://www.oschina.net/news/281116</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[馬斯克起訴 OpenAI 及其 CEO 奧特曼，要求公司恢復開源狀態]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>當地時間週四晚間，特斯拉 CEO 埃隆·馬斯克向舊金山高等法院提起訴訟，以違反合同為由起訴 OpenAI 及其 CEO 薩姆·奧特曼。</p><p>馬斯克在訴訟中表示，奧特曼和 OpenAI 違背了這家人工智能研究公司成立時達成的一項協議，即開發技術以造福人類而不是追逐利潤。</p><blockquote><p><img src="https://oscimg.oschina.net/oscnet/up-c1344f68b8ada81d79b927740c5e75e2cce.png" referrerpolicy="no-referrer"></p><p><em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftwitter.com%2FxDaily%2Fstatus%2F1763464048908382253" target="_blank">https://twitter.com/xDaily/status/1763464048908382253</a></u></em></p></blockquote><p>馬斯克聲稱 OpenAI 最近與科技巨頭微軟的關係損害了該公司最初致力於公共、開源的通用人工智能。自從公司將其開發的人工通用智能技術 (AGI) 以閉源形式交給微軟後，OpenAI 已經失去了其「開放」的本質。</p><blockquote><p>GPT-4 的內部細節只有 OpenAI 知道，據悉微軟也知道。因此，<strong>GPT-4 與'開放人工智能'恰恰相反</strong>。</p><p>它的封閉是出於商業考慮：微軟通過向公眾出售 GPT-4 獲得鉅額收益，但如果 OpenAI 按照要求將這項技術免費提供給公眾，那麼這是不可能的。</p></blockquote><p>馬斯克提出的訴訟包括違反合同、違反受託責任和不公平的商業行為。<strong>他要求公司恢復到開源狀態</strong>，並尋求法院頒佈禁令，以阻止 OpenAI 及其高管——包括被列為共同被告的總裁格雷戈裏·布羅克曼和 CEO 薩姆·奧特曼——以及微軟，利用公司的人工通用智能技術獲利。</p><p><span style="background-color:#ffffff; color:#0f1419">馬斯克是 OpenAI 最初的董事會成員之一，於 2018 年離開，他認為董事會與奧特曼之間的衝突源自 GPT-4 的開發和下一代 AGI 技術的潛在開發，這可能會危及公眾安全。 </span></p><p>詳情：<em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.courthousenews.com%2Felon-musk-sues-openai-over-ai-threat%2F" target="_blank">https://www.courthousenews.com/elon-musk-sues-openai-over-ai-threat/</a></u></em></p></div>
                                    ]]>
            </description>
            <pubDate>Fri, 01 Mar 2024 08:38:04 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/281047/elon-musk-sues-openai-over-ai-threat</guid>
            <link>https://www.oschina.net/news/281047/elon-musk-sues-openai-over-ai-threat</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[魅族 21 PRO 發佈，面向所有大模型團隊開放]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#222222">魅族發佈 21 PRO 手機，定價 4999~5899 元</span>。<span style="color:#333333">2 月 29 日 20:00 在魅族商城、各大授權電商、魅族線下門店開啓預售，3 月 2 日 10:00 線下線下全渠道開售。</span></p><p><span style="color:#222222">魅族稱其是公司歷史上首個開放式 AI 終端，並面向</span>所有的大模型團隊進行開放，向開發者提供系統權限、API 文檔，並開放處理器的 AI 算力。<span style="color:#333333">魅族「百萬懸賞」計劃也宣佈同步啓動，邀請更多團隊基於魅族開放平台開發大模型應用。</span></p><p>基於 FlymeOS 操作系統，魅族 21 PRO 將實現包括 Aicy 語音助手、AI 圖庫在內的多項 AI 功能。根據規劃，魅族 21 PRO 的 AI 靈動鍵和 AI 輔助輸入等功能也將在今年上半年陸續推出。</p><p><img alt="" height="443" src="https://oscimg.oschina.net/oscnet/up-694cfed6a8793190b89faae0e8477609ea1.jpg" width="300" referrerpolicy="no-referrer"></p></div>
                                    ]]>
            </description>
            <pubDate>Fri, 01 Mar 2024 08:07:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/281036</guid>
            <link>https://www.oschina.net/news/281036</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[OpenNJet telemetry 支持 Ubuntu 環境！]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div><span><a href="https://gitee.com/njet-rd/njet-telemetry">Gitee 代碼倉庫</a>提供瞭如何使用源碼在 ubuntu 環境下進行編譯的方法；並且提供了 v2.0.1 版本的 deb 安裝包，可直接通過 apt 源（<span style="background-color:#ffffff; color:#000000">Openet apt 源使用方法:&nbsp;</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fnjet.org.cn%2Fcases%2Fapt-online%2F" target="_blank">https://njet.org.cn/cases/apt-online/</a>）進行下載安裝使用：</span></div><ul><li><span>&nbsp;apt update</span></li><li><span>&nbsp;apt search njet-otel</span></li><li><span>&nbsp;apt install njet-otel</span></li></ul></div>
                                    ]]>
            </description>
            <pubDate>Fri, 01 Mar 2024 08:04:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/281034</guid>
            <link>https://www.oschina.net/news/281034</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[開源中國 APP 全新上線：「動彈」迴歸、集成大模型對話、暢讀技術報告]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>經過數月籌備和研發的<strong>新版開源中國 APP —— 今日正式上線</strong>！</p><p>在當今 AI 浪潮的衝擊下，我們身處一個充滿無限可能的時代。在這個時代，技術的發展呈現出前所未有的速度和深度，而開發者無疑是引領這股潮流的關鍵力量。</p><p>開源中國不忘「為開發者服務」的初心，希望將 APP 打造成 AI 浪潮中的一艘航船，和廣大開發者一起遠行。</p><p>閒言少敍（要敍咱去<strong><span style="background-color:#e67e22">「動彈」</span></strong>敍），先來感受一波新版 APP 的絲滑體驗：</p><p>&nbsp;</p><p style="text-align:center"><img height="889" src="https://oscimg.oschina.net/oscnet/up-925497f35e3f24a14318d7b6ad12f2ed5d4.gif" width="400" referrerpolicy="no-referrer"></p><p>&nbsp;</p><p>新版本 APP 亮點版塊</p><ul><li><p><strong><span style="background-color:#e67e22">「廣場」</span></strong>：「動彈」迴歸、最新鮮開源資訊、最全開源軟件庫</p></li><li><p><strong><span style="background-color:#e67e22">「報告」</span></strong>：暢讀技術報告</p></li><li><p><strong><span style="background-color:#e67e22">「O Insight」</span></strong>：集成大模型對話</p></li></ul><p>下面繼續看看詳細的新功能體驗。</p><h3><span style="color:#f39c12"><strong># 動彈</strong></span></h3><p>大家期待已久的開源中國社區「靈魂」——動彈終於不負眾望迴歸了！</p><p>動彈移動版上線，歡迎大家暢所欲言。在這裏，您可以和廣大程序員交流互動，分享經驗、討論技術話題，還可隨時隨地查看開發者各類分享和吐槽。</p><p style="text-align:center"><img height="889" src="https://oscimg.oschina.net/oscnet/up-7c3c3c0ed0058a81a6d0115364fe9e5faed.gif" width="400" referrerpolicy="no-referrer"></p><h3><span style="color:#f39c12"><strong># 大模型對話</strong></span></h3><p>置身 AI 浪潮，新版開源中國 APP 新增大模型對話，準確率高，提供齊全的數據內容；還可選擇「社區版、智普 AI 、導師版」三個不同版本；</p><p style="text-align:center"><img height="895" src="https://oscimg.oschina.net/oscnet/up-764690510ca07e10016c28ed8240767c06e.gif" width="400" referrerpolicy="no-referrer"></p><h3><span style="color:#f39c12"><strong># 開源報告</strong></span></h3><p>新版開源中國 APP 還新增報告模塊，包含「開源日報、開發者研究、行業研究」三類研究報告，涵蓋了開發領域的最新技術趨勢和前沿研究。</p><p style="text-align:center"><img height="889" src="https://oscimg.oschina.net/oscnet/up-842e51ced6d226559af1af95c8041338cb2.gif" width="400" referrerpolicy="no-referrer"></p><p>&nbsp;</p><p>這些報告不僅是您學習、探索的寶藏，更是洞悉行業動態的重要參考。通過開源中國 APP，您可以隨時隨地獲取最新的技術資訊，緊跟行業的脈搏，把握未來發展的方向。</p><p>&nbsp;</p><p>除了上面介紹的功能，新版 APP 還有許多其他改進，歡迎大家掃碼下載安裝體驗 ↓↓↓</p><h4 style="text-align:center"><img alt="" height="300" src="https://oscimg.oschina.net/oscnet/up-8ab7bb9f45ecaae87f7a862ea446ae1dacf.png" width="300" referrerpolicy="no-referrer"><br><strong><span style="background-color:#e67e22">（</span><em><span style="background-color:#e67e22">目前僅提供 Android 版本</span></em><span style="background-color:#e67e22">）</span></strong></h4><p>另外，後續我們還將推出「智能終端」，敬請期待。</p><hr><p>身處人工智能時代，開源中國社區積極擁抱創新，致力於服務每一位開發者。</p><p>2024，開源中國社區將全面加速擁抱 AI 技術，提供研究報告、大模型應用、AIGC 創作等產品，打造一個充滿活力和創新的開源技術生態社區。</p><p>2024，開源中國社區全新起航！</p></div>
                                    ]]>
            </description>
            <pubDate>Fri, 01 Mar 2024 07:58:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/281031/oschina-app-2024</guid>
            <link>https://www.oschina.net/news/281031/oschina-app-2024</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Stack Overflow 向谷歌 Gemini 開放 API]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">Stack Overflow 和 Google Cloud <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fstackoverflow.co%2Fcompany%2Fpress%2Farchive%2Fgoogle-cloud-strategic-gen-ai-partnership" target="_blank">宣佈</a>建立戰略合作伙伴關係，將通過 Stack Overflow 平台、Google Cloud Console 和 Gemini for Google Cloud 為開發者提供新的 AI 功能。</span></p><p><span style="color:#000000">他們新推出了一個&nbsp;Overflow API，使得 Google 的 Gemini AI 模型能夠訪問 Stack Overflow 的知識庫，為開發人員提供來自 Stack Overflow 的建議、代碼和答案。Overflow API 目前正處於開發階段，預計將在 4 月份舉行的 Google Cloud Next 會議上預覽，並於 2024 年上半年推出。</span></p><p><img height="251" src="https://oscimg.oschina.net/oscnet/up-1882278c0c317615884d15fe98b7c0c961f.png" width="500" referrerpolicy="no-referrer"></p><p><span style="color:#000000">這次合作除了可以幫助谷歌改進&nbsp;Gemini 外，對&nbsp;Stack Overflow 而言也有助於其在 AI 浪潮中保持對開發人員的影響力。此前，Stack Overflow 就推出了一項 OverflowAI 產品，旨在為其平台添加生成式 AI 功能。藉助於谷歌的合作，其 OverflowAI 產品也或將得到增強。</span></p><p><span style="color:#000000">另一方面，Stack Overflow 去年已經經歷了多輪裁員。因此 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.infoworld.com%2Farticle%2F3713343%2Fstack-overflow-opens-api-to-googles-gemini.html" target="_blank">InfoWorld</a> 指出，儘管谷歌是 Overflow API 的啓動合作伙伴，但 Stack Overflow 也有意與更多希望利用其知識庫和內容培訓 LLM 的公司達成合作。共享數據用於模型訓練可以成為公司新的收入來源，也可以為公司提供槓桿，確保在開發人員經常使用的平台上提供數據。</span></p><p><span style="color:#000000">谷歌和 Stack Overflow 沒有透露具體的合作財務條款。</span></p></div>
                                    ]]>
            </description>
            <pubDate>Fri, 01 Mar 2024 06:39:15 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/281010/stack-overflow-api-googles-gemini</guid>
            <link>https://www.oschina.net/news/281010/stack-overflow-api-googles-gemini</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[萬字帶你走過數據庫的這激盪的三年]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><img src="https://nebula-website-cn.oss-cn-hangzhou.aliyuncs.com/nebula-blog/andy-database-review/database-review.jpg" alt="" referrerpolicy="no-referrer"></p><p>本文收集了卡內基梅隆大學計算機科學系數據庫學副教授 Andy Pavlo 從 2021 到 2023 連續三年對數據庫領域的回顧，希望通過連續三年的回顧讓你對數據庫領域的技術發展有所瞭解。</p><blockquote><p>關於 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.cs.cmu.edu%2F%7Epavlo%2F" target="_blank">Andy Pavlo</a>：卡內基梅隆大學計算機科學系數據庫學副教授，數據庫調優公司 OtterTune 的 CEO 兼聯合創始人。</p></blockquote><p>為了聚焦於數據庫技術趨勢演變，本文未對原文「寒暄式」開頭和註釋性語句作翻譯。此外，為了節約部分讀者的時間，本文分為「觀點簡述」及「歷年回顧」兩部分：在「觀點簡述」部分，你將瞭解到 Andy 這 3 年對數據庫的看法、見解；在「歷年回顧」部分，你將瞭解到該年具體的數據庫領域發生的事件，以及 Andy 對該事件的看法。</p><p>本文目錄：</p><ul><li>觀點簡述</li><li>歷年回顧 
  <ul><li>2023 年數據庫回顧：向量數據庫雖然大火，但沒有技術壁壘 
    <ul><li>向量數據庫的崛起 
      <ul><li>Andy 説：向量數據庫沒有技術護城河</li></ul></li><li>SQL 持續變好 
      <ul><li>屬性圖查詢（SQL/PGQ）</li><li>多維數組（SQL/MDA）</li><li>Andy 説：SQL:2023 是個里程碑</li></ul></li><li>MariaDB 的困境 
      <ul><li>Andy 説：數據庫的聲譽比以往任何時候都重要</li></ul></li><li>美國航空因政府數據庫崩潰而停飛 
      <ul><li>Andy 説：歷史悠久的核心數據系統，是每個數據庫從業者最大的噩夢</li></ul></li><li>數據庫的融資情況 
      <ul><li>Andy 説：無論初創公司，還是高估值的公司日子都不好過</li></ul></li><li>史上最貴的密碼重置 
      <ul><li>Andy 説：意料之外的大人物生活</li></ul></li></ul></li><li>2022 年數據庫回顧：江山代有新人出，區塊鏈數據庫還是那個傻主意 
    <ul><li>放緩的大規模數據庫融資 
      <ul><li>Andy 説：不只是 OLAP 領域，OLTP 領域前景也一樣嚴峻</li></ul></li><li>區塊鏈數據庫還是那個蠢點子 
      <ul><li>Andy 説：有讓人信服的用例才是合格的新技術</li></ul></li><li>新的數據系統 
      <ul><li>Andy 説：欣然看到數據庫領域的勃勃生機</li></ul></li><li>數據庫先驅的逝世 
      <ul><li>Andy 説：這是一個讓人難過的消息</li></ul></li><li>數據庫的鉅額財富和民主 
      <ul><li>Andy 説：Larry 幹得漂亮</li></ul></li></ul></li><li>2021 年數據庫回顧：性能之爭烽煙起，不如低調搞大錢 
    <ul><li>PostgreSQL 的主導地位 
      <ul><li>Andy 説：PostgreSQL 只會在未來幾年變得更好</li></ul></li><li>基準測試之爭 
      <ul><li>Databricks vs Snowflake</li><li>Rockset vs Apache Druid vs ClickHouse</li><li>ClickHouse vs TimescaleDB</li><li>Andy 説：性能之爭不值當</li></ul></li><li>大數據搞大錢 
      <ul><li>Andy 説：我們正處在數據庫的黃金時代</li></ul></li><li>消逝的數據庫們 
      <ul><li>ServiceNow 收購了 Swarm64</li><li>Splice Machine 破產了</li><li>私募公司收購了 Cloudera</li><li>Andy 説：2022 年可能會有更多的數據庫公司倒閉</li></ul></li><li>堅持的回報 
      <ul><li>Andy 説：為 Larry 高興</li></ul></li></ul></li></ul></li></ul><h2>觀點簡述</h2><p>從 2021 年興起的數據庫性能之爭，似乎經過 2 年時間的洗禮，熱度有所降低，2022、2023 的數據庫廠商們相對 Peace 並沒有發起過多的性能戰。枯木又逢春，儘管向量數據庫存在已久，2023 年 vector database 又大火的一把。不過在 Andy 看來，向量數據庫並沒有技術壁壘：有多種現成的集成方式，可快速集成向量能力到現有的數據庫，這些集成方式甚至還有開源的，更是大大降低數據庫廠商的集成成本。SQL 新規範 SQL:2023 在對圖數據的支持上，雖然目前只是做了讀查詢的適配，在 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fconfluence.nebula-graph.io%2Fpages%2Fviewpage.action%3FpageId%3D103353671" target="_blank">Oracle v23c</a> 給出了 Oracle 的圖查詢示例。不過，目前跟進 SQL/PGQ 的 DBMS 不多，像是 DuckDB 的實驗性分支；此外，Andy 覺得 SQL/PGQ 對現有的圖數據庫並不會造成威脅，畢竟還有查詢的性能問題需要攻克。在多維數組的支持上，SQL 新規範強化了數組功能，支持了真正意義上的數組——任意維度的數組。</p><p>在融資方面，2021 年是融資大年，各類數據庫無論是初創還是老牌數據庫廠商都能融到八位數的融資；到了 2022 年，上半年依舊保持着「好融資，融資高」的勁頭，但在下半年融資情況急轉直下，大額度的融資變少了，資金縮緊。這個情況延續到了 2023 年，除了市場融資變冷清之外，更多的資金集中到了同向量相關的領域，雖然還是有一些數據庫廠商「破局」成功融到了錢。</p><p>在數據庫可持續發展方面，自 2021 年 Swarm64、Cloudera 被收購，Splice Machine 破產之後。隨後的 2022、2023 年，MarkLogic、Ahana、EverSQL、Seafowl 也先後分別被 Progress Software、IBM、Aiven、EnterpriseD 收購，結束了他們的「獨立」生涯。</p><p>這 3 年也發生了一些逸事，比如 Oracle 的聯合創始人 Larry Ellison 雖然在 2018 年在億萬富翁排名中跌至第十位，但是在 2021 年重返第五位，甚至在 2023 年僅次於 Bernard Arnault、Elon Musk、Jeff Bezos 以 1,070 億美元名列第四。此外，Larry Ellison 在 2023 年還花了 10 億給 Elon Musk 來重置他的 Twitter 密碼好繼續他的推特之旅。習慣用子女名來命名數據庫的 MySQL、MaxDB、MariaDB 之父 Monty Widenus 估計最近的日子不好過，因為 MariaDB 的公司和基金會發生了一些矛盾，不僅如此，它的市值還蒸發了 90%。</p><p>除了上面的一些事件，像是美國航空因政府數據庫崩潰而停飛 11,000 多架飛機、區塊鏈數據庫是個蠢點子之類的指控，就得你翻閲歷年回顧了。</p><h2>歷年回顧</h2><h3>2023 年數據庫回顧：向量數據庫雖然大火，但沒有技術壁壘</h3><blockquote><p>英文原文：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fottertune.com%2Fblog%2F2023-databases-retrospective" target="_blank">https://ottertune.com/blog/2023-databases-retrospective</a></p></blockquote><h4>向量數據庫的崛起</h4><p>毫無疑問，2023 年是向量數據庫的一年。儘管幾年前相關的某些系統早已存在，但去年人們對 LLM 及其上構建的服務（例如，ChatGPT）的廣泛關注讓向量數據庫成為大家的視線焦點。向量數據庫旨在基於語義，而不僅僅是數據內容來提供更深層的數據檢索能力，特別是針對非結構化數據。也就是説，應用程序可以搜索與<strong>主題相關</strong>的文檔（例如，「有 Slinging 相關歌曲的 hip-hop 團體」），而<strong>不是包含精準關鍵字</strong>（例如，「Wu-Tang Clan」）的文檔。</p><p>這種主題搜索所依賴的「魔法」是 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fen.wikipedia.org%2Fwiki%2FTransformer_%28deep_learning_architecture%29" target="_blank">transformer</a>，它將數據轉換為一個固定長度的一維浮點數向量，稱之為嵌入 Embedding。人類雖然不能直接理解這些嵌入的值，但嵌入的內容編碼了參數和 transformer 訓練語料庫之間的某種關係。這些嵌入向量的大小從簡單 transformer 的數百維到高端模型的數千維不等。</p><p>假如，我們使用 transformer 為數據庫中的所有記錄生成嵌入，就能通過查找與給定輸入在高維空間中最相近的記錄嵌入來搜索相似記錄。然而，暴力比較所有向量以找到最相近的匹配結果是非常昂貴的。這種暴力搜索的複雜度是 O(N * d * k)，其中 N 是嵌入的數量，d 是每個向量的大小，k 是你想要的匹配數量——你可能不知道這個複雜度代表什麼，反正很糟糕就是。</p><p>這也促成向量數據庫的崛起。本質上，向量數據庫只是一個帶有特定索引數據結構的文檔數據庫，以加速對嵌入的相似性搜索。不同於對查詢進行精準匹配來找到最相似的向量，向量數據庫用近似搜索來生成結果，在速度和精度之間做了權衡，這種結果做出了「足夠好」的折中。</p><p>在 2022 年區塊鏈數據庫神話崩盤之後，風投們嗅到了向量數據庫的商機，再次變得興奮。他們幾乎投資了向量數據庫領域的所有主流玩家（廠商）們。在 2023 年的種子輪融資中，Marqo 爆出了一個 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.prnewswire.com%2Fnews-releases%2Fmarqo-secures-us5-2m-to-bring-continuous-learning-vector-search-to-businesses-301902319.html" target="_blank">520 萬美元的種子輪</a>，Qdrant 拿到了 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftechcrunch.com%2F2023%2F04%2F19%2Fqdrant-an-open-source-vector-database-startup-wants-to-help-ai-developers-leverage-unstructured-data%2F" target="_blank">750 萬美元的種子輪</a>，而 Chroma 則融到一個鉅額的 1,800 萬美元種子輪。同年 4 月，Weaviate 在 B 輪成功融到 5,000 萬美元。最搶眼的還是 2023 年 Pinecone 在 B 輪融到讓人羨慕的 1 億美元。很顯然，向量數據庫公司在正確的時間點出現在了正確的賽道。</p><h5>Andy 説：向量數據庫沒有技術護城河</h5><p>自從 LLM 在 2022 年末隨着 ChatGPT 變成熱點，在<strong>不到一年的時間</strong>，多家 DBMS 廠商便添加了自己的向量搜索擴展，其中包括有 SingleStore、Oracle、Rockset 和 ClickHouse。同時，不少基於 PostgreSQL 的數據庫產品也宣佈支持向量搜索；有些使用 pgvector 擴展（像 Supabase、AlloyDB），而另外一些則使用其他的開源 ANN（近似最近鄰算法，Approximate Nearest Neighbor）庫，比如：Timescale、Neon。此外，領先的 NoSQL 數據庫，像 MongoDB 和 Cassandra，也支持了向量索引。</p><p>我們將多個 DBMS 對向量的快速支持，和先前 JSON 數據類型的興起做個有意思的對比。在 2000 年代後期，原生存儲 JSON 的 NoSQL 系統變得流行（像 MongoDB 和 CouchDB）。但在之後幾年時間裏，關係型 DBMS 的老牌廠商才添加了對 JSON 的支持，像 PostgreSQL、Oracle 和 MySQL 分別是在 2012、2014 和 2015 年支持的該類型。SQL 標準雖在 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fen.wikipedia.org%2Fwiki%2FSQL%3A2016" target="_blank">SQL:2016</a> 中添加了操作 JSON 數據的函數，但直到 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fpeter.eisentraut.org%2Fblog%2F2023%2F04%2F04%2Fsql-2023-is-finished-here-is-whats-new%23new-json-features" target="_blank">SQL:2023</a> 才添加了官方的 JSON 數據類型。儘管許多關係型 DBMS 已經支持了概念上相似的 XML，這種適配的拖延還是讓人唏噓。</p><p>向量搜索索引的快速支持有兩個可能的解釋。第一個是能通過嵌入進行的相似性搜索越發重要，以至於每個 DBMS 廠商都快速推出了自己的向量版本並第一時間宣佈該消息。第二個是引入新的訪問方法和索引數據結構所需的工程成本如此低，以至於 DBMS 廠家們添加向量搜索並不需要太多工作。大多數廠商甚至沒有從頭開始編寫向量索引，而是直接集成了幾個可用的高質量開源庫之一，像是 Microsoft DiskANN、Meta Faiss。</p><p>DBMS 集成向量搜索能力的成本如此低，向量 DBMS 廠商根本沒有足夠深的護城河來抵抗現有 DBMS 的侵略，保持競爭優勢。</p><p>我最近和兩家公司 Pinecone 和 Weaviate （上面提到融資成功的向量數據庫廠商）的聯合創始人聊過，他們可以走兩條路（詳情參考 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3D_QBZv5DrCUM%26t%3D3230s" target="_blank">Andy 對話 Weaviate CTO 的採訪視頻</a>）。第一條路是，客戶開始用向量 DBMS 作為「記錄數據庫」，廠商將為操作型工作提供更好的支持。最終，向量數據庫會看起來更像流行的文檔 DBMS，比如：MongoDB。接着，在五年內，像之前的 NoSQL 一樣增加對 SQL 的支持。另一條路是，向量 DBMS 作為次級數據庫，通過上游操作型 DBMS 的變更進行更新。就像人們使用 Elastic 和 Vespa 這樣的搜索引擎 DBMS 一樣。在這種情況下，向量 DBMS 可以在不擴展它們的查詢語言或擁有更結構化的數據模型的情況下生存。</p><p>旁註： 我最近錄製了一個關於<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3DjDhVEjgCHGk" target="_blank">向量與關係數據庫的問答節目</a>。在裏面我提到了，每個關係型 DBMS 在未來五年內都將擁有一個高性能的向量索引實現。</p><h4>SQL 持續變好</h4><p>今年 2024 年是 Don Chamberlain 和 Ray Boyce (RIP) 在 IBM 研究院創建 SQL 的五十週年。最初被稱為 SEQUEL（Structured English QUEry Language，結構化英語查詢語言）的 SQL，自 1980 年代以來，一直是與數據庫交互的事實標準。儘管 SQL 已經很老了，但它的使用情況和功能一直在增加，尤其是過去的十年。</p><p>去年，<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fen.wikipedia.org%2Fwiki%2FISO%2FIEC_9075" target="_blank">ISO/IEC 9075</a> 規範的最新版本 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fen.wikipedia.org%2Fwiki%2FSQL%3A2023" target="_blank">SQL:2023</a> 面世。這次更新包括了不少用來處理各種 SQL 方言中的痛點和不一致性的「好用功能」，比如：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fpeter.eisentraut.org%2Fblog%2F2023%2F04%2F04%2Fsql-2023-is-finished-here-is-whats-new%23any_value-t626" target="_blank">ANY_VALUE</a>）。值得一提的是，當中兩個 SQL 增強功能，進一步削弱了對替代數據模型和查詢語言的需求。不過需要注意一點，新的 SQL 規範包含這些內容，並不代表你喜歡的關係型 DBMS 會立即支持這些新特性。</p><h5>屬性圖查詢（SQL/PGQ）</h5><p>目前，SQL 支持對圖進行只讀查詢。這允許應用程序在現有表上聲明一個屬性圖結構。下面這個 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblogs.oracle.com%2Fdatabase%2Fpost%2Fget-started-with-property-graphs-in-oracle-database-23c-free-developer-release" target="_blank">Oracle v23c</a> 的圖示例，它記錄了哪些人在哪支樂隊中：</p><pre><code class="language-sql">CREATE TABLE PEOPLE (ID INT PRIMARY KEY, NAME VARCHAR(32) UNIQUE);
CREATE TABLE BANDS (ID INT PRIMARY KEY, NAME VARCHAR(32) UNIQUE);
CREATE TABLE MEMBEROF (PERSON_ID INT REFERENCES PEOPLE (ID), 
                       BAND_ID INT REFERENCES BANDS (ID), 
                       PRIMARY KEY (PERSON_ID, BAND_ID));

CREATE PROPERTY GRAPH BANDS_GRAPH
   VERTEX TABLES (
      PEOPLE KEY (ID) PROPERTIES (ID, NAME),
      BANDS KEY (ID) PROPERTIES (ID, NAME)
   )
   EDGE TABLES (
      MEMBEROF
      KEY (PERSON_ID, BAND_ID)
      SOURCE KEY (PERSON_ID) REFERENCES PEOPLE (ID)
      DESTINATION KEY (BAND_ID) REFERENCES BANDS (ID)
      PROPERTIES (PERSON_ID, BAND_ID)
   );
</code></pre><p>它由 DBMS 決定是為屬性圖創建輔助數據結構（例如，鄰接矩陣）還是僅跟蹤元數據。你可以用 <code>MATCH</code> 關鍵字在 SQL 中編寫圖遍歷查詢，這個語法建立在現有查詢語言（像是 Neo4j 的 Cypher，Oracle 的 PGQL 和 TigerGraph 的 GSQL）的基礎上，並且兼容了新興的 GQL 標準。以下查詢返回每支樂隊的成員數：</p><pre><code class="language-sql">SELECT band_id, COUNT(1) AS num_members
   FROM graph_table ( BANDS_GRAPH
      MATCH (src) - [IS MEMBEROF] -&gt; (dst)
      COLUMNS ( dst.id AS band_id )
   ) GROUP BY band_id ORDER BY num_members DESC FETCH FIRST 10 ROWS ONLY;
</code></pre><p>截至 2024 年 1 月，我知道的唯一支持 SQL/PGQ 的 DBMS 是 Oracle。DuckDB 的實驗性分支雖然也支持 SQL/PGQ，但上面示例不能運行，因為兩個數據庫支持的語法略有不同。你可以從 CWI/DuckDB 研究員 Gabor Szarnyas 整理的這個 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fszarnyasg%2Fgql-sql-pgq-pointers" target="_blank">SQL/PGQ 的優秀資源列表</a>中瞭解更多關於 SQL/PGQ 的信息。</p><h5>多維數組（SQL/MDA）</h5><p>從 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fen.wikipedia.org%2Fwiki%2FSQL%3A1999" target="_blank">SQL:1999</a> 引入有限的單維度、固定長度數組數據類型以來，SQL 就支持數組類型。而 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fen.wikipedia.org%2Fwiki%2FSQL%3A2003" target="_blank">SQL:2003</a> 更是增強了該功能，支持嵌套數組，而無需預定義最大基數。在 SQL:2023 中，SQL/MDA 部分更新支持了使用整數座標的真正的多維數組，這些數組可以是任意維度。此外，<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdoc.rasdaman.org%2F04_ql-guide.html" target="_blank">Rasdaman 的 RQL</a> 大大地啓發了 SQL/MDA 語法，SQL 可以提供與其兼容，並與集合語義正交的結構和操作數組構造。藉此讓應用程序只用在 SQL 中與多維數組交互和操作，而無需將它們導出，例如：到 Python Notebook。<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fd-nb.info%2F1137054492%2F34" target="_blank">下表</a>展示了在 <code>CREATE TABLE</code> 語句中使用 <code>MDARRAY</code> 數據類型的不同示例：</p><p><img src="https://nebula-website-cn.oss-cn-hangzhou.aliyuncs.com/nebula-blog/andy-database-review/01.svg" alt="" referrerpolicy="no-referrer"></p><p>儘管 SQL/MDA 規範在 2019 年以技術報告的形式出現，但直到 SQL:2023 它才被正式納入 SQL 標準。據我所知，除了 Rasdaman 之外，沒有其他生產級別的 DBMS 支持 SQL/MDA 擴展。我能找到的唯一其他數據庫是 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fmisev%2Fasqldb" target="_blank">ASQLDB</a>，一個數據庫 HSQLDB 的分支。</p><h5>Andy 説：SQL:2023 是個里程碑</h5><p>SQL:2023 修訂版是 SQL 這種通用查詢語言持續進化和改進的下一個階段。當然，SQL 並不完美，也不具備真正的可移植性，因為每個 DBMS 都有自己的特點、專有特性和非標準擴展。就像我個人就非常喜歡 PostgreSQL 的 <code>::</code> 轉換操作符快捷方式。</p><p>雖然 SQL/PGQ（SQL 對圖的支持）是個大事，但我不覺得它會立即對圖數據庫造成威脅，因為已經有多種方法將面向圖的查詢轉換為 SQL。包括 SQL Server 和 Oracle 在內的 DBMS 都提供了內置的 SQL 擴展，可以容易地存儲和查詢圖數據。Amazon Neptune 則是在 Aurora MySQL 之上的圖數據服務層。Apache AGE 在 PostgreSQL 之上提供了一個 openCypher 接口。我預測其他主流 OLAP 數據系統，例如：Snowflake，Redshift，BigQuery，都會在不久的將來支持 SQL/PGQ。</p><p>但在一個 DBMS 中添加 SQL/PGQ 並不像添加新語法那樣簡單。要確保圖查詢性能良好，需要考慮幾個工程上的問題。例如，圖查詢執行多路連接來遍歷圖。但當這些連接的中間結果比基礎表還大時，問題就來了。一個 DBMS 必須使用最壞情況下最優連接（<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fen.wikipedia.org%2Fwiki%2FWorst-case_optimal_join_algorithm" target="_blank">WCOJ</a>，Worst-case optimal join）算法來更有效地執行兩表聯合查詢，而不是通常用來連接兩個表的 hash join。另一個技術要點是使用因式分解來避免在連接過程中物化冗餘的中間結果。這種類型的壓縮讓 DBMS 規避了一遍又一遍地用相同的連接記錄導致內存耗盡的問題。</p><p>上面我提到的優化點，並不是説現有的圖數據庫都做到了。據我所知，像是 Neo4j、TigerGraph 等圖數據庫都沒有實現。我唯一知道的實現了優化的是滑鐵盧大學的嵌入式圖數據庫 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fkuzudb.com%2F" target="_blank">Kuzu</a>。大多數關係型數據庫也沒有實現它們，至少我知道的那些開源數據庫沒有。上面提到的 DuckDB 實驗分支實現了 WCOJ 和因式分解優化，並在 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.cidrdb.org%2Fcidr2023%2Fpapers%2Fp66-wolde.pdf" target="_blank">2023 年的論文</a>中顯示，在一個行業標準的圖基準測試中，其性能比 Neo4j 高出多達 10 倍。</p><p>我很久之前説過，SQL 可能在你出生之前就存在，到你去世它依然會存在。對於那些聲稱自然語言查詢將完全取代 SQL 的説法，我依舊嗤之以鼻。</p><p>旁註：從上次我公開説到 2030 年圖數據庫都不會在數據庫市場上超過關係型數據庫以來，已經兩年過去了。到目前為止，我還是對的。</p><h4>MariaDB 的困境</h4><p>過去的一年，MariaDB 頻頻出現在新聞報道中，而且大多數都不是什麼好消息。獨立於 MariaDB 基金會的 MariaDB 公司顯然是一個混亂的公司。在 2022 年，這家公司試圖借殼 SPAC 上市，但是股票（$MRDB）在 IPO 後的三天內立即跌了 40%。而為了加速在紐交所上市進度的借殼操作也被公諸於世。到 2023 年底，MariaDB 公司股價自開盤以來跌了 90% 以上。</p><p>因為這些糟糕的財務問題，MariaDb 公司宣佈了兩輪裁員。第一輪在 2023 年 4 月，但同年 10 月他們進行了另一輪更大規模的裁員。公司還宣佈他們將關停兩款產品：Xpand 和 SkySQL。前者是 MariaDB 公司在 2018 年收購的產品，當時它還被稱為 Clustrix；我在 2014 年還參觀了 Clustrix 的舊金山辦公室，當時我覺得那裏像個陰森的鬼城（辦公室裏一半的燈都熄滅了）。後者 SkySQL 的歷史更加複雜。最初它只是一個提供 MariaDB 服務的獨立公司，在 2013 年與 Monty Program AB 合併。在 2014 年，合併後的 Monty Program AB + SkySQL 公司變成了今天的 MariaDB 公司。但在 2023 年 12 月，公司又宣佈 SkySQL 沒有「死去」，而是作為一個獨立公司重新回到了市場！</p><p>MariaDB 公司的情況如此糟糕，以至於 MariaDB 基金會的 CEO 專門寫文章，抱怨自從 MariaDB 公司上市以來基金會與公司的關係是如何惡化，他希望能夠重新審視彼此關係。雪上加霜的是，微軟在 2023 年 9 月宣佈，未來不再提供作為託管 Azure 服務的 MariaDB，而是改為採用 MySQL。可能有人不知道，MariaDB 本身就是 MySQL 的一個分支，是 MySQL 的原創始人 Monty Widenus 在 2009 年 Oracle 宣佈收購 Sun Microsystems 後創建的。回憶下，Oracle 在 2005 年買了 InnoDB 的製造商 InnoBase，Sun 在 2008 年買了 MySQL AB。現在 MySQL 運行良好，MariaDB 卻遇到了問題。戲劇來源於現實，多看看數據庫市場你能吃到各種瓜！</p><h5>Andy 説：數據庫的聲譽比以往任何時候都重要</h5><p>過去的十年，數據庫客戶的精明程度有了大幅度的提升。各家公司也不再能僅憑華而不實的性能數字、取代 SQL 的新查詢語言，或是名人效應來「扮成功直到真正成功」了。數據庫的聲譽比以往任何時候都更為重要，其背後的公司聲譽也同樣重要。也就是説，這意味着軟件本身的穩定很重要，其公司也得有條不紊地運作。</p><p>開源數據庫背後的公司如果倒閉了，很少數據庫能繼續發展和繁榮。不過，PostgreSQL 算一個例外，儘管今天我們用的開源版本是基於加州大學伯克利分校的源碼，而不是 1996 年被 Informix 收購的商業版本 Illustra。另一個例子是，為 MySQL 構建 InfiniDB OLAP 引擎的公司在 2014 年破產後，其 GPLv2 源碼被接手並作為 MariaDB 的 ColumnStore 持續發展。</p><p>相反，更多現實告訴我們，一旦支付最多開發費用的公司消失，對應的數據庫就會逐漸衰落。唯二在某種程度上算是活下來數據庫的例子是 Riak 和 RethinkDB。Basho 在 2017 年破產後，現在 Riak 由在 UK's NHS 工作的一個人維護。RethinkDB 公司在 2017 年倒閉（鑑於創始人對女性在科技界的看法，這並不奇怪）後，數據庫源碼就被轉移到了 Linux 基金會。儘管基金會接手了項目，RethinkDB 仍處於活着的狀態：該項目在 2023 年發佈了一個新版本，但它們只是熱修復，來解決一些已知問題。有興趣的話，你可以去 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fattic.apache.org%2F" target="_blank">Apache 基金會檔案室</a>看看那些被遺棄的數據庫項目。</p><p>只在雲端提供數據庫服務的 DBaaS，在穩定性上只會更糟糕。因為如果公司失敗，或是開始面臨財務壓力，他們就會關閉託管你數據庫的服務器。Xeround 在 2013 年關閉雲服務時，給了他們的客戶兩週時間遷移數據。為了降低成本，InfluxDB 在 2023 年 7 月刪除整個 region 前給了客戶六個月的時間遷移，但大家還是大吃一驚。</p><p>MariaDB 比一般的數據庫創業公司處於更好的位置，因為 Monty 和其他人成立了一個管理開源項目的非營利基金。但當你是一個以盈利為目的的開源數據庫公司，而幫助你管理該 DBMS 運作的非營利組織公開表示你管理混亂的話，那就是一個壞兆頭！與此同時，MySQL 在持續改善，Oracle 依舊是那個從工程角度看不錯的企業級數據庫選擇。MariaDB 公司的混亂將進一步促進人們轉向使用 PostgreSQL。</p><p>MariaDB 肯定不能失敗，據我所知，Monty 沒有更多的孩子可以用來給數據庫命名了（例如：MaxDB、MySQL、MariaDB）。</p><p>小趣聞：MariaDB 取名自 Monty 的小女兒 Maria，MaxDB 取名自兒子 Max，MySQL 來自大女兒 My。</p><h4>美國航空因政府數據庫崩潰而停飛</h4><p>在 2023 年 1 月 11 日，由於飛行通知 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fen.wikipedia.org%2Fwiki%2FNOTAM" target="_blank">NOTAM</a> 系統故障，聯邦航空管理局 FAA 停飛了美國所有的航班。NOTAM 系統向飛行員提供以純文本編碼的消息，告訴他們可能在飛行路徑上會遇到的意外和潛在危險。當 NOTAM 系統在 1 月 11 日早晨崩潰時，直接導致美國大約 11,000 架航班無法起飛。所幸的是，其他國家運行着獨立的、不受美國 NOTAM 故障影響的 NOTAM 系統能正常起飛。</p><p>根據 FAA 官方説法，這次故障是由於一個數據庫文件損壞導致的。一名來自第三方承包商的工程師嘗試用備份文件替換它，但結果是備份文件也有問題。2008 年也發生了類似的<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.eweek.com%2Fnetworking%2Fcorrupt-file-brought-down-faa-s-antiquated-it-system%2F" target="_blank">事件</a>。</p><p>關於 FAA 在 NOTAM 所用的 DBMS 並沒有公開信息。有一些報道稱，NOTAM 仍然在運行於 1988 年的兩台 Philips DS714/81 大型機上。但這些 Philips DS714 機器沒有我們今天所知的操作系統；它們是 1960 大型機年代的遺物。也就是説，在 1980 年代 FAA 無法為應用使用現有的數據庫系統，即便是那些當時已經存在的數據庫，像是 Oracle、Ingres 和 Informix 都支持當時的各種 Unix。我覺得比較合理的可能是，NOTAM 可能用 Flat File（比如：CSV）來自行管理數據。1980 年代由非數據庫專家編寫的應用程序代碼負責從文件中讀取/寫入記錄，複製到備用服務器，並在出現故障時維護數據的完整性。</p><h5>Andy 説：歷史悠久的核心數據系統，是每個數據庫從業者最大的噩夢</h5><p>在無法替代的傳統硬件上運行關鍵任務系統，使用的還是由早就退休的內部開發人員編寫的自定義數據庫訪問庫，這是每個數據庫從業者最大的噩夢。我很驚訝它竟然沒崩潰得更早（除非 2008 年的故障是同一系統），我覺得我們應該給這個運行了 35 年的系統一些掌聲。</p><p>有消息稱，NOTAM 系統每秒只處理 20 條消息。按照現代數據標準，這個數據量真的很小，但別忘記，FAA 是在 1980 年代配置的這個系統。數據庫傳奇人物，1998 年圖靈獎得主 Jim Gray 在 1985 年寫到，<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fjimgray.azurewebsites.net%2Fpapers%2FTandemTR85.1_1kTPS.pdf" target="_blank">「普通」的數據庫管理系統可以執行大約每秒 50 次事務</a>（txn/sec），而非常高端的系統可以達到每秒 200 次。作為參考，五年前，有人使用 1980 年代的基準測試（基於 TPC-A 的 TPC-B）<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.rustprooflabs.com%2F2019%2F04%2Fpostgresql-pgbench-raspberry-pi" target="_blank">在樹莓派 3 上運行 PostgreSQL，大約達到了每秒 200 次事務</a>。如果我們不考慮那些使用跨數據中心的強一致性複製（這會受到光速的限制）的系統，現代單節點在線事務處理（OLTP）DBMS 可以在某些工作負載下實現每秒數百萬次事務的吞吐量。NOTAM 在 1980 年代的峯值每秒 20 條消息的吞吐量並沒有推動當時的技術極限，而且顯然今天也沒有。</p><p>因為 NOTAM 沒有將數據庫與應用程序邏輯分離，所以獨立升級這些組件是不可能的。考慮到在 1980 年代中期，關係模型的優點已經眾所周知，NOTAM 這種設計是該批判的。當然，並不是説 SQL 就能防止這次確切的失敗（這是一個人為錯誤），但獨立性會讓各個組件不那麼笨重，更易於管理。</p><p>儘管如此，當時美國政府其實已經在用商用關係型 DBMS。例如，Stonebraker 的 RTI（Ingres 廠商）在 1988 年的 IPO 申報文件中提到，他們現有的客戶包括國防部和內政部、軍事分支和研究實驗室。我相信當時美國政府的其他部門也在使用 IBM DB2 和 Oracle。因此，除非 NOTAM 有什麼我不知道的特別之處，不然 FAA 本可以使用真正的數據庫管理系統。</p><p>停飛事件發生的時候，我正在阿姆斯特丹的 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.cidrdb.org%2Fcidr2023%2F" target="_blank">CIDR 2023</a> 會議的返程中。幸運的是，停飛沒有影響入境的國際航班，我的飛機可以順利地降落。但我還是被困在紐瓦克機場，因為美國所有國內航班都停飛了。熟悉紐瓦克機場的人都知道，在這裏待着並不是什麼好事。</p><p>延伸閲讀：你可以閲讀我之前的<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fottertune.com%2Fblog%2Fwhy-the-faas-database-problem-wont-happen-in-aws" target="_blank">文章</a>，瞭解下為什麼如果 NOTAM 數據庫運行在 Amazon RDS 上，不太可能發生數據庫崩潰。</p><h4>數據庫的融資情況</h4><p>除了上面提到的向量數據庫是風投的「新寵」之外，其他類型的數據庫在 2023 年也是有融資的。但總體而言，今年的數據庫融資活動比往年要冷清得多。</p><p>自動調優初創公司 DBTune 在歐洲完成了 260 萬美元的種子輪融資。PostgresML 獲得了 450 萬美元的種子輪融資，來打造一個通過自定義擴展來支持從 SQL 調用 ML 框架的 DBaaS。TileDB 在秋季宣佈完成了 3,400 萬美元的 B 輪融資，以此繼續完善他們的陣列數據庫管理系統。儘管有着 13 年的歷史，SQReam 還是獲得了 4,500 萬美元的 C 輪融資，來繼續開發他們的 GPU 加速數據庫管理系統。Neon 在 2023 年 8 月完成了 4,600 萬美元的 B 輪融資，以擴展無服務器 PostgreSQL 平台。當然，2023 年的融資贏家再次是 Databricks，他們在 2023 年 9 月完成了 5 億美元的 I 輪融資。雖然這是一筆鉅款，但並不如他們在 2021 年 H 輪的 16 億美元來得多。</p><p>Peter Boncz 和 Tianzhou Chen 提醒我了，還有 MotherDuck（DuckDB 的商業版本）在 2023 年 9 月完成的 5,250 萬美元的 B 輪融資。另一個數據庫產品 DBeaver，完成了 500 萬美元的種子輪融資，來繼續研發受歡迎的 multi-DBMS 。</p><p>此外，2023 年數據庫領域也發生了一些收購。最大的一筆交易在年初發生，MarkLogic 被 Progress Software 以 3.55 億美元現金收購。MarkLogic 是最古老的 XML 數據庫管理系統之一（約 2001 年），而 Progress 擁有 OpenEdge，一種更古老的數據庫管理系統（約 1984 年）。IBM 收購了 Meta 的衍生公司 Ahana，該公司試圖將 PrestoDB（它不同於已經更名為 Trino 的 PrestoSQL）商業化。多雲數據庫服務提供商 Aiven 收購了 AI 驅動的查詢重寫器初創公司 EverSQL。EnterpriseDB 用 Bain Capital（私募投資公司）的資金收購了基於 DataFusion 兼容 PostgreSQL 的 OLAP 引擎的 Seafowl 團隊。Snowflake 收購了兩家初創公司：（1）由前斯坦福教授 Peter Bailis 打造的 Sisu Data，以及（2）由伯克利教授 Aditya Parameswaran 基於 Modin 研發的 Ponder。</p><h5>Andy 説：無論初創公司，還是高估值的公司日子都不好過</h5><p>我的風投朋友們説，他們在 2023 年看到了更多新公司的推介，但比往年簽發的支票更少。這個趨勢貫穿所有初創領域，數據庫市場也不例外。大部分的風投注意力都在那些和人工智能+大型語言模型（LLM）有一點點關係的項目，這也合理，畢竟這是計算領域的新篇章。</p><p>儘管美國 2023 年的宏觀經濟指標有些積極的跡象，但科技產業依舊緊張，每家企業都在削減成本。像 OtterTune（作者所在的公司）客戶希望我們的數據庫優化服務能在 2023 年幫助他們降低數據庫基礎設施成本。這與公司早些年人們主要來找 OtterTune 提高數據庫管理系統的性能和穩定性不同。我們計劃在 2024 年宣佈新功能，以幫助降低數據庫成本。回到大學，這個學期有比平常更多的學生請我幫他們找數據庫開發的工作。這讓我很吃驚，因為 CMU 的計算機科學學生一直不愁找工作，靠自己就拿到不錯的實習和全職 offer，除了有次我最優秀的本科生重寫了我們的查詢優化器，但因為忘了問我，結果找不到暑期實習，最後在匹茲堡機場附近的迪克體育用品店做網頁開發——他現在在 Vertica 工作得很開心。</p><p>如果美國的科技市場繼續低迷不振，接下來的幾年眾多數據庫初創公司都難有大發展。小型的數據庫初創公司要麼會被大型科技公司或私募股權收購，要麼就直接倒閉。但是，那些融到大筆錢且估值很高的公司也不好過。正如我之前説的那樣，有些公司可能無法 IPO，而且沒有哪家大型科技公司會需要這些 DBMS，因為如今大家都有自己的數據庫系統。因此，這些大數據庫管理系統公司將面臨三個選擇：接受降低估值的融資以保持運營；通過私募股權獲得支持，保持運營（比如：Cloudera）；被一家 IT 服務公司收購（比如：Rocket，Actian），這些公司將 DBMS 置於維護模式，但繼續從那些被困的客戶那裏收取許可費，因為這些客戶有他們無法輕易遷移的遺留應用程序。不過，這三條路對於數據庫公司來説都不理想，應該會嚇跑潛在的新客戶。</p><p>最後，我要重述一句：不要問 Databricks 是不是會 IPO，而是它何時會 IPO。</p><h4>史上最貴的密碼重置</h4><p>2023 年，數據庫傳奇大佬 Larry Ellison 春風得意。對於他原本傑出的職業生涯來説，2023 年也是一個標誌性的一年。2023 年 6 月，他重返世界第四富有的位置。Oracle 公司的股價（$ORCL）在 2023 年上漲了 22%，略低於標準普爾 500 指數 24% 的回報率。此外，在 2023 年 9 月，Larry 第一次去了 Redmond，並與微軟首席執行官 Satya Nadella 一起登台宣佈，Oracle 可作為 Azure 雲平台上託管服務使用。隨後同年 11 月，股東們壓倒性地投票支持 79 歲的 Larry 繼續擔任 Oracle 董事會主席。</p><p>但 2023 年真正的大新聞是，Elon Musk 在 Larry 對 Musk 收購社交媒體公司投資了 10 億美元后，親自幫 Larry 重置了 Twitter 密碼。正是這筆價值 10 億美元的密碼重置，我們在 2023 年 10 月有幸看到了 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftwitter.com%2Flarryellison%2Fstatus%2F1709982050521125224" target="_blank">Larry 的第二條推文</a>，也是他十多年來的首條新推文。Larry 預告了他即將前往牛津大學的行程，後來他在那裏宣佈在牛津大學成立埃裏森技術研究院（EIT）。</p><h5>Andy 説：意料之外的大人物生活</h5><p>其實 Larry 發了什麼根本不重要，重要的是 Larry 迴歸推特發推文。我偷偷打聽過，Larry 偶爾會看看推特，主要關注創業點子提案、祝福以及不經意冒出的奇思妙想。</p><p>Larry 的推文之所以出人意料，是因為人們一般會認為他總是忙於更宏偉的活動。畢竟，他擁有一架 MiG-29 戰鬥機和一個夏威夷島嶼。他有很多更偉大的事情可以做。所以，當他抽出時間在一個日益衰落的社交媒體上寫推文，告訴我們他在做什麼。這對我們所有人來説，都是一個重大的生活事件。為此，Larry 不得不請他那個世界上最富有的朋友來重置他的密碼。雖然花費 10 億美元，但當你擁有 1,030 億美元時，這都不是什麼事了。</p><h3>2022 年數據庫回顧：江山代有新人出，區塊鏈數據庫還是那個傻主意</h3><blockquote><p>英文原文：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fottertune.com%2Fblog%2F2022-databases-retrospective" target="_blank">https://ottertune.com/blog/2022-databases-retrospective</a></p></blockquote><h4>放緩的大規模數據庫融資</h4><p>正如我去年説的那樣，2021 年是數據庫融資的大年。隨着投資者繼續尋找下一個 Snowflake，大量資金湧向了新的 DBMS 初創公司。2022 年初看起來像是要再過一次 2021 年，有非常多的大額融資消息。</p><p>融資狂歡在 2022 年的 2 月開始，Timescale 完成了 1.1 億美元的 C 輪融資，Voltron Data 完成了 1.1 億美元的種子輪 + A 輪融資，Dbt Labs 完成了 2.22 億美元的 D 輪融資。Starburst 在 3 月宣佈了他們 2.5 億美元的 D 輪融資來繼續提升他們的 Trino 產品。Imply 在 5 月拿出 1 億美元的 D 輪融資用於開發他們的 Druid 商業版本。DataStax 在 6 月的 IPO 途中獲得了 1.15 億美元的資金。最後，SingleStore 在 7 月完成了 1.16 億美元的 F 輪融資，然後在 10 月又融了 3,000 萬美元。</p><p>2022 年上半年還有幾家較小的公司完成了讓人印象深刻的 A 輪融資，包括 Neon 的 3,000 萬美元 A 輪用來研發無服務器 PostgreSQL 產品，ReadySet 2,900 萬美元 A 輪融資來研發查詢緩存層，Convex 的 2,600 萬美元 A 輪來繼續開發他們基於 PostgreSQL 的應用程序框架，以及 QuestDB 的 1,500 萬美元 A 輪來開發時序數據庫。儘管我們 OtterTune 沒有新的 DBMS 或相關基礎設施，但我們也在 4 月完成了 1,200 萬美元的 A 輪融資。</p><p>但是，到了 2022 年下半年，大規模的融資輪停止了。儘管早期初創公司還是有較小額的融資進來，但更後面的公司再也沒有九位數的美元融資了。</p><p>流處理引擎 RisingWave 在 10 月籌集了 3,600 萬美元的 A 輪，Snowflake 查詢加速器 Keebo 融到 1,050 萬美元的 A 輪資金。在 11 月，我們看到了 MotherDuck 的 4,500 萬美元種子輪 + A 輪融資的新聞來開發商業化 DuckDB 的雲版本，以及 EdgeDB 在 11 月的 1,500 萬美元 A 輪融資。最後，是 SurrealDB 完成了 600 萬美元的種子輪融資。我可能漏掉了一些其他公司，這不是一個詳盡的列表。</p><p>在數據庫領域唯一其他值得注意的金融事件是，MariaDB 在 12 月的災難性地通過 SPAC IPO，股價在首個交易日就下跌了 40%。</p><h5>Andy 説：不只是 OLAP 領域，OLTP 領域前景也一樣嚴峻</h5><p>與 2021 年相比，在 2022 年大額融資輪減少的原因有兩個。最明顯的是整個科技行業在降溫，部分原因是人們對通貨膨脹、利率和加密經濟崩潰的擔憂。另一個原因是，有能力大額融資的公司在資金乾涸之前就完成了融資。</p><p>例如，Starburst 在 2021 年完成了 1 億美元的 C 輪融資後，在 2022 年進行了它的 D 輪融資。在過去兩年完成鉅額融資的數據庫公司，很快就需要再次融資來保持增長勢頭。</p><p>壞消息是，除非科技行業有所改善，並且大型機構投資者開始再次將資金投入市場，否則這些公司們將面臨困境。市場無法維持這麼多獨立軟件供應商（ISVs）為數據庫服務。這些擁有十億美元估值的公司唯一繼續前進的法子是，進行首次公開募股或破產。這些公司對於大多數公司來説太貴了，無法被收購（除非風投公司願意大打折扣）。</p><p>此外，進行大型併購的大型科技公司（比如：亞馬遜、谷歌、微軟）都有了自己的雲數據庫產品。因此，不清楚誰會收購這些數據庫初創公司。亞馬遜沒有理由在他們 Redshift 每年賺取數十億美元時，去以 2021 年的 20 億美元估值購買 ClickHouse。這個問題不僅限於 OLAP 數據庫公司；OLTP 數據庫公司很快也將面臨同樣的問題。</p><p>我並不是唯一一個對數據庫初創公司的前景做出如此嚴峻預測的人。Gartner 分析師預測，到 2025 年，<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.gartner.com%2Fen%2Farticles%2F12-data-and-analytics-trends-to-keep-on-your-radar" target="_blank">50% 的獨立 DBMS 供應商將退出市場</a>。顯然我有自己的看法，我認為未來生存下來的公司是那些致力改善或者是強化 DBMS 的公司，而不是替換它們的公司（比如：dbt、ReadySet、Keebo 和 OtterTune）。</p><p>我無法判斷 MariaDB 借殼 SPAC 「快速上市」是否是個好主意。這種金融操作不在我的專業領域（數據庫）內。但既然這和前美國總統用他的社交媒體公司做的事情一樣，我就姑且認為它不是什麼好主意。</p><h4>區塊鏈數據庫還是那個蠢點子</h4><p>關於 Web3 根本性轉變了構建新應用程序方式這點，有很多誇張的説法。我有一個學生甚至因為我教授的是關係數據庫而不是 Web3，憤然從我的課堂離席。Web3 運動的核心是在區塊鏈數據庫中存儲狀態。</p><p>區塊鏈本質上是去中心化的分散的日誌結構數據庫（即，賬本），它們通過使用某種 Merkle 樹的變體和 BFT 共識協議來維護增量校驗和，從而確定下一個要入庫的更新。這些增量校驗和是區塊鏈確保數據庫日誌記錄不變性的方式：客戶端使用這些校驗和來驗證之前的數據庫更新沒有被更改。</p><p>區塊鏈是之前想法的巧妙結合。但是，廠商們認為去中心化賬本是每個人構建 OLTP 應用程序必須的，這點是一種誤導。從數據庫的角度，除了加密貨幣之外，區塊鏈數據庫和現有的 DBMS 沒有任何差別。此外，任何區塊鏈在數據庫安全性和可審計性比現有 DBMS 表現更好的説法，都是胡説。</p><p>如果説加密貨幣是區塊鏈數據庫的最佳實踐，那麼 2022 年加密市場的崩潰顯然沒有幫到它們，甚至是進一步阻礙了區塊鏈數據庫的發展。當然我會忽略 FTX 的崩盤（他們申請了破產保護），畢竟它就是徹頭徹尾的詐騙，和數據庫一點關係都沒。不過，我要指出，FTX 和所有其他加密貨幣交易所一樣，並沒有在區塊鏈數據庫上運行業務，而是使用了 PostgreSQL。</p><p>此外，其他與加密貨幣無關的區塊鏈數據庫用例，如交易和遊戲平台，都因為不切實際或詐騙沒有落地。</p><h4>Andy 説：有讓人信服的用例才是合格的新技術</h4><p>評估某項技術的原則之一是，一旦廠商開始製作它的媒體廣告，它就不再是「新」技術了。簡單來説，像是 IBM 之類的廠商在打廣告的時還沒有出來讓人信服的用例，那麼這個產品永遠也不會有用例。</p><p>舉個例子，IBM 在 2002 年在一則商業廣告中吹捧 Linux 是一個熱門的新事物，但那時已經有包括谷歌在內的成千上萬的公司將 Linux 作為主要服務器操作系統使用了。所以，當 IBM 在 2018 年發佈他們的區塊鏈廣告時，我就知道這項技術除了在加密貨幣領域有用，在其他領域毫無用處。因為其他領域沒有一個問題是去中心化的區塊鏈能解決，而中心化的 DBMS 不能解決的。</p><p>因此，2022 年 IBM 宣佈將關閉與航運巨頭 Maersk 合作的供應鏈 IT 基礎設施改造項目，也就不奇怪了，畢竟這正是 IBM 在廣告中炒作的場景。</p><p>相比任意一個可信權威管理、只允許受信任的客戶端直連、用心編寫的事務數據庫，區塊鏈數據庫的效率低得可怕。除了加密貨幣（見上文）或者其他什麼欺詐場景，現實數據世界的運行方式都是和其他數據庫目前處理的那樣。</p><p>信任是一個正常運轉的社會的基石。例如，我授權託管 OtterTune 網站的公司向我的信用卡收費，他們又信任一個雲提供商來託管他們的軟件。沒人會需要使用區塊鏈數據庫來進行這些「信任」交易。</p><p>從工作量證明（PoW：proof-of-work）轉換到不那麼費事的權益證明（PoS：proof-of-stake），共識機制確實提升了區塊鏈數據庫的性能。但這隻影響數據庫的吞吐量；區塊鏈交易的延遲仍然以數十秒計算。如果解決這些長延遲的方法是使用參與者較少的 PoS 區塊鏈，那麼應用程序使用 PostgreSQL 來認證這些參與者會更好。</p><p>你可以讀一讀 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.tbray.org%2Fongoing%2FWhen%2F202x%2F2022%2F11%2F19%2FAWS-Blockchain" target="_blank">Tim Bray（XML 之父）同 AWS 高層內部討論是否有區塊鏈可行用例</a>的精彩文章。值得留意的是，Tim 説 AWS 在 2016 年就得出過區塊鏈數據庫是數據問題的解決方案的結論，這比 IBM 推出區塊鏈數據庫廣告早了兩年！雖然 AWS 最終在 2018 年發佈了 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Faws.amazon.com%2Fqldb%2F" target="_blank">QLDB</a> 服務，但它不同於區塊鏈；它是一箇中心化的可驗證賬本，不使用 BFT 共識。與亞馬遜極為成功的 Aurora 產品相比，QLDB 客戶的採用率一直不太理想。</p><p>趣聞：在 FTX 崩盤（申請破產保護）前的三週，有人和我説 OtterTune 的全職工程師人數和 FTX 在巴哈馬的團隊一樣。這個人還説，既然工程師人數一樣，OtterTune 應該像 FTX 那樣更有前景，而且現在應該有 10 億美元的年度經常性收入（ARR）。真是有意思呀。</p><h4>新的數據系統</h4><p>今年有不少新的 DBMS 軟件的重大新聞：</p><ul><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcloud.google.com%2Falloydb" target="_blank">Google AlloyDB</a>：2022 年最讓人震驚的消息是 5 月份谷歌雲宣佈了它們的新數據庫服務。AlloyDB 不是基於 Spanner 構建的，而是一個修改版的 PostgreSQL，它分離了計算層和存儲層，並且支持在存儲中直接處理 WAL 記錄。</li><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.snowflake.com%2Fen%2Fdata-cloud%2Fworkloads%2Funistore%2F" target="_blank">Snowflake Unistore</a>：6 月份，Snowflake 宣佈了他們的新 Unistore 引擎，用「混合表」來支持 DML 操作的低延遲交易。當查詢要更新表時，變更會傳到 Snowflake 的列式存儲中。SingleStore 數據庫的某個人有些激動，説 SingleStore 在這個領域有一些專利，雖然這個説法沒啥實質性證據支撐。補充信息：SingleStore 和 Snowflake Unistore 有部分技術交集，你可以理解為他們存在一定的競爭關係。</li><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.oracle.com%2Fmysql%2Fheatwave%2F" target="_blank">MySQL Heatwave</a>：當 Oracle 發現 Amazon 從 MySQL 賺的錢比他們多後，終於在 2020 年決定為 MySQL 構建自己的雲服務。但他們並沒有僅僅做個 RDS（關係數據庫服務）克隆版，而是用一個叫做 Heatwave 的內存向量化 OLAP 引擎擴展了 MySQL。2021 年 Oracle 還宣佈他們的 MySQL 服務還支持自動化數據庫優化（但與 OtterTune 提供的優化服務不同）。到了 2022 年，Oracle 終於發現他們不是領先的雲供應商，並向 AWS 「低頭」在 AWS 上託管了 MySQL Heatwave。</li><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fvelox-lib.io%2F" target="_blank">Velox</a>：Meta 在 2020 年開始構建 Velox，作為 PrestoDB 的新執行引擎。兩年後，他們宣佈了這個項目並發表了一篇關於它的 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fresearch.facebook.com%2Fpublications%2Fvelox-metas-unified-execution-engine%2F" target="_blank">VLDB 論文</a>。Velox 並不是一個完整的 DBMS：它不帶 SQL 解析器、目錄、優化器或網絡支持。相反，它是一個帶有內存池和存儲連接器的 C++ 可擴展執行引擎。人們可以基於 Velox 構建一個成熟的 DBMS。</li><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.influxdata.com%2Fblog%2Finfluxdb-engine%2F" target="_blank">InfluxDB IOx</a>：就像 Meta 的 Velox 一樣，Influx 團隊在過去兩年一直在努力開發新 IOx 引擎。在 10 月，他們宣佈新引擎正式上線（GA）。InfluxDB 從零開始基於 DataFusion 和 Apache Arrow 構建了 IOx。值得慶祝下的是，我在 2017 年和 Influx 的 CTO 説使用 MMAP 是個壞主意後，他們在新系統中拋棄了 MMAP。</li></ul><h5>Andy 説：欣然看到數據庫領域的勃勃生機</h5><p>很高興見證了 2022 年數據庫領域發生的這些事。我對 AlloyDB 的看法是，它是一個簡潔的系統，當中投入了讓人感嘆的工程量，但我還是不知道它有什麼創新點。AlloyDB 的架構類似於 Amazon 的 Aurora 和 Neon，在 DBMS 存儲中有個額外的計算層，可以獨立於計算節點處理 WAL 記錄。儘管谷歌雲已經擁有堅挺的數據庫產品組合（比如：Spanner、BigQuery），但它們還是覺得有必要構建 AlloyDB 來嘗試趕上亞馬遜和微軟。</p><p>需要關注的長期趨勢是諸如 Velox、DataFusion 和 Polars 之類的框架的普及。結合像 Substrait 之類的項目，這些查詢執行組件的商品化意味着未來的五年內，所有的 OLAP DBMS 將在性能上大致持平。</p><p>與其完全從頭開始構建一個新的 DBMS，或者是 hard fork 一個現有系統（像 Firebolt fork ClickHouse），比如使用一個像 Velox 這樣的可擴展框架。也就是説，每個 DBMS 都將具備同 Snowflake 十年前獨有的相同向量化執行能力。尤其是在雲上，存儲層對每個人來説都是相同的（比如：亞馬遜控制的 EBS/S3），那麼區分 DBMS 產品的關鍵因素將會是那些難以量化的事物，如 UI/UX 設計和查詢優化。</p><h4>數據庫先驅的逝世</h4><p>在 2022 年 7 月有一個讓人難過的消息，Martin Kersten 逝世了。Martin 是 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.cwi.nl%2Fresearch%2Fgroups%2Fdatabase-architectures" target="_blank">CWI</a> 的研究員，他是多個頗具影響力的數據庫項目的引領者，包括 1990 年代最早的分佈式內存 DBMS（PRISMA/DB）和 2000 年代最早的列式 OLAP DBMS（MonetDB）。因為他在數據庫方面的貢獻，Martin 在 2020 年因被荷蘭政府授予皇家騎士稱號。</p><p>MonetDB 的代碼庫還是其他幾個 OLAP 系統項目的跳板。在 2000 年代末，Peter Boncz 和 Marcin Żukowski fork MonetDB 它開發 MonetDB/X100，後來商業化為 Vectorwise（現在叫 Actian Vector）。Marcin 後來離開，聯合他人共同創立的 Snowflake，採用了原來他在 MonetDB 代碼上開發的許多技術點。最近，Hannes Mühleisen 搞了個 MonetDB 的嵌入式版本 MonetDBLite，後來他又重寫了項目，變成了現在的 DuckDB。</p><p>Martin 對現代數據庫系統的貢獻如此重大，以至於你如果使用任何現代分析型 DBMS（像是 Snowflake、Redshift、BigQuery、ClickHouse），你就是在享受 Martin 和他的學生在過去 30 年開發的眾多進步成果。</p><h5>Andy 説：這是一個讓人難過的消息</h5><p>我知道，相比 Mike Stonebraker（研究數據庫的計算機科學家，2014 年圖靈獎獲得者）這樣的人，數據庫研究圈外人可能知曉 Martin 沒那麼多。我總把 Martin 看作是 Stonebraker 的歐洲版：他們都是多產的數據庫研究者，高個子、瘦弱、戴眼鏡，年齡相仿。但 Martin 並不是像 Nintendo Smitch 山寨 Nintendo Switch 那樣的山寨貨。</p><p>除了研究，在業餘時間 Martin 也樂於同他人討論數據庫架構。我最後一次見 Martin 是在新冠爆發之前的 2019 年。我們就他為什麼認為在 MonetDB 中使用 MMAP 是正確的選擇爭論了一個小時；他聲稱因為 MonetDB 專注只讀的 OLAP 工作負載，所以 MMAP 就夠好了。其實有件事很對不住 Martin，就是那些他應對過的在 YouTube 觀看我的數據庫課程後，給他發郵件詢問為什麼 MonetDB 做出了我聲稱的較差設計的學生。</p><p>我建議你看下 Martin 在 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3DvjWRE0UnJDQ%26list%3DPLSE8ODhjZXjbeqnfuvp30VrI7VXiFuOXS%26index%3D19" target="_blank">2021 年 CMU-DB 研討會的壓軸演講</a>。我和 Martin 承諾在他的演講中，我不會用 MonetDB 採納 MMAP 這點讓他分心。為了表示誠意，在這個視頻的前面 60 秒，我找了個荷蘭人錄製一個仿皇家的 Martin 短片介紹。</p><h4>數據庫的鉅額財富和民主</h4><p>2022 年 5 月，《華盛頓郵報》報道説，Oracle 創始人和帆船愛好者 Larry Ellison 參加了 2020 年 11 月剛結束的選舉的電話會議，與會的有美國總統和其他保守派領袖。</p><p>電話會議集中討論了總統的盟友和活動分子可能採取的、來推翻總統選舉的結果的不同策略。正如《郵報》文中指出的那樣，目前尚不清楚為什麼政府要讓 Larry 參與通話。一種猜測是，鑑於 Larry 顯而易見的強大技術背景，他可能很適合評估外國勢力利用某種方式來使用衞星技術來遠程操控美國選舉的説法是否可行。</p><h5>Andy 説：Larry 幹得漂亮</h5><p>相信 Larry 和我都厭倦了人們對他支持美國右翼的離譜言論，甚至有人説這個電話是 Larry 做過的最糟糕的事。這不是真的，要知道這樣的新聞和社交媒體言論會讓 Larry 感到難過。</p><p>我向你保證，Larry 只是試圖用他作為世界第七富有的人的鉅額財富來幫助他的國家。他參與這次通話是值得欽佩的，應該受到讚揚。自由和公正的選舉不是一件小事，不像划船比賽，有時候只要你能贏，搞點小動作也沒關係。Larry 用他的錢做了一些被人忽視的偉大事情，比如：為了活得更久，在抗衰老研究上花費了 3.7 億美元；投資了 10 億美元幫助 Elon Musk 運營 (?，那時候推特尚未被收購) 推特。所以，我支持 Larry 這個行為。</p><h3>2021 年數據庫回顧：性能之爭烽煙起，不如低調搞大錢</h3><blockquote><p>英文原文：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fottertune.com%2Fblog%2F2021-databases-retrospective" target="_blank">https://ottertune.com/blog/2021-databases-retrospective</a></p></blockquote><p>對數據庫行業來説，2021 年是瘋狂的一年，數據庫的新人「超越」了老牌廠商，數據庫廠商們為基準測試的數字爭論不休，還有各種引人注目的融資輪次。好消息是不少，但是收購、破產或重組之類的不好消息，也讓一些數據庫消失在數據庫市場。</p><h4>PostgreSQL 的主導地位</h4><p>開發者的認知已經發生轉變：PostgreSQL 成為香餑餑，已是新應用程序的首選。它穩定可靠，功能豐富，且在不斷增加新功能。2010 年，PostgreSQL 開發團隊採取了更積極的發佈計劃，每年發佈一個新的主要版本，這裏要感謝下 Tomas Vondra。順便提一嘴，PostgreSQL 是開源的。</p><p>如今，對很多系統來説，PostgreSQL 的兼容性是一個顯著亮點。這種兼容性是通過支持 PostgreSQL 的 SQL 方言（如 DuckDB）、線協議（如 QuestDB、HyPer）或整個前端（如 Amazon Aurora、YugaByte、Yellowbrick）來實現的。大公司們也跟進了這個趨勢。谷歌在 10 月宣佈在 Cloud Spanner 中增加了 PostgreSQL 兼容性。還是在 10 月，亞馬遜宣佈了 Babelfish 功能，將 SQL Server 查詢轉換成 Aurora PostgreSQL 查詢。</p><p>數據庫受歡迎程度的一個衡量標準是 DB-Engine 排名。這個排名不是很客觀，得分帶有一點程度的主觀性，但就排名前十的系統結果還是合理的。截至 2021 年 12 月，DB-Engine 排名顯示，雖然 PostgreSQL 仍然是第四大流行數據庫（僅次於 Oracle、MySQL 和 MSSQL），但它在過去的一年裏縮小了與 MSSQL 的差距。</p><p>另一個值得考慮的趨勢是 PostgreSQL 在線上社區的提及頻率。它給我們提供了人們在數據庫中討論什麼的信息。我下載了 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.reddit.com%2Fr%2Fdatabase%2F" target="_blank">Reddit 上 2021 年在數據庫</a>相關的所有評論，並計算了數據庫名稱的出現頻率，自然 PostgreSQL 在其中。我又交叉參考數據庫的列表，合併了縮寫（例如，Postgres → PostgreSQL，Mongo → MongoDB，ES → Elasticsearch），最後整理出了前 10 個提及最多的 DBMS：</p><pre><code class="language-shell">     dbms      | cnt 
---------------+-----
 PostgreSQL    | 656
 MySQL         | 317
 MongoDB       | 266
 Oracle        | 222
 SQLite        | 213
 Redis         |  88
 Elasticsearch |  70
 Snowflake     |  52
 DGraph        |  46
 Neo4j         |  42
</code></pre><p>自然，這個排名還是不科學，因為我沒有對評論進行情感分析。但它清楚地顯示了，在過去的一年裏，人們提到 Postgres 的次數遠超過其他數據系統。經常有開發者發帖詢問新應用該用什麼 DBMS，線上社區的迴應幾乎都是 Postgres。</p><h5>Andy 説：PostgreSQL 只會在未來幾年變得更好</h5><p>首先，關係數據庫系統成為新應用的首選肯定是一件好事。這表明 Ted Codd 在 1970 年代提出的關係模型的持久影響力。其次，PostgreSQL 是一個很棒的數據庫系統。同所有 DBMS 一樣，它有已知的問題和不足之處。但是有着如此高的關注，PostgreSQL 只會在未來幾年變得更好。</p><h4>基準測試之爭</h4><p>不同的數據庫廠商之間在基準測試結果爭議，今年並不少見。數據庫廠商們試圖證明他們的系統比競爭對手的更快，這種做法可以追溯到 1980 年代末。這也是為什麼 TPC（交易處理性能委員會）成立的原因，希望能提供一箇中立平台來監管性能比較。但是，隨着 TPC 在<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftwitter.com%2Fandy_pavlo%2Fstatus%2F1461164543825129481" target="_blank">過去十年的影響力和普及度的減弱</a>，數據庫們再次處於數據庫基準測試戰爭的漩渦中。</p><p>讓人印象深刻的有三場基準測試爭論。</p><h5>Databricks vs Snowflake</h5><p>Databricks 宣佈他們新的 Photon SQL 引擎在 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.databricks.com%2Fblog%2F2021%2F11%2F02%2Fdatabricks-sets-official-data-warehousing-performance-record.html" target="_blank">100TB TPC-DS 測試中創造了新的世界紀錄</a>。Snowflake 回擊説，他們的數據庫速度是 Databricks 的兩倍，並且 Databricks 運行 Snowflake 的方式不正確。Databricks 反駁道，他們的 SQL 引擎在執行和價格、性能方面都優於 Snowflake。</p><h5>Rockset vs Apache Druid vs ClickHouse</h5><p>ClickHouse 強勢聲明，與 Druid 和 Rockset 相比，CK 的成本效率方面更出色。但沒那麼簡單：Imply 立即用 Druid 的新版本進行了測試，並聲稱 Druid 獲得了性能勝利。Rockset 也加入了討論，説它的性能在實時分析上比其他兩個要好。</p><h5>ClickHouse vs TimescaleDB</h5><p>感受數據庫市場的風向變化，採取老虎式行事風格的 Timescale 加入了性能戰爭。他們發佈了自己的基準測試結果，並藉此機會指出 ClickHouse 技術的弱點。在 Hacker News 上，第三方基準測試的相關討論變得非常火爆。</p><h5>Andy 説：性能之爭不值當</h5><p>在先前的數據庫基準測試中，已經有太多血淋淋的故事（參考：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.percona.com%2Fblog%2Fis-voltdb-really-as-scalable-as-they-claim%2F" target="_blank">https://www.percona.com/blog/is-voltdb-really-as-scalable-as-they-claim/</a> 、<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3D-TIUGC4X2q8%26t%3D418s%EF%BC%89%EF%BC%8C%E6%88%91%E4%B9%9F%E6%9B%BE%E6%98%AF%E5%85%B6%E4%B8%AD%E4%B8%80%E5%91%98%E3%80%82%E4%BD%86%E5%9C%A8%E6%80%A7%E8%83%BD%E7%AB%9E%E4%BA%89%E7%9A%84%E8%B7%AF%E4%B8%8A%EF%BC%8C%E6%88%91%E5%A4%B1%E5%8E%BB%E4%BA%86%E5%A4%AA%E5%A4%9A%EF%BC%9A%E4%B8%8D%E5%8F%AA%E6%98%AF%E6%9C%8B%E5%8F%8B%EF%BC%8C%E8%BF%98%E6%9C%89%E5%A5%B3%E6%9C%8B%E5%8F%8B%E3%80%82%E9%9A%8F%E7%9D%80%E6%97%B6%E9%97%B4%E7%9A%84%E6%B5%81%E9%80%9D%EF%BC%8C%E7%8E%B0%E5%9C%A8%E6%88%91%E8%A7%89%E5%BE%97%E6%80%A7%E8%83%BD%E4%B9%8B%E4%BA%89%E4%B8%8D%E5%80%BC%E5%BE%97%E3%80%82" target="_blank">https://www.youtube.com/watch?v=-TIUGC4X2q8&amp;t=418s），我也曾是其中一員。但在性能競爭的路上，我失去了太多：不只是朋友，還有女朋友。隨着時間的流逝，現在我覺得性能之爭不值得。</a></p><p><strong>現如今客觀地比較數據系統更加困難</strong>，因為雲數據庫管理系統有很多可移動的部件和可調選項，往往很難確定性能差異的真正原因。真實的應用程序也不僅僅是一遍又一遍地運行相同的查詢。在提取、轉換和清洗數據時的用戶體驗，和原始性能數字一樣重要。正如我在這篇<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.protocol.com%2Fenterprise%2Fdatabricks-snowflake-data-warehouse-tpc" target="_blank">關於 Databricks 基準測試結果的文章</a>中告訴記者的那樣，只有老年人才關心官方的 TPC 數字。</p><h4>大數據搞大錢</h4><p>自 2020 年下半年以來，價值至少 1 億美元的風險投資輪次數量一直在穩步增加。2020 年有 327 筆這樣的大宗交易，幾乎佔總風險資本交易量的一半。截至 2021 年 1 月，<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fexplodingtopics.com%2Fblog%2Fvc-trends" target="_blank">價值 1 億美元或以上的風險投資回合已經超過 100 輪</a>。</p><p>2021 年，大量投資資金湧向數據庫公司。在運營數據庫方面，CockroachDB 以 1.6 億美元的融資輪次領跑籌資排行榜，在 2021 年 12 月它再次融了 2.78 億美元。Yugabyte 完成了 1.88 億美元的 C 輪融資。PlanetScale 為他們的 Vitess 託管版融到了 2,000 萬美元的 B 輪。相對較老的 NoSQL 簇擁者 DataStax 為他們的 Cassandra 實現了 3,760 萬美元的風險融資。</p><p>儘管這些融資金額都很驚人，分析型數據庫市場的競爭更為激烈。TileDB 在 2021 年 9 月籌集了一筆未披露金額的資金。Vectorized.io 為他們與 Kafka 兼容的流處理平台籌到 1,500 萬美元。StarTree 不再低調，宣佈了用來打造商業化 Apache Pinot 的 2,400 萬美元融資。有着附加功能的物化視圖的 DBMS Materialize 宣佈他們在 C 輪獲得了 6,000 萬美元。Imply 為基於 Apache Druid 的數據庫服務籌集了 7,000 萬美元。SingleStore 在 2021 年 9 月籌集了 8,000 萬美元，使他們朝着 IPO 邁近了一大步。</p><p>2021 年年初，Starburst Data 為其 Trino 系統（前身為 PrestoSQL）籌集了 1 億美元。Firebolt 是另一家不再低調 DBMS 初創公司，他們發佈了基於 ClickHouse 分支的雲數倉的 1.27 億美元融資新聞。一家新公司，ClickHouse, Inc.，融了可怕的 2.5 億美元，來以 ClickHouse 為主建立新公司，以及從 Yandex 獲得使用 ClickHouse 名稱的權利。</p><p>不過 2023 年數據庫領域融資的最大贏家顯然是 Databricks，他們在 2021 年 8 月籌集了高達 16 億美元的資金，遙遙領先其他數據庫。</p><h5>Andy 説：我們正處在數據庫的黃金時代</h5><p>我們正處在數據庫的黃金時代，有很多優秀的數據庫可以選擇。投資者們正在尋覓下一個像 Snowflake 一樣可以 IPO 的數據庫初創公司。2021 年的融資金額比以往數據庫初創公司都要大。例如，Snowflake 直到成立五年後的 D 輪融資才有超過 1 億美元的單輪融資。Starburst 在成立不到三年的時間內就完成了 1 億美元的融資。現在融資涉及許多因素，比如：Starburst 團隊從 TeraData 獨立出來之前已經在 Presto 工作多年，我覺得如今數據庫的投入資金更多了。</p><h4>消逝的數據庫們</h4><p>遺憾的是，2021 年我們也「送別」了一些數據庫。</p><h5>ServiceNow 收購了 Swarm64</h5><p>該公司最初是開發在 PostgreSQL 上運行分析工作負載的 FPGA 加速器。後來，他們轉向僅使用擴展作為 PostgreSQL 的軟件加速器。但他們未能獲得關注，尤其是與其他資金充裕的雲數倉相比。在 ServiceNow 收購之後，目前仍然沒有消息表明 Swarm64 產品是否會繼續維護。</p><h5>Splice Machine 破產了</h5><p>Splice 推出了一種混合型（HTAP）DBMS，它結合了 HBase 和 Spark SQL，前者用來處理操作性工作負載，後來用來分析數據。後來，他們推動提供一個用於操作性/實時機器學習應用的平台。但是，由於專業的 OLTP 和 OLAP 系統在市場的主導地位，all-in-one 的混合系統在市場並沒有取得什麼進展。</p><h5>私募公司收購了 Cloudera</h5><p>在 2010 年到 2020 年這十年的後期，技術重心從 MapReduce 和 Hadoop 技術轉移之後，Cloudera 同這些技術一樣在雲數倉市場上失去了競爭力。儘管項目依舊在開發且在發佈新版本，Impala 和 Kudu 的初創團隊的大部分人都已經離職。股價也跌破了 2018 年 IPO 的初始價。新投資者能否扭轉公司局面，還有待觀察。</p><h5>Andy 説：2022 年可能會有更多的數據庫公司倒閉</h5><p>看到數據庫項目或公司倒閉的新聞，總是讓人唏噓，但這也是數據庫行業的殘酷現實。開源可能有利於 DBMS 比開發它的廠商活得更久，但事實並非總是如此。由於數據庫的複雜性，它需要全職人員持續地修復 bug 和新增功能。將一個只有軀殼（defunct）的 DBMS 的源碼權和控制權轉移到像 Apache 或是 CNCF 這樣的開源軟件基金會，並不代表這個項目就會神奇般地復甦。</p><p>例如，RethinkDB 在公司破產後捐給了 Linux 基金會，從 GitHub 上的跡象來看，這個項目已經處於停滯狀態（很少有提交，PR 也沒有合併）。無獨有偶，另一個例子是 DeepDB：公司失敗後，他們為代碼創建了自己的非營利基金會，但從來沒有人在上面工作。我預測，2022 年將有更多無法與主流雲廠商、上面提到的那些資金充足的初創公司競爭的數據庫公司倒閉。</p><h4>堅持的回報</h4><p>近年來，Oracle 的聯合創始人 Larry Ellison 運氣不是很好。早在 2015 年，他還是世界上第五富有的人。但世事難料，在 2018 年的億萬富翁排名中他跌到了第十位。</p><p>但這一切在 2021 年 12 月發生了轉變，當 Larry 超過谷歌的聯合創始人 Larry Page 和 Sergey Brin，再次登上世界第五富有的位置。在 2021 年 12 月的某天，在宣佈公司季度盈利超過預期時，Oracle 股票達到過去 20 年單日第二高漲幅，Larry 也在一天之內賺了 160 億美元。新聞媒體認為，這歸功於投資者對 Oracle 成功轉向雲服務十分有信心。</p><h5>Andy 説：為 Larry 高興</h5><p>Larry 和我是舊相識，他重返財富榜第五位無疑是一個振奮人心的新聞。當他運氣不好，僅僅是世界上第十富有的人時，他可能有些憂鬱。但是我很高興看到他能夠從低谷中走出來，回到他應有的排位。</p><hr><p>以上為 Andy 教授三年來的數據庫 review。如果你對數據庫的發展有自己的看法，記得留言喲~</p><h2>參考資料</h2><ul><li>2023 年數據庫回顧原文：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fottertune.com%2Fblog%2F2023-databases-retrospective" target="_blank">https://ottertune.com/blog/2023-databases-retrospective</a></li><li>2022 年數據庫回顧原文：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fottertune.com%2Fblog%2F2022-databases-retrospective" target="_blank">https://ottertune.com/blog/2022-databases-retrospective</a></li><li>2021 年回顧：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fottertune.com%2Fblog%2F2021-databases-retrospective" target="_blank">https://ottertune.com/blog/2021-databases-retrospective</a> &nbsp;</li></ul><p>翻譯：GPT-4 校對：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdiscuss.nebula-graph.com.cn%2Fu%2Fsteam%2Fsummary" target="_blank">清蒸</a>、<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fxiaobot.net%2Fp%2Fsystem-thinking" target="_blank">木鳥</a></p><hr><p>感謝你的閲讀 (///▽///)</p><blockquote><p>關於 NebulaGraph：它是一款開源的分佈式圖數據庫，自 2019 年開源以來，先後被美團、京東、360 數科、快手、眾安金融等多家企業採用，應用在智能推薦、金融風控、數據治理、知識圖譜等等應用場景。(^з^)-☆ GitHub 地址：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fvesoft-inc%2Fnebula" target="_blank">https://github.com/vesoft-inc/nebula</a></p></blockquote></div>
                                    ]]>
            </description>
            <pubDate>Fri, 01 Mar 2024 04:15:44 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/4169309/blog/11045421</guid>
            <link>https://my.oschina.net/u/4169309/blog/11045421</link>
            <author>
                <![CDATA[原創]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[開源日報 | 我讓 AI 用 C 語言寫一個算法；微軟三進制 LLM]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>歡迎閲讀 OSCHINA 編輯部出品的開源日報，每天更新一期。</p><h3><span style="color:#e67e22"><strong># 2024.2.29</strong></span></h3><h2><strong><span style="color:#16a085">今日要點</span></strong></h2><p><strong>OpenSource Daily</strong></p><h3><a href="https://www.oschina.net/news/280842" target="_blank">阿里發佈肖像視頻生成框架 EMO</a></h3><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><span style="background-color:#ffffff; color:#333333">來自阿里巴巴的團隊發佈了音頻驅動的肖像視頻生成框架 EMO（Emote Portrait Alive），相關論文同步發表於 arXiv。輸入一張參考圖像和聲音音頻，該框架能夠生成具有豐富面部表情和頭部姿勢的聲音肖像視頻。<span>&nbsp;</span></span><img alt="" src="https://oscimg.oschina.net/oscnet/up-c3861be0f8476ff9f2bd3f603f40da0bfb7.png" referrerpolicy="no-referrer"></p><h3><a href="https://www.oschina.net/news/280752/bytedance-megascale" target="_blank">字節跳動打造 MegaScale：用於訓練 LLM 的單一 「萬卡集羣」</a></h3><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">MegaScale 將大語言模型訓練擴展到超過 10000 個 GPU，在 12288 個 GPU 上訓練 175B LLM 模型時，MegaScale 實現了 55.2% 的模型 FLOP 利用率（MFU），與層內模型並行技術 Megatron-LM 相比，MFU 提高了 1.34 倍。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><img src="https://oscimg.oschina.net/oscnet/up-a9ada357531674c7eff4dfbd452a1d5c7ff.png" referrerpolicy="no-referrer"></p><hr><h2><strong><span style="color:#16a085">今日觀察</span></strong></h2><p><img src="https://oscimg.oschina.net/oscnet/up-1820b6584b86587277ddac5d427fcd78cbb.png" referrerpolicy="no-referrer"></p><p><span style="background-color:#ffffff; color:#333333">- 微博&nbsp;</span><u><em><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fweibo.com%2F7389231930%2FO2p3z9PSo" target="_blank">一個動態類型的幽靈</a></em></u></p><p><img src="https://oscimg.oschina.net/oscnet/up-eca415a4fd4d03ea517620492c70f1f537e.png" referrerpolicy="no-referrer"></p><p><span style="background-color:#ffffff; color:#333333">- </span><u><em><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fweibo.com%2F6105753431%2FO2OWtwvX7" target="_blank">量子位</a></em></u></p><hr><h2><span style="color:#16a085"><strong>今日推薦</strong></span></h2><p><img src="https://oscimg.oschina.net/oscnet/up-e6601611a548100f9fc98d57fcc92ceb0f2.png" referrerpolicy="no-referrer"></p><hr><h2><span style="color:#16a085"><strong>開源之聲</strong></span></h2><p><img src="https://oscimg.oschina.net/oscnet/up-6ff6bae6e0f678ef52c422248ccaf72102f.png" referrerpolicy="no-referrer"></p><p><img src="https://oscimg.oschina.net/oscnet/up-2baf3fa8669686d11308dec291c8c171c9b.png" referrerpolicy="no-referrer"></p><hr><h2><span style="color:#16a085"><strong>每日項目榜</strong></span></h2><p><strong><span style="background-color:#e67e22">每日 GitHub 精選</span></strong></p><p><img src="https://oscimg.oschina.net/oscnet/up-e9fdc2d06458972c54c34a1682f2338527e.png" referrerpolicy="no-referrer"></p><blockquote><h4><strong><span style="background-color:#e67e22">在線閲讀完整日報內容，訪問：</span></strong><br><u><em><strong><a href="https://report.oschina.net/api/files/jhim80u9qm1ofsw/qdljicvqiqsshd6/187ZiLwG48lc_CngfQJ1Qxs.pdf" target="_blank">開源日報第 19 期：我讓 AI 用 C 語言寫一個算法；微軟三進制 LLM</a></strong></em></u></h4></blockquote><hr><p><strong>往期回顧</strong></p><ul><li><a href="https://report.oschina.net/api/files/jhim80u9qm1ofsw/qdljicvqiqsshd6/187ZiLwG48lc_CngfQJ1Qxs.pdf" target="_blank">開源日報第 018 期：蘋果十年造車夢碎；這個開源項目有點...「大膽」</a></li><li><a href="https://report.oschina.net/api/files/jhim80u9qm1ofsw/7r8dkz3232v4e7a/17_maria_db_v_linux_GoyNoM85IZ.pdf">開源日報第 017 期：MariaDB 消亡史；寫代碼我有三不沾；V 神建議馬斯克用 Linux</a></li><li><a href="https://report.oschina.net/api/files/jhim80u9qm1ofsw/6typ9w3u98f5mxn/16_1_8_2efTeNfFjN.pdf">開源日報第 016 期：鴻蒙程序員平均月薪超 1 萬 8；中美 AI 差距有多大？</a></li><li><a href="https://report.oschina.net/api/files/jhim80u9qm1ofsw/92n4c9ryegpcq1z/015_sora_KcAkRNX93Y.pdf">開源日報第 015 期：為什麼擋不住英偉達；Sora 不靠蠻力</a></li><li><a href="https://report.oschina.net/api/files/jhim80u9qm1ofsw/s7n800w84o6guyv/014_kyezhNxOGD.pdf">開源日報第 014 期：目前的人工智能技術連貓的智能水平都沒達到</a></li><li><a href="https://oscimg.oschina.net/public_shard/%E5%BC%80%E6%BA%90%E6%97%A5%E6%8A%A5%E7%AC%AC013%E6%9C%9F%EF%BC%9A%E7%AD%89%E5%88%B0%20Sora%20%E5%BC%80%E6%BA%90%E4%BA%86%E7%AB%8B%E5%88%BB%E6%8E%A8%E5%87%BA%E5%B1%9E%E4%BA%8E%E6%88%91%E4%BB%AC%E8%87%AA%E5%B7%B1%E7%9A%84%E5%A4%A7%E6%A8%A1%E5%9E%8B.pdf">開源日報第 013 期：等到 Sora 開源了立刻推出屬於我們自己的大模型</a></li><li><a href="https://oscimg.oschina.net/public_shard/%E5%BC%80%E6%BA%90%E6%97%A5%E6%8A%A5%E7%AC%AC012%E6%9C%9F%EF%BC%9ASora%20%E7%BB%99%E4%B8%AD%E5%9B%BD%20AI%20%E5%B8%A6%E6%9D%A5%E7%9A%84%E7%9C%9F%E5%AE%9E%E5%8F%98%E5%8C%96%EF%BC%9BDart%203.3%20%E5%8F%91%E5%B8%83.pdf">開源日報第 012 期：Sora 給中國 AI 帶來的真實變化；Dart 3.3 發佈</a></li><li><a href="https://oscimg.oschina.net/public_shard/%E5%BC%80%E6%BA%90%E6%97%A5%E6%8A%A5%E7%AC%AC11%E6%9C%9F%EF%BC%9A%E7%9B%AE%E5%89%8D%E8%BF%98%E6%B2%A1%E6%9C%89%E2%80%9C%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%89%88Linux%E2%80%9D.pdf">開源日報第 011 期：目前還沒有「大模型版 Linux」</a></li><li><a href="https://oscimg.oschina.net/public_shard/%E5%BC%80%E6%BA%90%E6%97%A5%E6%8A%A5%E7%AC%AC010%E6%9C%9F%EF%BC%9ATauri%20v2%20%E6%94%AF%E6%8C%81%20Android%20%E5%92%8C%20iOS%EF%BC%8C%E8%B7%A8%E5%B9%B3%E5%8F%B0%E5%BC%80%E5%8F%91%E6%96%B0%E9%80%89%E6%8B%A9.pdf">開源日報第 010 期：Tauri v2 支持 Android 和 iOS，跨平台開發新選擇</a></li><li><a href="https://oscimg.oschina.net/public_shard/%E5%BC%80%E6%BA%90%E6%97%A5%E6%8A%A5009%E6%9C%9F%EF%BC%9AVue.js%E8%AF%9E%E7%94%9F10%E5%91%A8%E5%B9%B4%EF%BC%9B%E6%89%8E%E5%85%8B%E4%BC%AF%E6%A0%BC%E8%A7%A3%E9%87%8AMeta%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E5%BC%80%E6%BA%90%E5%85%B6AI%E6%8A%80%E6%9C%AF.pdf">開源日報第 009 期：Vue.js 誕生 10 週年；扎克伯格解釋 Meta 為什麼要開源其 AI 技術</a></li><li><a href="https://www.oschina.net/news/277585">開源日報第 008 期：推動中國開源軟硬件發展的經驗與建議</a></li><li><a href="https://www.oschina.net/news/277415">開源日報第 007 期：「Linux 中國」 開源社區宣佈停止運營</a></li><li><a href="https://www.oschina.net/news/277214">開源日報第 006 期：選擇技術棧一定要選擇開源的</a></li><li><a href="http://www.oschina.net/news/277040">開源日報第 005 期：RISC-V 萬兆開源交換機發售；npm 存在大量武林外傳視頻</a></li><li><a href="https://www.oschina.net/news/276864">開源日報第 004 期：百度輸入法在候選詞區域植入廣告；大神用 Excel 構建 CPU</a></li></ul></div>
                                    ]]>
            </description>
            <pubDate>Fri, 01 Mar 2024 04:05:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/280981</guid>
            <link>https://www.oschina.net/news/280981</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
    </channel>
</rss>
